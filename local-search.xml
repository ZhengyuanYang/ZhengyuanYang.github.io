<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Decision Tree and Ensemble Models</title>
    <link href="/2023/02/27/decision-tree/"/>
    <url>/2023/02/27/decision-tree/</url>
    
    <content type="html"><![CDATA[<h1 id="decision-tree-and-ensemble-models">Decision Tree and Ensemble Models</h1><h2 id="decision-tree">1. Decision Tree</h2><h3 id="about-decision-tree">1.1 About Decision Tree</h3><p>Decision Tree is a data structure that can split data into subsets. In Machine Learning, we can use such a structure as our hypothesis space to segment our datasets into units and perform prediction.</p><p><img src="/2023/02/27/decision-tree/1.png"></p><p>A decision tree consists of decision nodes and leaf nodes. Each decision node represent a split of sample based on some conditions a input feature <span class="math inline">\(X_i\)</span>. A directed route of the decision nodes represent a series of <strong>conditioning</strong> on the sample sapce. Each leaf node represents a subsample space obtained from a unique route, and we can estimate the conditional probability distribution <span class="math inline">\(P(Y|X=x)\)</span> from the leaf node. The output variable Y can be either continuous(regression) or discrete(classification).</p><p>The decision tree is a non-parameter model. It can be infinitely extended without a constraint on max tree depth.</p><h3 id="training-process">1.2 Training Process</h3><p>The training process of decision tree is a recursive process. Let D denote the original sample set, X denote the feature spaces</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs pseudocode">def splitting(tree):<br>while impurity metrics is not reached:<br>x+i = select a feature x_i in feature space X(tree)<br>sub_tree_left,sub_tree_right = find the best split based on x_i(tree, x_i)<br>tree.left = splitting(sub_tree_left)<br>tree.right = splitting(sub_tree_right)<br>  return tree<br><br>splitting(D)<br><br>def label_and_predict(tree, sample):<br>for leaf in tree:<br>if a classification_tree:<br># use the mode of Y of training samples belong to this leaf node as the prediction<br>leaf.pred = leaf.Y.mode()<br>else:<br># use the mean of Y of training samples belong to this leaf node as the prediction<br>leaf.pred = leaf.Y.mean()<br><br>leaf_node_for_sample = find the leaf node the sample belong to according to sample&#x27;s X<br>sample_pred = leaf_node.pred<br><br></code></pre></td></tr></table></figure><p><img src="/2023/02/27/decision-tree/2.png"></p><p>The implementation of Decision Tree includes ID3, C4.5 and CART. The differences of these implementations are the strategy they select layer(feature) and best split.</p><h2 id="implementation-of-decision-tree">2. Implementation of Decision Tree</h2><h3 id="id3">2.1 ID3</h3><p>ID3 is a decision tree that can deal only with <strong>finite discrete inputs</strong>(usually <strong>categorical features</strong>). Suppose we have a sample set D and a feature space X, where <span class="math inline">\(X_i\)</span> is a finite discrete feature like sex, country. If <span class="math inline">\(X_i\)</span> has infinite values or is continues, then the ID3 requires the feature to be binned into finite discrete sections.</p><h4 id="feature-selection-and-splitting">2.1.1 Feature Selection and Splitting</h4><p>The strategy of selecting feature to split is based on Information Gain. For the explanation of IG, refer to <a href="http://zhengyuanyang.com/2022/09/22/information-theory-in-ML/">this article</a>.</p><p>For each feature <span class="math inline">\(X_i\)</span>: <span class="math display">\[\begin{aligned}IG(X_i) &amp;= H(D) - H(D|X_i) \\&amp;= -\sum_m^k p(y=c_m)log(p(y=c_m)) - (-\sum_n\sum_m p(y=c_m|X_i = x_n)p(X=x_n)log(p(y=c_m|X_i = x_n)))\end{aligned}\]</span> According to the definition, the feature with the largest imformation can reduce the uncertainty of Y to the greatest extent, thus would be selected as the feature to split. There is no specific techniques in finding best split, since all features are categorical, just split the tree into n nodes, where n is the number of categories of feature <span class="math inline">\(X_i\)</span></p><h4 id="properties">2.1.2 Properties</h4><ul><li>ID3 does not have any pruning strategy</li><li>ID3 perfer features with large number of category</li><li>ID3 can only deal with finite discrete inputs if no binning is implemented.</li><li>ID3 cannot deal with missing values</li><li>Since or feature is catrgorical, once a featrure is selected a layer, it would not appear in the following subtrees any more.</li></ul><h3 id="c4.5">2.2 C4.5</h3><p>C4.5 is a improved version of ID3. One drawback of ID3 is that it would perfer features with large number of category. For example, if there is a unique identity number for each sample, then that feature's IG would be 1, but this provide no clues for future's prediction.</p><h4 id="feature-selection-and-splitting-1">2.2.1 Feature selection and splitting</h4><p>To solve this, the C4.5 use Information Gain Rate to select feature: <span class="math display">\[IGR(X_i) = \frac{IG(X_i)}{H(D)}\]</span> this would penalize those features with to many categories, as these features usually have larger entropy. However, this could bring the algorithm to the opposite that it would prefer feature with less number of categories. This means the absolute values of IG can be low while the IGR is high. To fix this, the C4.5 would first do a feature selection based on IG:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs pseudocode">for X_i in X:<br>if IG(X_i) &lt; IG(X).avg()<br>X.drop(X_i)<br></code></pre></td></tr></table></figure><p>In addition, the C4.5 introduce different techniques to deal with selection on continuous input feature, for a continuous feature <span class="math inline">\(X_i\)</span>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs pseudocode">for X_i in X<br>if X_i is continuous:<br>      Sort all sample by X_i in a ascending order<br>      for each adjacent samples<br>          m_j = the medium of X_i_j,X_i_(j+1) #use the medium as a threshold<br>          #Z is a label flagged whether X_i of a sample is above the threshold<br>          Z = Z_right if x_i_j &lt; m_j else Z_right <br>          IGR_j = IGR(D, Z) #A binary split based on Z<br>      # The split with the highest IGR is the best split of feature X_i<br>      IGR_best_i = max(IGR_j)<br>    else:<br>    IGR_best_i = calculate IGR(X_i) as a categorical variable like ID3<br>    <br># Compare all<br>the feature to select = argmax_Xi(IGR_best_i)<br><br></code></pre></td></tr></table></figure><p>The process put feature selection and feature splitting together. It first use a enlightening method to filter some feature with low IG. then calculate the IGR for the rest of the features. For a continuous feature, it use the split with highest IGR as the best split. For a categorical feature, it still generate a child node for each category.</p><h4 id="pruning-strategy">2.2.2 Pruning Strategy</h4><p>One drawback ID3 is that it does not have a pruning strategy, thus can be easy to overfit. In C4.5, post-pruning is applied to control the complexity of the model. The post-pruning means the algorithm would first make the split and then decide whether to prune the subtrees based on the error rate on the leaf node. Specifically, the post-pruning strategy is a method called Pessimistic Error Pruning.</p><p>For a decision node, suppose the algorithm first split <span class="math inline">\(n_L\)</span> child nodes based on a feature. Then:</p><ul><li>Let <span class="math inline">\(E_i\)</span> denote the number of false classification in the <span class="math inline">\(i^{th}\)</span> node</li><li>Let <span class="math inline">\(N_i\)</span> denote the number of samples in the <span class="math inline">\(i^{th}\)</span> node</li><li>Let <span class="math inline">\(\gamma\)</span> be a penalty parameters for complexity of model</li></ul>The error rate of splitting and treat the node as a subtree: <span class="math display">\[e_{tree} = \frac{ \sum_iE_i + \gamma*n_L}{\sum_iN_i}\]</span> Consider a random variable <span class="math inline">\(M_{tree}\)</span> denoting the number of misclassification. For example, if the output variable Y is binary, we can consider <span class="math inline">\(M_{tree} \sim Bino(e,\sum_i N_i)\)</span> $$<span class="math display">\[\begin{aligned}E[M_{tree}] &amp;= \sum_iN_i *e_{tree}\\Std[M_{tree}] &amp;= \sqrt{\sum_i N_i*e_{tree}*(1-e_{tree})}\end{aligned}\]</span><p><span class="math display">\[ Now apply pruning and replace the subtree with a leaf node. Let E, N denote the number of misclassified samples and all samples in the leaf node, calculate the error rate if not splitting and treat the node as a leaf node:\]</span> e_{leaf} =  <span class="math display">\[Accordingly:\]</span> E[M_{leaf}] = N*e_{leaf} <span class="math display">\[If $M_{leaf}$ is significant greater than $M_{tree}$, we can make the judgement that the splitting is necessary. When N is big, the binomial distribution is approximate to a Normal distribution. Thus, through a test,the condition of accepting a splitting is:\]</span> p = T_test(E[M_{leaf}] - E[M_{tree}])  $$ Otherwise, the subtree should be pruned.</p><h4 id="missing-value-processing">2.2.3 Missing Value Processing</h4><p>When there exists missing values in features, two problem needs to be solved by the decision tree:</p><ul><li>How to calculate the IG/IGR of <span class="math inline">\(X_i\)</span> when there are missing values in <span class="math inline">\(X_i\)</span>?</li><li>When training, how to decide which sub-node the sample containing missing value belong?</li><li>When predicting, how to label the sample when it meet a node that based on its missing values?</li></ul><p>For the first question, the solution by C4.5 is to calculate the IGR on samples without missing values and then add a weight to the IGR. Let the weight be: <span class="math display">\[\rho  = \frac{n_{\widetilde{D}}}{n_D}\]</span> where <span class="math inline">\(D, \widetilde{D}\)</span> is the orginal sample set and a subset that samples with missing values of <span class="math inline">\(X_i\)</span> are dropped. <span class="math inline">\(n\)</span> denote the number of samples. The revised IGR would then be: <span class="math display">\[IGR(X_i)&#39;/IG(X_i)&#39; = \rho * IGR(X_i)/IG(X_i)\]</span></p><p>For the second question, let <span class="math inline">\(w_k\)</span> denote the fraction of samples that belong to the <span class="math inline">\(k^{th}\)</span> category(or value for continuous variable): <span class="math display">\[\omega_k = \frac{n_k}{n_ {\widetilde{D}}}\]</span> If a sample's value on <span class="math inline">\(X_i\)</span> is missing when trying to split the samples based on <span class="math inline">\(X_i\)</span>, then those missing value samples would <strong>enter every child node with a weight <span class="math inline">\(\omega_k\)</span></strong>. This means, when further splitting the nodes, the <span class="math inline">\(P(y = c_m)\)</span> in the information gain now calculated as: <span class="math display">\[P(y = c_m) = \frac{\sum \omega_{k, y= c_m}}{\sum \omega_k}\]</span> and the weight of information gain would also be: <span class="math display">\[\rho = \frac{\sum\omega_\widetilde{D}}{\sum \omega_D}\]</span> For example, suppose we have the following dataset</p><p><img src="/2023/02/27/decision-tree/3.png"></p><p>In this first split, <span class="math inline">\(\widetilde{D} = \{1,2,3,4,5,7,8,,9,10,11,12,13,14\}\)</span>, <span class="math inline">\(\rho = \frac{13}{14}\)</span>, then <span class="math display">\[\begin{aligned}H(\tilde{D}) &amp;= [-\frac{5}{13}*log(\frac{5}{13})-\frac{3}{13}*log(\frac{3}{13})-\frac{5}{13}*log(\frac{5}{13})]\\IGR &amp;= \frac{H(\tilde{D}) - H(\tilde{D}|outlook)}{H(\tilde{D})}\\IGR&#39; &amp;= \frac{13}{14}*IGR\end{aligned}\]</span> Suppose outlook is the feature with max IGR'. Let split the sample based on outlook. Since there is a sample 6 that missing value "outlook", let will enter each node with a weight. <span class="math inline">\(\omega_s = \frac{5}{13}, \omega_o = \frac{3}{13}, \omega_r = \frac{5}{13}\)</span></p><p>Now move the subtree that "outlook = sunny"</p><p><img src="/2023/02/27/decision-tree/4.png"></p><p>suppose we want to further split the tree and we want to calculate the IGR of "Windy", now: <span class="math display">\[\begin{aligned}\rho &amp;= \frac{5+\frac{5}{13}}{5+\frac{5}{13}} = 1\\H(\tilde{D_s}) &amp;= [-\frac{2+\frac{5}{13}}{5+\frac{5}{13}}*log(\frac{2+\frac{5}{13}}{5+\frac{5}{13}})-\frac{3}{5+\frac{5}{13}}*log(\frac{3}{5+\frac{5}{13}})]\\IGR &amp;= \frac{H(\tilde{D_s}) - H(\tilde{D_s}|Windy)}{H(\tilde{D_s})}\\IGR&#39; &amp;= 1*IGR \end{aligned}\]</span></p><p>Finally, for the third question, when we try to make the prediction. Suppose we have a decision tree like this:</p><p><img src="/2023/02/27/decision-tree/5.png"></p><p>Now we have a sample that "outlook = sunny" and "humidity = null". To decide the label of this sample, we just calculate the conditional probability distribution of Y when the sample meet the node it is missing value of.</p><p>For the humidity node: <span class="math display">\[\begin{aligned}P(Class = play|sunny) =&amp; P(Class = Play|Humidity \le 75|sunny) P(Humidity \le 75|sunny) \\&amp;+ P(Class = Play|Humidity &gt; 75|sunny) P(Humidity &gt; 75|sunny)\\=&amp;\frac{2}{5.4}*1+\frac{3.4}{5.4}*\frac{3}{3.4} = 44\%\end{aligned}\]</span></p><p><span class="math inline">\(P(Class = Play) &lt; P(Class = not \ play)\)</span>, thus the prediction is "play"</p><h4 id="properties-1">2.2.4 Properties</h4><ul><li>C4.5 is a classification algorithm. Although it deal with continuous features, the output features still needs to be categorical</li><li>For continuous feature, C4.5 sort the samples and split the samples into 2 parts. The continuous feature can be applied again in the subtrees.</li><li>For categorical feature, C4.5 still split the samples into n parts. The categorical feature won't be applied again in the subtrees.</li><li>C4.5 is still a Multi-tree. It has lower efficiency than CART.</li></ul><h3 id="classification-and-regression-treecart">2.3 Classification and Regression Tree(CART)</h3><p>The C4.5 algorithm can only deal with classification tasks, and the efficiency of it is low. CART is a improved algorithm for C4.5.</p><h4 id="feature-selection-and-splitting-2">2.3.1 Feature selection and splitting</h4><p>CART has similar processing like C4.5, which sort the samples in an ascending order and find a best split to segment the samples in 2 parts. The difference is CART applies such method on all feature, not just continuous features, and it provides a different metrics to measure a split.</p><p>In addition, CART can do both regression and classification. When the output variable is continuous, it use a combined MSE to measure the error of a split: <span class="math display">\[MSE = [\sum_{i \in D_{left}}(y_i-\bar{y}) + \sum_{i \in D_{right}}(y_i-\bar{y})]\]</span> When doing classification, CART use the <a href="http://zhengyuanyang.com/2022/09/22/loss-function/#gini-impurity">Gini Index</a> as a metric: <span class="math display">\[G = 1- \sum_i^mP(y = c_m)\]</span></p><p><span class="math display">\[Combined \ Gini = G_{left} + G_{right}\]</span></p><p>Unlike information gain, both metrics are better when lower.</p><p>The feature selection process would then be:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs pseudocode">for X_i in X<br>      Sort all sample by X_i in a ascending order<br>      for each adjacent samples<br>          m_j = the medium of X_i_j,X_i_(j+1) #use the medium as a threshold<br>          #Z is a label flagged whether X_i of a sample is above the threshold<br>          Z = Z_right if x_i_j &lt; m_j else Z_right<br>          #A binary split based on Z<br>          if a regression tree:<br>          I_j = combine_MSE(D, Z)<br>          else:<br>          I_j = combined_Gini(D,Z)<br>      # The split with the lowest MSE or Gini is the best split of feature X_i<br>      I_best_i = min(I_j)<br><br>    <br># Compare all<br>the feature to select = argmax_Xi(I_best_i)<br></code></pre></td></tr></table></figure><h4 id="pruning-strategy-1">2.3.2 Pruning Strategy</h4><p>The pruning strategy applied in CART is called Cost Complexity Pruning. It is also a kind of post-pruning. The idea of this strategy is similar like Pessimistic Error Pruning in C4.5, but it works different.</p><p>Suppose we have a parent node t. Let <span class="math inline">\(T\)</span>be tree below node t(<span class="math inline">\(T\)</span> use t as a root node). Let C be error function that can evaluate the performance of <span class="math inline">\(T\)</span>. For regression, C can be MSE, for classification, C can be misclassification rate. Construct a regularization term <span class="math inline">\(C_\alpha\)</span>: <span class="math display">\[C_\alpha(T) = C(T) + \alpha|T|\]</span> where |T| is the number of leaf nodes in T, <span class="math inline">\(\alpha\)</span> is a hyperparameter that adjust the penalty of complexity.</p><p>Similarly like the C4.5, we calculate the difference on <span class="math inline">\(C_\alpha\)</span> between use the tree T and replace T with a single leaf node. Define the cost of doing so as: <span class="math display">\[g(t) = \frac{C_\alpha(T_{leaf}) - C_\alpha(T_{tree})}{|T|-1}\]</span> <span class="math inline">\(g(t)\)</span> represent the cost on performance if replace the non-leaf node t with a leaf node.</p><p>The pruning strategy is then:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs pseudocode">non-leaf nodes sorted = sort the non-leaf nodes in original DT from the bottom to the top<br>for node in non-leaf nodes sorted:<br># calculate the cost of each node<br>cost_nodesa.append(g(node))<br># fine the node with least cost and prune that node<br>node_to_prune = argmin(cost_node_i)<br>DT_temp = replace node_to_prune with a leaf node<br># once a node is pruned, record the updated tree<br>DTs.append(DT.temp)<br><br># validate each tree in the record and select the best<br>for DT_j in DTs:<br>validate the performance of DT_j<br>select the DT_j with best performance<br><br></code></pre></td></tr></table></figure><h4 id="missing-value-processing-1">2.3.3 Missing Value Processing</h4><p>Back to the three questions:</p><ul><li>How to calculate the MSE/Gini of <span class="math inline">\(X_i\)</span> when there are missing values in <span class="math inline">\(X_i\)</span>?</li><li>When training, how to decide which sub-node the sample containing missing value belong?</li><li>When predicting, how to label the sample when it meet a node that based on its missing values?</li></ul><p>For the first question, the solution by CART is same as C4.5, which is give the MSE or Gini with a weight: <span class="math display">\[\rho = \frac{n_{\widetilde{D}}}{n_D}\]</span></p><p>where <span class="math inline">\(D,\tilde{D}\)</span> is the orginal sample set and a subset that samples with missing values of <span class="math inline">\(X_i\)</span> are dropped. n denote the number of samples.</p><p>The Gini/MSE would then be: <span class="math display">\[Gini&#39;\ or \ MSE&#39; = \frac{ 1}{\rho} * (Gini\ or \ MSE)\]</span></p><p>For the scond and third question, the CART use a method call <strong>surrogate splitter</strong>. Suppose we select <span class="math inline">\(X_i\)</span> from X as our best splitting feature. If a sample reach the splitter with missing value on <span class="math inline">\(X_i\)</span>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs pseudocode">IG = Gini or MSE of the Decision node on X_i<br><br>thresh = a threshold measure the difference of IG on two feature<br><br>for X_j in the X except for X_i:<br>IG_j = calculate Gini or MSE of X_j on current decision node<br># record X_j as a surrogate splitter<br>SS.append(j, IG_j)<br># rank the surrogate splitters according to there information gain<br><br>SS = SS.rank by S_j<br>for j,IG_j in enumerate(SS):<br>if sample.X_j is missing: drop X_j from SS<br>if IG - IG_j &gt; thresh: drop X_j from SS<br>if there are surrogate splitter left in SS:<br>decide the sample based on X_SS[0] #decide the sample by the best surrogate splitter<br>else:<br>let the sample enter the leaf node with most samples in it<br><br></code></pre></td></tr></table></figure><p>In this method, for a best spliter node <span class="math inline">\(X_i\)</span>, if a sample happen to miss value <span class="math inline">\(X_i\)</span>, we will calculate the MSE or Gini of the rest features based on the samples in this node. We rank these features by Gini or MSE and apply them as a surrogate splitter.</p><p>Given a sample, a legal surrogate splitter should guarante:</p><ul><li>The sample should not miss its value on the feature this splitter based on</li><li>The surrogate splitter should not be too different too the original splitter, that is, the difference between there Gini or MSE should be within a threshold</li></ul><p>In the legal surrogate splitters, select the best(with lowest Gini or MSE) surrogate splitter to decide which child node the sample should go to. If there are no legal surrogate splitters, just put the sample into the node that have the most samples.</p><p>This method is very time-consuming, as it demands metrics calculation on all features in every split.</p><h4 id="properties-of-cart">2.3.4 Properties of CART</h4><ul><li>CART can deal with both Regression and Classification</li><li>Features in CART would be applied as splitters repeatedly. We can use the frequency they emerge as a feature importance measure</li><li>CART is a strict binary tree, and it does not involve log calculations, thus is faster than C4.5</li><li>CART has different pruning and missing value processing strategy comparing to C4.5</li><li>CART suit big sample, the variance can be high if applied on small sample</li></ul><h2 id="ensemble-model">3. Ensemble Model</h2><p>As single model can have problem with bias or variance. An ideal is to combine multiple basic learner(single model) into a strong learner(ensemble model). The way to combine the basic learners includes:</p><p><strong>Bagging</strong></p><p>Bootstrap aggregating is a method to deal with high variance of model.It randomly take samples with replacement from the original dataset. Each subset is sent to a weak learner and used to estimate the probability <span class="math inline">\(P(Y|X)\)</span>. All weak learner work parallelly. When a new sample sent to the model for prediction, it would go through all weak learner and get a set of partial prediction. The weak learners would than make a vote to decide the final decision by the strong learner.</p><p><strong>Boosting</strong></p><p>Boosting is a method to deal with high bias of model. The bias is reflected by the residual between <span class="math inline">\(y_{true}\)</span> and <span class="math inline">\(y_{pred}\)</span>. We can thus model on the residual again to get more accurate model. Boosting is a kind od serial method.</p><p>As a typical non-parameter learner, Decision is often applied as a basic learner in ensemble model.</p><h3 id="random-forest">3.1 Random Forest</h3><h4 id="training-process-1">3.1.1 Training Process</h4><p>A random forest is a <strong>bagging method</strong> in which every learner is a decision tree. The basic learner is a CART, but in most applications, the basic learner support Information Gain as a splitting criterea when doing classification.</p><p><img src="/2023/02/27/decision-tree/6.png"></p><p>Specifically, the train process of a RF should be like:</p><ol type="1"><li>Randomly take n sample set from the dataset with replacement, where n is the number of weak learner. Each sample set contain m samples</li><li>For each subset, conduct a column sampling, which take a subset k from the original feature space X</li><li>Train each weak learner with a sub training set with a size of <span class="math inline">\(m * k\)</span>.</li><li>For a test sample, run the test sample through each tree, then average each treeâ€™s prediction.</li></ol><h4 id="pruning-strategy-2"><strong>3.1.2 Pruning</strong> Strategy</h4><p>Since the bagging method already realize a overfitting control, usually we won't apply pruning on an RF. We can still demand pruning, if we do want so, based on the pruning strategy of a single DT though.</p><h4 id="missing-value-processing-2"><strong>3.1.3 Missing Value Processing</strong></h4><p>Although weak learner already provides missing value processing strategy, it could be very time-consuming when applied to ensemble model with larger scale of estimators. Thus, most ensemble model frameworks do not provide missing value processing function in ensemble modeling.</p><p>However, if we do want to equip the RF model with a missing value imputation method, we can do the following stuff:</p><ol type="1"><li>impute all numerical missing value with sample average, all categorical missing value with sample mode</li><li>use the imputed sample set to calculate a similarity matrix among all samples, where the similarity between the <span class="math inline">\(i^{th}\)</span> and <span class="math inline">\(j^{th}\)</span> samples is <span class="math inline">\(W_{i, j}\)</span></li><li>Back to the original sample set, use the similarity as a weight, fill a missing value <span class="math inline">\(X_{k,j}\)</span>, with the weighted average of all other sample: <span class="math inline">\(X_{k,j} = \frac{1}{n} \sum_{i\ne k}^n W_{i,k}X_{i,j}\)</span>. If <span class="math inline">\(X\)</span> is a categorical variable, use a weighted vote.</li></ol><p>This process is basically a data filling based on <strong>collaborative filtering</strong></p><h4 id="feature-importance"><strong>3.1.4 Feature Importance</strong></h4><p>Ensemble models usually have some embedded feature importance evaluation method. For the RF, there commonly are two methods:</p><p><strong>Mean Impurity Decrease / Error Decrease/ Information Gain</strong></p><p>For a feature <span class="math inline">\(X_i\)</span>, its importance on a non-leaf node m is: <span class="math display">\[FI(X_i,m) = GI_m -(GI_{left}+GI_{right})\]</span> Where GI is the gini index of the node, left and right represent the left and right child node of m.</p><p>Suppose in a DT, M is the collection of a node that select <span class="math inline">\(X_i\)</span> as a spliter, then the feature importance of <span class="math inline">\(X_i\)</span> on this tree is: <span class="math display">\[FI(X_i,DT) = \sum_{m \in M} FI(X_i,m)\]</span> Suppose there are n trees in the forest, the feature importance of <span class="math inline">\(X_i\)</span> would then be: <span class="math display">\[FI(X_i) = \sum_j^nFI(X_i,DT_j)\]</span> We can normalize the feature importance so its scale is 1: <span class="math display">\[\hat{FI(X_i)} = \frac{FI(X_i)}{\sum_i FI(X_i)}\]</span> Samely, we can replace the criterion with MSE or Imformation Gain and compute according feature importance</p><p><strong>OOB Error(Permutation)</strong></p><p>IN a RF, for a DT, there would exist some samples that never been selected by the bootstrap process. We call these samples the Out-of-bag data. We can use these data to evaluate the trained DT. Let <span class="math inline">\(E_j\)</span> denote the error rate (1-accuracy) of the <span class="math inline">\(j^th\)</span> DT using OOB data.</p><p>Now add a random noise to feaure <span class="math inline">\(X_i\)</span>, and use the OOB data with noise to evaluate the DT again. Denote the error as <span class="math inline">\(E_j&#39;\)</span></p><p>If a noise added to <span class="math inline">\(X_i\)</span> would lead to a great descent of accuracy of the DT, then <span class="math inline">\(X_i\)</span> is very important to that DT. Thus we define the feature importance of <span class="math inline">\(X_i\)</span> on the forest with n trees as: <span class="math display">\[FI(X_i) = \sum_j FI(X_i,DT_j) = \sum_j (E_j - E&#39;_j)\]</span></p><h3 id="gradient-boosting-decision-treegbdt">3.2 Gradient Boosting Decision Tree(GBDT)</h3><h4 id="training-process-2">3.2.1 Training Process</h4><p>In the GDBT, we define the residual as: <span class="math display">\[r = \frac{\partial L(y_{ture},M(X)) }{\partial M(X)}\]</span> where L is a loss function, M(X) is the output of a tree</p><p>Let <span class="math inline">\(X_0,Y_0\)</span> be the original inputs and outputs. According to the idea of boosting, the traning process of a GBDT is:</p><ol type="1"><li>Fit a model <span class="math inline">\(M0\)</span> to predict <span class="math inline">\(\hat{Y_0} = M_0(X)\)</span></li><li>Calculate the residual <span class="math inline">\(r_0 = \frac{\partial L(\hat{Y_0},Y_0)}{\partial\hat{Y_0}}\)</span></li><li>Fit a new model <span class="math inline">\(M1\)</span> using X as inputs and <span class="math inline">\(r_0\)</span> as outputs, get the prediction of residual <span class="math inline">\(\hat{r_0} = M_1(X )\)</span></li><li>update the prediction <span class="math inline">\(\hat{Y_1} = \hat{Y_0} + \alpha \hat{r_0}\)</span>, where <span class="math inline">\(\alpha\)</span> is the learning rate</li><li>use <span class="math inline">\(\hat{Y_1}, Y_0\)</span> to calculate <span class="math inline">\(r_1\)</span>, this time <span class="math inline">\(r_1 = \frac{\partial L(\hat{Y_1},Y_0)}{\partial\hat{r_0}}\)</span></li><li>Repeat process 3-5 until the residual is small enough</li></ol><p><strong>GDBT for Classification</strong></p><p>GDBT requires the residual to be continuous, this means the basic learner of GBDT are all Regression Tree. But GBDT can still do classification. The idea is the same as Generalized Linear Model like Logistic Regression. For the weak learner to predict <span class="math inline">\(\hat{r_i}\)</span>, the weak learner first estimates a canonical parameter <span class="math inline">\(\theta\)</span> for a Nature Exponential Family Distribution. Let <span class="math inline">\(\eta = M(X)\)</span> denote the estimation of <span class="math inline">\(\theta\)</span> given by the DT: <span class="math display">\[\hat{r_i} = AF(M_{i+1}(X)) = AF(\eta_{i+1})\]</span> where AF is the activation function. <span class="math display">\[\hat{Y_{i+1}} = \hat{Y_{i}}+\alpha\hat{r_i} = \hat{Y_{i}}+\alpha AF(\eta_{i+1})\]</span> Note thar the GDBT always <span class="math display">\[r_{i+1} = \frac{\partial L(\hat{Y_{i+1}},Y_0)}{\partial \eta_{i+1}}\]</span> The loss function in classification scenarios are usually <a href="http://zhengyuanyang.com/2022/09/22/loss-function/#log-losscross-entropy-loss">Log Loss</a>.</p><p>For details of GLM, refer to <a href="http://zhengyuanyang.com/2023/02/23/linear-regression/#generalized-linear-model">this article</a></p><p><strong>Subsampling</strong></p><p>In many framework, GDBT support sampling. Suppose we have 100 feature and the subsampling rate is 0.9, the every time a new weak learner is created, 90 sample is drawed randomly from the sample set. This could lead to a situation that for model <span class="math inline">\(M_{i+1}\)</span>, the output variable for some samples are <span class="math inline">\(r_i\)</span>, while other samples's output is <span class="math inline">\(r_{j &lt; i}\)</span>. Such a process would increase the bias but can reduce the variance of the model.</p><h4 id="pruning-strategy-3">3.2.2 Pruning Strategy</h4><p>Some GDBT support <strong>pre-pruning</strong>, that is, the impurity decrease or information gain must be less or greater than a threshold for the split the be generated. Samely, we can applied the post-pruning strategy the weak learner has originally.</p><p>However, in real application of boosting, we usually control overfitting by</p><ul><li>constrain the max depth of a single tree</li><li>set a shrinkage parameter to <span class="math inline">\(\alpha\)</span> to control the step size of learning</li><li>Apply subsampling</li></ul><h4 id="missing-value-processing-3">3.2.3 Missing Value Processing</h4><p>In GDBT, for time-saving reasons, the strategy is to:</p><ol type="1"><li>When training, calculate impurity or information gain without missing value sample</li><li>Try to put <strong>all the missing value samples</strong> respectively into the left and right split and calculate which would bring less loss(based on the loss function selected). Put the sample into that split and record the direction(left or right)</li><li>When predicting, suppose a sample is missing value <span class="math inline">\(X_i\)</span> and meet a node split on that feature. If there exists value missing on that node, then find the direction that missing values samples goes during the training process. If there are no missing value samples in the training, then the new sample goes to a default direction decided by the instance.</li></ol><h4 id="feature-importance-1">3.2.4 Feature Importance</h4><p>The GDBT can use same feature importance evaluation method like the RF. Since GDBT's basic estimator is Regression Tree, we usually just calculate the decrease of <strong>MSE</strong>. However, when doing classification, we can also consider directly use the real label Y to calculate the <strong>impurtiy</strong> of a node.</p><h3 id="xgboosting">3.3 XGBoosting</h3><h4 id="training-process-3">3.3.1 Training Process</h4><p><strong>Objective Function</strong></p><p>The XGboosting is a improved version of GDBT. The biggest difference is the way it define the residual. XGB use the second derivative Taylor Series to define the residual, that: <span class="math display">\[\begin{aligned}r_{i+ 1} &amp;= [L(y_0,\hat{y}_{i})+g_{i}\hat{r}_i+\frac{1}{2}h_{i}\hat{r}_i^2] + \Omega(T)\\g_{i} &amp;= -\frac{\partial L(y_0,\hat{y}_{i})}{\partial M_{i+1}(X)} \\h_{i} &amp;= -\frac{\partial^2 L(y_0,\hat{y}_{i})}{\partial M_{i+1}(X)^2 } \\\end{aligned}\]</span> where in regression <span class="math inline">\(\hat{r_i} = M_{i+1}(X)\)</span> and in classification <span class="math inline">\(\eta_ {i+ 1} = M_ {i+1}(X)\)</span>, and <span class="math inline">\(\Omega(T)\)</span> is a regularization term: <span class="math display">\[\Omega(T) = \gamma J + \frac{1}{2}\lambda \sum_{j=1}^J b_j^2\]</span> where J is number of leaf nodes under node T, <span class="math inline">\(b_j\)</span> is values on those leaf nodes, <span class="math inline">\(\gamma, \lambda\)</span> are hyper parameters control the degree of penalty.</p><p><strong>Splitting Strategy</strong></p><p>Unlike traditional CART, the XGB use a generalized gain deduced from the objective function.</p><p>Let <span class="math inline">\(R_ j\)</span> represent the collection of samples belong to the current node t. In equation 32, we know that the prediction of residual on a node t <span class="math inline">\(\hat{ r}_t\)</span> is actually decided by the samples, which is the average of samples beneath the t's subtree, which is the leaf values <span class="math inline">\(b_j\)</span>. If we express <span class="math inline">\(r_i\)</span> in <span class="math inline">\(\sum_j^ Jbj\)</span>: <span class="math display">\[r_t = [L(y_0,\hat{y}_{i})+G_{j}b_j+\frac{1}{2}(H_{j}+\lambda )b_j^2] + \gamma J\]</span> where <span class="math inline">\(G_j = \sum_{k \in R_j}g_k\)</span>, representing the sum of first derivatives of samples belong to this node. Same with <span class="math inline">\(H_j\)</span>.</p><p>When the samples belongs to the node <span class="math inline">\(R_ j\)</span> is given, in other word, a split has been made, the only unknown variable in this function is <span class="math inline">\(b_j\)</span>. Now we calculate the optimal value of <span class="math inline">\(b_j\)</span> using <span class="math inline">\(\frac{d r_{i+ 1}}{db_j} = 0\)</span>, and we obtain: <span class="math display">\[b^* = -\frac{G_j}{H_j+\lambda}\]</span> and bring the optimal back to objective function to get the best error function given a split: <span class="math display">\[obj_{R_j} =-\frac{1}{2}[\frac{ G_ j^ 2}{H_ j + \lambda}] + \gamma J]\]</span> In a splitting process, XGB need to compare the error of using a node as a leaf node or splitting it into 2 child nodes. In such scenario, <span class="math inline">\(J, J_L, J_R\)</span> all equal to 1. Thus we define the Gain of a split as: <span class="math display">\[\begin{aligned}Gain &amp; = Obj_{L+R} - [Obj_L + Obj_R ] \\&amp; = [-\frac{1}{2} \cdot \frac{ (G_L + G_R)^ 2}{H_L+H_R + \lambda} + \gamma] - [-\frac{1}{2} \cdot (\frac{G_L^ 2}{H_L + \lambda} + \frac{G_R^ 2}{H_R + \lambda})+2\gamma]  \\&amp; = \frac{1}{2}[\frac{G_L^ 2}{H_L + \lambda} + \frac{G_R^ 2}{H_R + \lambda} - \frac{ (G_L + G_R)^ 2}{H_L+H_R + \lambda}] + \gamma\end{aligned}\]</span></p><p>Gain is naturally an error decrease measure, it is quiet similar to information gain <span class="math inline">\(IG = H( D) - [H( D| left) + H(D|right) ]\)</span> . The only difference is it replace the entropy with a best error transformed from the objective function.</p><p>According to the definition, higher gain bring more error decrease. Thus, we can use gain as a criterion to decide the best split. The specific splitting strategy is just like the MSE in Regression Tree, the only difference is the the criterion.</p><p><img src="/2023/02/27/decision-tree/7.png"></p><p><strong>Other Improvement</strong></p><ol type="1"><li>XGB can do both row and column subsampling, which means it can drop some feature just like RF</li><li>XGB support linear regression model as basic estimator. (Dart is also supported)</li><li>XGB support customized loss function, as long as it is second derivative</li><li>XGB sort the samples respectively by each feature and save the ranking as blocks. This makes in best-split-find process can be done parallelly across different feature.</li></ol><h4 id="pruning-strategy-4">3.3.2 Pruning Strategy</h4><p>XGB support both pre-pruning and post-pruning. For pre-pruning, XGB can set a threshold for gain when splitting. For post-pruning, XGB can set a threshold, that if a subtree contains no child node that has a greater gain than this threshold, it will be pruned.</p><p>Like GDBT, more common overfitting control method in XGB is:</p><ul><li>Raw and column subsampling rate</li><li>shrinkage parameter $$</li><li>Structural hyper parameters like max_depth, min_leaf_sample_size</li></ul><h4 id="missing-value-processing-4">3.3.3 Missing Value Processing</h4><p>As mentioned above, XGBoosting support linear estimator. When the booster is gblinear, XGB can not deal with missing value. It would fill all missing value with 0.</p><p>When the booster is gbtree or dart, the XGB use same missing value processing strategy like GDBT.</p><h4 id="feature-importance-2">3.3.4 Feature Importance</h4><p><strong>Gain</strong></p><p>The Gain method is similar to the mean impurity decrease method in Random Forest. The different is, instead of impurity, the gain method use the gain to calculate the decrease.</p><p>Let T denote a collections of spliter using <span class="math inline">\(X_ i\)</span> in the <span class="math inline">\(j+1^{th}\)</span> tree model: <span class="math display">\[Gain(X_i, DT_{j+1}) = \sum_{t \in T} Gain(t)\]</span> suppose there are n DTs: <span class="math display">\[Gain(X_i) = \frac{ 1}{n} \sum _j^n Gain(X_i,DT_j)\]</span> We can than use this gain as a feature importance. We can also normalize the feature importance so its scale is 1: <span class="math display">\[\hat{Gain(X_i)} = \frac{Gain(X_i)}{\sum_i Gain(X_i)}\]</span></p><p><strong>Weight</strong></p><p>The frequency of <span class="math inline">\(X_i\)</span> being used as a spliter in the whole ensemble model. Note that when we make column subsampling, we should consider carefully whether to use weight as a feature importance, as sample important feature may just happened to be sampled only a few times.</p><p><strong>Cover</strong></p><p>For a feature <span class="math inline">\(X_i\)</span>, let <span class="math inline">\(R_t\)</span> denote the number of sample under a node t that split using <span class="math inline">\(X_i\)</span>. Let T denote a collection of all nodes in the ensemble models that uses <span class="math inline">\(X_i\)</span> as spliter, <span class="math inline">\(n_T\)</span> denote the length of T(how many times the feature is used). <span class="math display">\[cover = \frac{\sum_{t \in T}R_t}{n_T}\]</span> <strong>Difference of these 3 methods:</strong></p><ul><li>weight gives higher FI to numerical features.</li><li>Gain give higer FI to unique features. If we want to applied, drop features that is unique or close to unique like personal ID</li><li>cover gives higher FI to categorical features.</li></ul><h3 id="other-ensemble-models">3.4 Other Ensemble Models</h3><p><a href>ongoing</a></p>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Decisions Tree</tag>
      
      <tag>Ensemble Model</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linear Regression and Generalized Linear Model</title>
    <link href="/2023/02/23/linear-regression/"/>
    <url>/2023/02/23/linear-regression/</url>
    
    <content type="html"><![CDATA[<h1 id="linear-regression-and-generalized-linear-model">Linear Regression and Generalized Linear Model</h1><h2 id="linear-regression">1. Linear Regression</h2><h3 id="hypothesis-space-and-basic-assumption">1.1 Hypothesis Space and Basic Assumption</h3><p>The Linear Regression is a statistical model used to discover the correlation between an output variable Y and a set of input variable X. Basically, a linear regression model should follow such <strong>hypothesis space</strong>: <span class="math display">\[Y = \beta _1X+\beta_0 +\epsilon\]</span> where <span class="math inline">\(\beta_1\)</span> is a vector consists of parameters for each feature. <span class="math inline">\(\beta_0\)</span> is a constant, <span class="math inline">\(\epsilon\)</span> represents the random error of the observation.</p><p>To modeling the data with a linear regression model, five assumption should be fulfilled:</p><p><strong>1. Linearity</strong></p><p>Linearity Assumption requires there to has a linear mapping relationship between Y and X. That is, the real mapping relationship should be consistent with the hypothesis space. Otherwise, there would be bais in the model.</p><p><strong>2. <span class="math inline">\(\epsilon\)</span> Independency</strong></p><p>The linear model assume the <span class="math inline">\(\epsilon\)</span> is a completely randomized error. That is, a sample's <span class="math inline">\(\epsilon\)</span> shoud not be correlated with other samples. If this assumption cannot be satisfied, we say there exists autocorrelation in the data. Autocorrelation would make the model underestimate the randomized error and increase bias. It usually happened when there exists time-sequence influence among the samples.</p><p><strong>3. X Independency</strong></p><p>The features should be independent to each other, otherwise we said there exists multicollinearity. Multicollinearity would increase the variance of the model and cause overfitting</p><p><strong>4.<span class="math inline">\(\epsilon\)</span> Homoskedasticity</strong></p><p>The variance of <span class="math inline">\(\epsilon\)</span> should be same on different scale of Y. Otherwise, we said there is a Heteroskedasticity. Heteroskedasticity.increase the variance of the model and make the learned parameter unstable.</p><p><strong>5. <span class="math inline">\(\epsilon\)</span> Normality</strong></p><p><span class="math inline">\(\epsilon \sim N(0,\sigma^2)\)</span> . If the randomzied error are not normally distributed, the data points with high error would make the learned parameter unstable and increase the variances of the model. Notice that when <span class="math inline">\(\epsilon \sim N(0,\sigma^2)\)</span>, and <span class="math inline">\(Y = \beta _1X+\beta_0 +\epsilon\)</span>, we would have <span class="math inline">\(Y \sim N(\beta _1X+\beta_0,\sigma^2)\)</span>. This means (Y|X) should follows a normal distribution. Notice that this is not equivalent to <span class="math inline">\(Y \sim N(\mu, \sigma^2)\)</span>. We do not need to do normality test on Y before the learning.</p><p>The detection techniques and solutions for the violation of the above assumptions can be found in <a href="http://zhengyuanyang.com/2022/09/22/evaluation-for-regression/">this article</a></p><p>Linear Regression is:</p><ul><li>A supervised learning model</li><li>A parameter learning model</li><li>A non-probability learning model</li><li>A discriminative model</li></ul><h3 id="training-process-of-linear-regression">1.2 Training Process of Linear Regression</h3><p>With the hypothesis space given:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs pseudocode">Initialize the weight<br>for each sample:<br>calculate output<br>Calculate overall error based on loss function<br>while the error &lt; threshold:  #or current error &gt; previous error <br>for each sample and error:<br>update w_new = w_old + a*w&#x27; #with a optimization algorithm<br>return to step2<br><br></code></pre></td></tr></table></figure><p><strong>Optimizer</strong></p><p>In the training process, the weight is updated n times where n is the sample size. <span class="math inline">\(\alpha\)</span> is the a hyper-parameter called learning rate. It control the step size of optimal searching process.</p><p>For regression models, most optimizers are based on gradient descending. In the pseudocode above, <span class="math inline">\(\omega&#39;\)</span> represents the partial derivatives of the parameters: <span class="math display">\[\omega&#39; = \frac{\partial L}{\partial \theta} = \frac{\partial L}{\partial Y}\cdot\frac{\partial Y}{\partial \theta}\]</span> For more on optimizer for linear regression, refer to <a href>this article</a></p><p><strong>Loss function:</strong></p><p>Common loss functions for linear regression includes MSE, MAE and RMSE. For more on loss functions, refer to<a href="http://zhengyuanyang.com/2022/09/22/loss-function/#numerical-output">this article</a></p><h2 id="regularization-lasso-regression-and-ridge-regression">2. Regularization: Lasso Regression and Ridge Regression</h2><p>A common problem in machine learning is the overfitting. For the details of overfitting, refer to <a href="http://zhengyuanyang.com/2022/09/19/overfitting/">this article</a></p><p>To solve overfitting, we can apply the structural Risk Minimization. We would add a penalty term regarding to the complexity of the model to the loss function. For details, refer to <a href="http://zhengyuanyang.com/2022/09/12/Principle/#structural-risk-minimization">this article</a></p><p>The application of SRM on linear regression create Lasso and Ridge Regression. The Lasso and Ridge Regression have same training process like linear regression, but it add a regularization term of <span class="math inline">\(\omega\)</span> in the loss function to penalize overfitting:</p><p><strong>Lasso Regression</strong> <span class="math display">\[J = MSE + \lambda ||\omega||_1\]</span> <strong>Ridge Regression</strong> <span class="math display">\[J = MSE + \lambda ||\omega||_2^2\]</span> where <span class="math inline">\(\lambda\)</span> is a penalty parameter decides the extent of penalty. The regularization term is a L-P norm of the parameter vector. It is a generalized distance concept. Refer to the <a href="http://zhengyuanyang.com/2022/10/08/distance/#minkowski-distance">Minkowski Distance</a></p><p>The basic function of Lasso Regression and Ridge Regression are both minimizing the parameters(complexity), but they have the following differences:</p><ul><li>The Lasso regression can reduce <span class="math inline">\(\omega_i\)</span> to 0, thus can be used for feature selection.</li><li>The Ridge mostly only reduce the parameter close to 0, thus is not very suitable for feature selection. We can still try it when the features are scaled though.</li></ul><h2 id="logistic-regression">3. Logistic Regression</h2><h3 id="basic-assumption">3.1 Basic Assumption</h3><p>Logistics Regression is a model for classification. Unlike normal linear model, which assume the output is continuous and normally distributed, the logistic regression assume the output Y follows a Bernoulli Distribution.</p><p>The hypothesis space if logistic regression:</p><p>Let Z denote the linear transformation contributed by the a linear regression model: <span class="math display">\[Z = \beta _1X+\beta_0 +\epsilon\]</span> Use an activation function sigmoid to convert such a transformation into a probability <span class="math inline">\(P(Y|X)\)</span>. For activation functions, refer to <a href>this article</a>. The decision boundary is thus: <span class="math display">\[P(Y=1|X=x) = sigmoid(Z)\]</span> Decide the classification of Y by <span class="math display">\[y_{pred}  = argmax \{P(Y=1|X=x) , P(Y=0|X=x)\}\]</span> The Logistic Regression model is a discriminative probably model, as it directly modeling on <span class="math inline">\(P(X|Y)\)</span></p><h3 id="training">3.2 Training</h3><p><strong>Loss Function</strong></p><p>The common loss function for logistic regression is <strong>Log Loss</strong>. Refer to <a href="http://zhengyuanyang.com/2022/09/22/loss-function/#log-losscross-entropy-loss">this article</a> for details.</p><p><strong>Optimizer</strong></p><p>The optimizer for logistic regression is the same as the linear regression. Notice that now: <span class="math display">\[\omega&#39; = \frac{\partial L}{\partial \theta} = \frac{\partial L}{\partial A}\cdot\frac{\partial A}{\partial Z}\cdot \frac{\partial Z}{\partial \theta}\]</span></p><h2 id="generalized-linear-model">4. Generalized Linear Model</h2><p>From the previous section we can find that the most important different between linear regression and logistic regression is that the output variable Y follows different distribution type. In fact, linear regression and logistic regression both belongs to Generalized Linear Model(GLM)</p><h3 id="exponential-family-distribution">4.1 Exponential Family Distribution</h3><p>Exponential Family Distribution refer to those distributions taht can be reformed as a exponential format: <span class="math display">\[p(x|\lambda)  = \frac{1}{Z(\lambda)}h(x)exp\{ \phi(\lambda)^TT(X)\}\]</span> where:</p><ul><li><span class="math inline">\(\lambda\)</span> is the original parameter of the distribution, it can be a constant or a vector(e.g. <span class="math inline">\(N(\lambda_1 = \mu, \lambda_2 = \sigma^2)\)</span>)</li><li>h(x) is a function called basic measure</li><li>T(X) is a function called sufficient statistic</li><li><span class="math inline">\(\phi(\lambda)\)</span> is a function of <span class="math inline">\(\lambda\)</span>, we can can let <span class="math inline">\(\theta = \phi(\lambda)\)</span>. In such form, we call <span class="math inline">\(\theta\)</span> the <strong>canonical parameter</strong>, it can be a constanr or a vector, with same size of <span class="math inline">\(\lambda\)</span></li><li><span class="math inline">\(Z(\lambda)\)</span> is the partition function of this probability <span class="math inline">\(Z(\lambda) = ln\int h(x)exp\{ \phi(\lambda)^TT(X)\}\)</span></li></ul><p>By moving <span class="math inline">\(h(x), Z(\lambda)\)</span> in to the exponential, let <span class="math inline">\(\theta = \phi(\lambda)\)</span>, we can obtain that all Exponential Family Distribution can be expressed in such format: <span class="math display">\[p(x|\theta) = \{ \theta^T T(x) + S(x) - A(\theta)\}\]</span> In this form, we <span class="math inline">\(A(\theta)\)</span> the cumulant function</p><p>For example, the PDF of a Bernoulli function: <span class="math display">\[p(x|p) = \lambda^x(1-\lambda)^{1-x} = exp\{ln[\lambda^x(1-\lambda)^{1-x}]\} = exp\{xln(\frac{\lambda}{1-\lambda})+ln(1-\lambda)\}\]</span> where:</p><ul><li>T(x) = x</li><li><span class="math inline">\(\theta\)</span> = <span class="math inline">\(ln(\frac{\lambda}{1-\lambda})\)</span></li><li><span class="math inline">\(A(\theta) = -ln(1-\lambda) = ln(1+e^\theta)\)</span></li><li><span class="math inline">\(S(x) = 0\)</span></li></ul><p>Common Exponential Family Distribution includes gaussian distribution, exponential distribution, gamma distribution, bernoulli distribution, binomial distribution, multinomial distribution, poisson distribution and so on.</p><p><strong>Natural EFD</strong></p><p>The Natural EFD is a subset of the EFD. If T(x) = x, we call this distribution a natural EFD. For example, Gaussian Distribution, Bernoulli Distribution, Exponential Distribution, Poisson Distribution, Gamma Distribution and Multinomial Distribution are all natural EFD.</p><p><strong>Statistics of EFD</strong></p><p>One properties of Exponential Family Distribution is that: <span class="math display">\[\frac{dA}{d\theta} = \frac{d}{d\theta}\{ln \int h(x) exp\{\theta^TT(x)\}\} = E[T(x)]\]</span> When T(x) is given, we can calculate E[x] according to the properties of Expectation. For natural EFD, which T(x) = x, <span class="math inline">\(E(T(x)) = E[x]\)</span>. Use the Bernoulli Distribution as an example: <span class="math display">\[\frac{dA}{d\theta} = \frac{d }{d\theta}ln(1+e^\theta) = \frac{1}{1+e^{-\theta}} = p\]</span> Samely, we can deduce that <span class="math inline">\(\frac{d^2A}{d\theta^2} = Var[T(x)]\)</span></p><p>This indicate a very important attribute of EFD: the canonical parameter <span class="math inline">\(\theta\)</span> has a mapping relationship with the moments(<span class="math inline">\(\mu, \sigma^2, skewness,...\)</span>) of the distribution. We know that the <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> of a EFD is decided by its original parameter <span class="math inline">\(\lambda\)</span>, and we know <span class="math inline">\(\theta = \phi (\lambda)\)</span>, so there exists are reversible function <span class="math inline">\(\theta = \psi(\mu)\)</span>(if the size of <span class="math inline">\(\theta\)</span> is 1)</p><p><strong>Canonical Form of EFD</strong></p><p>Some EFD has 2 original parameters and thus has two canonical parameters <span class="math inline">\(\theta = [\theta_1,\theta_2]\)</span>.</p><p>For example, the cumulant function of a gaussian distribution is: <span class="math display">\[A(\theta) = -\frac{\theta_1^2}{4 \theta_2} - \frac{1}{2}ln(-2\theta_2)\]</span> In such cases, some time we would find <span class="math inline">\(\mu,\sigma^2\)</span> are tangled with <span class="math inline">\(\theta_1, \theta_2\)</span> that <span class="math inline">\([\theta_1,\theta_2]= f(\mu,\sigma^2)\)</span>. This make it difficult to calculate <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span>. Thus, we would reconstruct the nature EFD as: <span class="math display">\[p(y|\theta_\mu) = exp \{ \frac{y\theta_\mu - b(\theta_\mu)}{a(\theta_v)} + c(y,\theta_v)\}\]</span> Both <span class="math inline">\(\theta_\mu\)</span> and <span class="math inline">\(\theta_v\)</span> are a function of <span class="math inline">\((\theta_1,\theta_2)\)</span>, and we would need to ensure: <span class="math display">\[A(\theta) = \frac{b(\theta_{\mu})}{a(\theta_v)}\]</span> Also, we would ensure <span class="math inline">\(\theta_{\mu}\)</span> would only be a function decided by <span class="math inline">\(\mu\)</span>. <span class="math inline">\(\theta_{mu} = \psi(\mu)\)</span> is <strong>stilled called canonical paraparameter</strong> and it control the location of the EFD. The <span class="math inline">\(\theta_v\)</span> is called a <strong>dispersion parameter</strong>, it is basically a scaler to control the shape of the EFD and is associated with the variance of the distribution. The <span class="math inline">\(a(\theta_v)\)</span> is called a dispersion function. For EFD that only has one original parameter, which means the distribution does not has a <span class="math inline">\(\theta_2\)</span>, the dispersion function is simply <span class="math inline">\(a(\theta_v) = 1\)</span>, as the distribution does not has a second parameters to control shape.</p><p>Now we can revise the calculation of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span>: <span class="math display">\[\mu = \frac{\partial A}{\partial \theta_\mu} = b&#39;(\theta_\mu)\]</span></p><p><span class="math display">\[\sigma^2 = \frac{\partial^2 A}{\partial \theta_\mu^2} = a(\theta_v)b&#39;&#39;(\theta_\mu)\]</span></p><h3 id="generalized-linear-model-1">4.2 Generalized Linear Model</h3><p>A Generalized Linear Model is a model used to predict output Y with input X. Thus, a good idea is to estimate <span class="math inline">\(E[Y|X]\)</span>. For example, the prediction of a linear regression is <span class="math inline">\(E[Y|X]\)</span>, the prediction of a logistic regression is <span class="math inline">\(E[Y|X] = 0*P(Y=0|X) + 1*P(Y=1|X) = P(Y=1|X)\)</span>, and the prediction muti-category regression(softmax regression) is <span class="math inline">\(E[\vec{Y}|X,\vec{\pi}=\vec{p}] = [P(Y=0|X),P(Y=1|X),P(Y=k|X)]\)</span>.</p><p>Now we nake the following assumption:</p><ol type="1"><li>The variable (Y|X) follows a natural EFD. Usually this can be guarantee by knowing Y follows a EFD.</li><li>The canonical parameter of the EFD <span class="math inline">\(\theta_\mu\)</span>, in a Bayesian context, follows a normal distribution, and thus can be learned from a linear hypothesis space</li></ol><p>To achieve the expectation, a GLM consists of:</p><ul><li>A linear predictor <span class="math inline">\(\eta = \beta X+b\)</span></li><li>A function that can transfer the linear prediction <span class="math inline">\(\eta\)</span> to the expectation <span class="math inline">\(\mu\)</span> we want. <span class="math inline">\(\mu = g^{-1}(\eta)\)</span></li></ul><p>We know that Y does not necessary follows a normal distribution and can be difficult to learned from with a linear hypothesis space. Thus we add a non-linear function to enhance the non-linearity of the hypothesis space. This function is called <strong>Activation Function</strong>, and the inverse of it <span class="math inline">\(\eta = g( \mu)\)</span> is called a joing function.</p><p><img src="/2023/02/23/linear-regression/2.png"></p><p>We know from the assumption that <span class="math inline">\(\theta\)</span> is normally distributed and can be learned directly from the linear predictor. Thus, a good idea is to let <span class="math inline">\(g = \psi^{-1}\)</span>, so we have: <span class="math display">\[\eta = g(\mu) = \psi^{-1}(\mu) = \theta_\mu\]</span> In this case, the <span class="math inline">\(\eta\)</span> we are learning is exactly <span class="math inline">\(\theta_\mu\)</span>, which can be learned with a linear hypothesis space.</p><p>Hence, we we want to build a GLM to predict a variable <span class="math inline">\(Y|X \sim natural \ EFD(\theta)\)</span></p><ol type="1"><li>Figure out the distribution type of Y, and rewrite it into a canonical form of EFD</li><li>Read <span class="math inline">\(\theta_\mu = \phi(\mu), b(\theta_\mu)\)</span> out of the format and write down <span class="math inline">\(\mu = \psi(\theta_\mu)\)</span></li><li>Select the activation function as <span class="math inline">\(\psi^{-1}(\eta)\)</span></li><li>Train the model</li></ol><p>The GLM enable us to generalize linear regression to many other cases, as long as Y|X follows a EFD. Common application includes Logistic Regression(Bernoulli Distribution), Softmax Regression(multi-category distribution), Polynomial Regression and so on. When Y|X follows a gaussian distribution, the activation function is just <span class="math inline">\(\mu = \eta\)</span>, and the model is reduced to a simply linear regression, which Y can be directly learned from a linear hypothesis space.</p><p>Some common joint functions and and activation functions are listed as follows:</p><p><img src="/2023/02/23/linear-regression/3.png"></p>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linear Regression</tag>
      
      <tag>Generalized Linear Model</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>A/B Testing: Experiment Sensitivity Improvement</title>
    <link href="/2023/02/18/sensitivity-improvement/"/>
    <url>/2023/02/18/sensitivity-improvement/</url>
    
    <content type="html"><![CDATA[<h1 id="ab-testing-experiment-sensitivity-improvement">A/B Testing: Experiment Sensitivity Improvement</h1><h2 id="about-sensitivity-improvement">1. About Sensitivity Improvement</h2><p>If you expected there to be an significance effect but the results turn out to be insignificant, there's a chance that the sensitivity of the experiment is not big enough. In other word, given current sample size, your experiment can not perform enough statistical power as your demand. The sensitivity is usually measured by the Minimum Detectable E Effect(MDE).</p><p>Notice that when MDE is smaller than the PSB, even if we further improve the sensitivity by reduce mde, the mean of difference on metrics would still be lower than the PSB(any valid significant difference <span class="math inline">\(\mu\)</span> should has <span class="math inline">\(\mu &lt; mde\)</span>, while <span class="math inline">\(mde &lt; psb\)</span>). In such cases, the results have no chance to be practically significant. In other word, <strong>we only need improve sensitivity when:</strong> <span class="math display">\[MDE &gt; PSB\]</span> Recall the formula of MDE: <span class="math display">\[MDE = (t_{\frac{1-\alpha}{2}} + t_ {1-\beta})\sqrt{\frac{\sigma_1^2}{n_ 1} + \frac{\sigma_2^2}{n_ 2}}\]</span> The formula suggests that if we want to maintain the desired statistical power, there are only two way to improve sensitivity:</p><p><strong>More Sample</strong></p><p>To collect more sample, we can:</p><ul><li>bring in more data by acquiring additional units</li><li>increase test duration</li><li>randomized on finer grain to increase sample size</li></ul><p><strong>Less Varaince</strong></p><p>According to the equation of <span class="math inline">\(n&#39;, \delta, \beta\)</span>, we know that if the variance of the population is lower, we would need less sample to detect identical effect, given desired fixed statistical power, that is, the real-time statistical power would get higher while the sampe size remains the same.</p><p>In real application this can be difficult to implement extra sample acquisition. Thus, for this article, we focusing on techniques that can lowering the variance to improve experiment Sensitivity</p><h2 id="variance-estimation">2. Variance Estimation</h2><p>Before lowering variance, first we need to make sure the variance of the parameters is estimated from the sample correctly. If the variance is incorrectly estimated, the p value and the confidence interval we calculated are both wrong.</p><p><strong>When Randomized Unit <span class="math inline">\(\ne\)</span> Analysis Unit</strong></p><p>As discussed in <a href="http://zhengyuanyang.com/2022/03/25/Hypothesis-Testing/#zt-test">this article</a>, when estimating the standard error, we would usually assume the variable for the results of single units are i.i.d. However, such assumption are not always fulfilled. For example, there might exist network effects. We need to expel these effects before variance estimation</p><p>For some metrics like CTR, the unit is a pageview instead of a user. As multiple view can came from the same user <span class="math inline">\(B_1,B_2,..B_n\)</span> may also be correlated. In thus case, we need to rewrite the metrics by aggregating it into a user level: <span class="math display">\[V[CTR] = V[\frac{user \ avg \ click }{user\ avg \ PV}] = V[\frac{\bar{X}}{\bar{Y}}]\]</span></p><p><strong>When Using Relevant Difference(<span class="math inline">\(\Delta \%\)</span>)</strong></p><p>Sometimes we would define the PSV using a relevant percentage instead of absolute value, like a 1% growth on GMV. In such case, we might want to judge the practical significance based on the confidence interval of a relevant of of the different between treatment and conrol group, let Y denote the measure on a single unit, <span class="math inline">\(\tilde{Y}\)</span> denote the paramter to test on (mean or ratio), <span class="math inline">\(\Delta\)</span> denote the difference of parameter between treatment and control group <span class="math display">\[\Delta\% = \frac{\Delta}{\tilde{Y_C}} = \frac{\tilde{Y_T}-\tilde{Y_C}}{\tilde{Y_C}}\]</span> Thus, suppose <span class="math inline">\(\tilde{Y}\)</span> is a mean parameter, when calculating the variance of <span class="math inline">\(\Delta\)</span>: <span class="math display">\[V[ \Delta] = V[\tilde{Y_T}-\tilde{Y_C}] = V[\tilde{Y_T}] + V[\tilde{Y_c}] = \frac{V[Y_T]}{n_1} + \frac{V[Y_C]}{n_2}\]</span> However, when calculating the variance of <span class="math inline">\(\Delta\%\)</span>: <span class="math display">\[V[\Delta \%] = V[\frac{\tilde{Y_T}-\tilde{Y_C}}{\tilde{Y_C}}] = V[\frac{\tilde{Y_T}}{\tilde{Y_C}}]\]</span> According to CTL, <span class="math inline">\(\tilde{Y_T},\tilde{Y_C }\)</span> both follow normal distribution. Thus, the variance of <span class="math inline">\(\frac{\tilde{Y_T}}{\tilde{Y_C}}\)</span> can be calculated from: <span class="math display">\[V[\Delta \%] =  \frac{1}{\tilde{Y_C}^2}V[ \tilde{Y_T}] + \frac{\tilde{Y_T}^2}{\tilde{Y_C}^4} V[\tilde{Y_C}] + 2\frac{\tilde{Y_T}}{\tilde{Y_C}^3} Cov[\tilde{Y_T},\tilde{Y_C}]\]</span> In a RCL, since treatment are randomly assigned, <span class="math inline">\(\tilde{Y_T}\)</span> and <span class="math inline">\(\tilde{Y_C}\)</span> are independent, thus <span class="math inline">\(Cov[\tilde{Y_T},\tilde{Y_C}] = 0\)</span>. Hence: <span class="math display">\[V[\Delta \%] =  \frac{1}{\tilde{Y_C}^2}V[ \tilde{Y_T}] + \frac{\tilde{Y_T}^2}{\tilde{Y_C}^4} V[\tilde{Y_C}]\]</span></p><h2 id="metrics-manipulation">3. Metrics Manipulation</h2><p>We can lower the variance by replace or transform the metrics</p><p><strong>Metrics Replacement</strong></p><p>Creating metrics with a smaller variance while capturing similar information. For example, the number of searches has a higher variance than the number of searchers; GMV has higher variance than order amount. The selection of lower-variance metrics should be validated in a real business environment.</p><p><strong>Metrics Transformation</strong></p><p>Transform the metrics so that it has lower variance. Common transformation includes discretization, log tranformation, and power transformation.</p><h2 id="construct-unbiased-estimator">4. Construct Unbiased Estimator</h2><h3 id="stratification">4.1 Stratification</h3><p>In stratification, you divide the sampling region into strata, sample within each stratum separately, and then combine results from individual strata for the overall estimate by weighted sum, which usually has smaller variance than estimating without stratification.</p><p>Let <span class="math inline">\(Y\)</span> be the value of the metrics(mean or ratio): <span class="math display">\[V[Y] = V[Y]_{within}+V[Y]_{between} = \sum_kp_k\sigma^2_k + \sum_kp_k(\bar{y}_k-\bar{y})^2\]</span> where <span class="math inline">\(p_k\)</span> is the weight of the strata</p><p>Let <span class="math inline">\(Y_k\)</span> be the within variance of the <span class="math inline">\(k^{th}\)</span> strata <span class="math display">\[V[\hat{Y}] = \sum_kp_kV[Y_k] = V[Y_{within}] &lt; V[Y]\]</span></p><p>The stratification eliminate the between-group variance, thus can reduce the overall variance. However, the covariate, which is the strata, must be discrete.</p><p><strong>Post-Stratification</strong></p><p>While stratification is most commonly conducted during the sampling phase (at runtime), it is usually expensive to implement at large scale. Therefore, most applications use post-stratification, which applies stratification retrospectively during the analysis phase.</p><p>For post-stratification, we still conducted a randomized sampling to decided treatment group and control group. When analyzing the results, we put the units from treatment group and control group into buckets according to their strata variable with a ratio of 1:1. This saves the costs of doing multiple randomization, but it may waste a small portion of samples.</p><h3 id="regression-covariant-control">4.2 Regression Covariant Control</h3><p>The covariate control method finds a continuous covariate that correlated with metric. The core idea is to make a regression relationship between the original metrics and its covariates. The covariates explain part of information of the original metric and contribute part of its variance. Thus, by taking out the part contributed by the covariate, the overall variance is lowered.</p><p>To some extent, the basic ideal of stratification and covariate control is the same. The difference is that covariate control method use regression to interpret the relationship between Y and its covariate.</p><p>Let X be the covariate. X should be constructed like the way Y does(mean or ratio). Construct new variable <span class="math inline">\(\hat{Y} = Y -\theta X\)</span>, if <span class="math inline">\(E[X_T] = E[X_c]\)</span>, then <span class="math inline">\(E[\hat{Y_T}-\hat{Y_C}] = E[Y_T-Y_c]\)</span>, the new variable is a unbiased estimation of the original metrics. It can be proven that <span class="math inline">\(V[\hat{Y}] &lt; V[Y]\)</span> if <span class="math inline">\(Cov[X,Y] &gt; 0\)</span>.</p><p><strong>Choosing Covariate</strong></p><p>One thing to notice when choosing the covariate is that the assumption <span class="math inline">\(E[X_T] = E[X_c]\)</span> should always be satisfied. Therefore, covariate should have no causal relationship with the experiment. If <span class="math inline">\(X \to T\)</span>, then the covariate is a confounder, then the covariate have different distribution on the treatment and control group,<span class="math inline">\(E[X_T] \ne E[X_C]\)</span>. On the other side, if <span class="math inline">\(T \to X\)</span>, then the X would be effected by the treatment, <span class="math inline">\(E[X_T] \ne E[X_C]\)</span> after the experiment is conducted. Either way, the estimation is biased. Thus, when choosing covariates:</p><ul><li>The covariates should be pre-experiment metrics or invariant metrics that won't be affected by the experiment</li><li>The covariates should be independent to the assigning of treatment and control group</li></ul><p>A common application it to apply the same metric before the experiment as the covariate, as the pre-experiment metric is usually highly correlated with post-experiment metric. This method is usually called <strong>Controlled-experiment Using Pre-Experiment Data(CUPED)</strong></p><p>Nevertheless, we can still used other covariate. Some thesis point out we can find such covariates through machine learning methods. These methods includes CUPAC(Control Using Predictions As Covariates) and MLRATE(machine learning regression-adjusted treatment effect estimator)</p><p><strong>Controlled-experiment Using Pre-Experiment Data(CUPED)</strong></p><p>Let X denots the value of the metric we want to test before the experiment, Y denots the value after the experiment. For an A/B test, we expect that <span class="math inline">\(E[X_T] = E[X_C], E[Y_T] \ne E[Y_C]\)</span>. Now construct two variables: <span class="math inline">\(\hat{Y_T} = Y_T - \theta X_T\)</span>, $  = Y_C - X_C$, where <span class="math inline">\(\theta\)</span> is a hyperparameter we can adjust. We know that: <span class="math display">\[E[ \hat{Y_T}-\hat{Y_C}] = E[(Y_T - \theta X_T) - (Y_C - \theta X_C)] = E[Y_T]-E[Y_C]\]</span> thus, estimate the treatment effect on CUPED variable is equivalent to estimate the effect on original metrics. Meanwhile: <span class="math display">\[V[\hat{Y_T}-\hat{Y_C}] =V [(Y_T - \theta X_T) - (Y_C - \theta X_C)] = V[Y_T- Y_C] +\theta^2V[X_T-X_C]-2\theta Cov[(Y_T-Y_C),(X_T-X_C)]\]</span> we can than regard <span class="math inline">\(V[\hat{Y_T}-\hat{Y_C}]\)</span> as a quadratic function of <span class="math inline">\(\theta\)</span>, where: <span class="math display">\[\Delta = 4Cov[(Y_T-Y_C),(X_T-X_C)]^2 - 4V[(Y_T - Y_ C)]V[X_T-X_C]\]</span> as we know: <span class="math display">\[Cov[X_1,X_2] \le \sqrt{V[X_1]V[X_2]}\]</span> we have that <span class="math inline">\(\Delta \ge 0\)</span>, thus: <span class="math display">\[V[\hat{Y_T}-\hat{Y_C}] \in [0,V[Y_T- Y_C]] \qquad \theta \ge 0\]</span> we have minimum <span class="math inline">\(V[\hat{Y_T}-\hat{Y_C}]\)</span> when <span class="math inline">\(\theta =\frac{Cov[(Y_T-Y_C),(X_T-X_C)]}{V[X_T-X_C]}\)</span></p><h3 id="variance-weighted-estimators">4.3 Variance-Weighted Estimators</h3><p><a href="ongoing"></a></p><p>see the thesis:</p><p>Variance-Weighted Estimators to Improve Sensitivity in Online Experiments</p><p>KEVIN LIOU, Facebook SEAN J. TAYLOR, Lyft</p>]]></content>
    
    
    
    <tags>
      
      <tag>A/B Testing</tag>
      
      <tag>Sensitivity Improvement</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Probability Density Estimation</title>
    <link href="/2023/02/13/prob-dense-estimation/"/>
    <url>/2023/02/13/prob-dense-estimation/</url>
    
    <content type="html"><![CDATA[<h1 id="probability-density-estimation">Probability Density Estimation</h1><h2 id="about-probability-density-estimation">1. About Probability Density Estimation</h2><p>Probability Density Estimation(PDE) is a techniques used for estimating probability distribution of a variable through samples. Specifically, it can be categorized as:</p><ul><li>Parameter Estimation: Assuming the variable follows a type of distribution and estimating the parameter of that distribution through samples</li><li>Non-parameter Estimation: Trying to obtain the distribution of the variables directly from the data without any distribution type assumptions</li></ul><p>For PDE, we usually assume that all samples are i.i.d</p><h2 id="parameter-estimation">2. Parameter Estimation</h2><h3 id="maximum-likelihood-estimation">2.1 Maximum Likelihood Estimation</h3><p>Consider the Bayesian's Law: <span class="math display">\[P(X=x|Y=y) = \frac{P(Y=y|X=x)P(X=x)}{P(Y=y)}\]</span> One <strong>critical</strong> thing to remember is the way to interpret the parameter <span class="math inline">\(\theta\)</span>.</p><p>According to Bayesian, the parameter <span class="math inline">\(\theta\)</span> itself sollows some kinds of distribution. Thus, the likelihood and posterior distribution in bayesian's law is exchangeable, <span class="math inline">\(\theta\)</span> is nothing but a random variable just like X and Y in equation 1. In such scenarios, likelihood and probability is the same thing <span class="math display">\[P(\theta|E) = \frac{P(E|\theta)P(\theta)}{P(E)}\]</span> where E represents the evidence variable.</p><p>However, according to frequentist, <span class="math inline">\(\theta\)</span> is a unknown constant values, and it does not have a distribution. Thus, there's <span class="math inline">\(\theta\)</span> cannot be put into the Bayesian's Law like a random variable. In this scenario, likelihood and probability is not one thing. Probability is for random variable, while likelihood is for parameter, which is a constant values. According to frequentist, given the i.i.d. assumption: <span class="math display">\[L(\theta| D) = P(D|\theta) = \prod_iP(d_i=x_i|\theta)\]</span> where D represents the results of all samples.</p><p>The MLE is a product of the frequentist. Thus, in MLE, to find best <span class="math inline">\(\theta\)</span>, we just need to find the <span class="math inline">\(\hat{\theta}\)</span> that maximize the likelihood function. For calculation, do average log operation on both sides: <span class="math display">\[\iota(\theta|D) = \frac{1}{n}lnL(\theta| D)\]</span></p><p><span class="math display">\[\hat{\theta} = argmax \ \iota(\theta|D)\]</span></p><p>The best parameter <span class="math inline">\(\theta\)</span> can thus be obtained calculating the zero point of the derivation function of the <span class="math inline">\(\iota(\theta|D)\)</span></p><h3 id="bayesian-estimation">2.2 Bayesian Estimation</h3><p>The Bayesian is the other side of view on probability. According to format (2): <span class="math display">\[P(\theta|E) = \frac{P(E|\theta)P(\theta)}{P(E)} = \frac{P(E|\Theta = \theta)P(\Theta = \theta)}{\sum_i P(E|\Theta =\theta_i)P(\Theta=\theta_i)}\]</span> In this equation:</p><ul><li><span class="math inline">\(P(\theta)\)</span> follows the prior distribution, which is decided by prior knowledge regardless of the sample information</li><li><span class="math inline">\(P(E|\Theta=\theta_i)\)</span> is the likelihood function decide by the knowledge of the mechanism between <span class="math inline">\(\theta\)</span> and <span class="math inline">\(E\)</span> regardless of sample information</li></ul><p>The bayesian estimation is a process of updating the prior knowledge through sample information. The updated posterior distribution can be the new prior distribution. In real application, the accurate understanding of the likelihood function can be difficult, besides, the calculation can also be quiet difficult.</p><h3 id="maximum-a-posterior-estimation">2.3 Maximum A Posterior Estimation</h3><p>The Maximum A Posterior Estimation is an approximation of the bayesian estimation. it assume the marginal distribution <span class="math inline">\(P(E)\)</span> is independent of the parameter distribution <span class="math inline">\(P(\theta)\)</span>. It calculate the best <span class="math inline">\(\theta\)</span> by maximize the posterior probability <span class="math inline">\(P(\theta|E)\)</span> <span class="math display">\[\hat{\theta} = argmax \ f(D|\theta)g(\theta) = \prod_iP(d_i=x_i|\theta)P(\theta)\]</span> Such assumption make the calculation of the posterior probability much more easier. The MAP allows to add the prior distribution of <span class="math inline">\(\theta\)</span> into the estimation. It is a simpler version of Bayesian Estimation.</p><h2 id="non-parameter-estimation">3. Non-parameter Estimation</h2><h3 id="histogram">3.1 Histogram</h3><h3 id="kernel-density-estimation">3.2 Kernel Density Estimation</h3><h3 id="parzen-windows-k_n-neighbors">3.2 Parzen Windows &amp; <span class="math inline">\(K_n\)</span> Neighbors</h3>]]></content>
    
    
    <categories>
      
      <category>Probability &amp; Statistics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Parameter Estimation</tag>
      
      <tag>Probability Density Estimation</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Analytics: Models and Framework</title>
    <link href="/2023/02/05/analytics-framework/"/>
    <url>/2023/02/05/analytics-framework/</url>
    
    <content type="html"><![CDATA[<h1 id="analytics-models-and-framework">Analytics: Models and Framework</h1><p>Data analysts build models to perform various analytics jobs. Each type of models are designed to figure out a certain problem. For specification, in this article, we call the general categories of these models as <strong>Analytics Model</strong> and specific example of the model as <strong>Analysis Framework</strong>.</p><h2 id="user-model">1. User Model</h2><h2 id="event-model">2. Event Model</h2><h2 id="funnel-analysis-model">3. Funnel Analysis Model</h2><h3 id="aarrr">3.1 AARRR</h3><p>The AARRR is a framework for product analysis. It consists of 5 ordinal objectives:</p><ol type="1"><li>Acquisition: Let user be aware of the product<br></li><li>Activation: Let user do what we want them to do</li><li>Retention: Keep user active, engaged and exhibiting sticky behavior</li><li>Revenue: generate businesses outcome. Usually money but can vary from the business model</li><li>Referral: Let user spread the product</li></ol><h3 id="sean-elliss-startup-growth-pyramid">3.2 Sean Ellisâ€™s Startup growth Pyramid</h3><p>The Startup growth Pyramid is a framework for starting up and enlarge business. It segment the business lifecycle into threee stages and discuss what we should do in each stage:</p><p><img src="/2023/02/05/analytics-framework/1.png"></p><p>The judgement on moving from the current stage to the next is based on user satisfaction. If 40% of people (or more) say theyâ€™d be very disappointed to lose the service, youâ€™ve found a fit, and now itâ€™s time to scale</p><h3 id="other-framework-and-comparison-table">3.3 Other Framework and Comparison Table</h3><p>Other Frameworks include Lean Analytics Stage, Maurya Lean Canvas and Lean Startup</p><p>The comparison of them are listed below</p><p><img src="/2023/02/05/analytics-framework/2.png"></p><h2 id="heatmap-model">4. HeatMap Model</h2><h2 id="customized-retention-analysis">5. Customized Retention Analysis</h2><h2 id="stickiness-analysis">6. Stickiness Analysis</h2><h2 id="full-behavior-route-analysis">7. Full Behavior Route Analysis</h2><h2 id="user-segmentation">8. User Segmentation</h2>]]></content>
    
    
    <categories>
      
      <category>A/B Testing &amp; Case Interview</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Analytics Model</tag>
      
      <tag>Analysis Framework</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Case Interview: Measure Success</title>
    <link href="/2023/01/31/measure-success/"/>
    <url>/2023/01/31/measure-success/</url>
    
    <content type="html"><![CDATA[<h1 id="case-interview-measure-success">Case Interview: Measure Success</h1><h2 id="analytics-framework">1. Analytics Framework</h2><p>For metrics selection, the funnel anaysis model is the most frequently applied type of frameworks. In this case, we commonly applied the AARRR framework to allocate proper metrics. For details on models and frameworks, refer to <a href>ongoing</a></p><p>The according metrics of each objectives under various business models are listed below:</p><table><thead><tr class="header"><th>Business Model</th><th>Acquisition</th><th>Activation</th><th>retention</th><th>Revenue</th><th>referral</th></tr></thead><tbody><tr class="odd"><td>E-commerce</td><td></td><td></td><td></td><td></td><td></td></tr><tr class="even"><td>SaaS</td><td></td><td></td><td></td><td></td><td></td></tr><tr class="odd"><td>Free Mobile APP</td><td></td><td></td><td></td><td></td><td></td></tr><tr class="even"><td>Media Site</td><td></td><td></td><td></td><td></td><td></td></tr><tr class="odd"><td>UGC</td><td></td><td></td><td></td><td></td><td></td></tr><tr class="even"><td>TS Marketplace</td><td></td><td></td><td></td><td></td><td></td></tr><tr class="odd"><td>For all</td><td>DAU/MAU, DNU by platform</td><td></td><td></td><td></td><td></td></tr></tbody></table><h2 id="criterion-for-metrcis-selection">2. Criterion for Metrcis Selection</h2><h2 id="procedure-of-measure-success-problem">3. Procedure of Measure Success Problem</h2><p>This type of cases usually come as "find a metric to measure the extent.....(how good a new feature/strategy/product is)". IT evaluates one's ability to design a measure according to certain business objectives</p><ol type="1"><li><p><strong>Clarify the objective</strong>:</p><p>Ask questions about:</p><ul><li>How this feature works?</li><li>who is it for</li></ul></li><li><p><strong>Confirm the business objective</strong></p><p>according to the explanation from the interviewer, conclude the objective of the feature to the following aspects:</p><ul><li>Acquisition: bring in more user, help them discover the product</li><li>Activation: make user taking actions we want them to, keep users engaged</li><li>conversion and retention: keep user continuing to use the product, convert them from free-user to paid user</li><li>Money: make revenue from users</li></ul></li><li><p><strong>Select metrics according to objective</strong></p><table><thead><tr class="header"><th>Objective</th><th></th></tr></thead><tbody><tr class="odd"><td>Acquisition</td><td>DAU/MAU, DNU by platform,</td></tr><tr class="even"><td>Activation</td><td>ACU/PCU, PV/UV, time spending, interaction behaviour</td></tr><tr class="odd"><td>Conversion and Retention</td><td>CTR,CO, pay rate, 7 day retention rate/churn rate</td></tr><tr class="even"><td>Money</td><td>ROI,GMV, AOV, ACV, ARPU/ARPPU</td></tr><tr class="odd"><td></td><td></td></tr></tbody></table><ul><li><p>Select 1 main success metric, this metric should be directly relevant to the business objective</p></li><li><p>Select 1 second success metrics, this metrics should be a supplement. It improve the completeness of the logic relationship of the key metrics and business goal. To fing the second goal, consider the following questions:</p><ul><li>Can the change of key metrics be caused by factors other than the feature?</li><li>Is the key metric equivalent to the business goal? Is there any intermediate process</li><li>If the key metrics changes on a group level, should we have same changes on single user level?</li></ul><p>Alternatively, we can do a funnel analysis to find the secondary success metrics</p></li><li><p>Select 1 guardrail metric, this metric is critical to the main goal of the whole product. The feature should not have significant negative effect on it</p></li></ul></li><li><p><strong>structure the answer</strong></p><p>if the guardrail metric shift towards a negative direction, the feature is probably not success.</p><p>Otherwise, if the key success metric and the second both shift towards a positive direction, the feature is successful.</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>A/B Testing &amp; Case Interview</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Measure Success</tag>
      
      <tag>Case</tag>
      
      <tag>Metric Selection</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>A/B Testing: Results Analysis</title>
    <link href="/2023/01/24/results-analysis/"/>
    <url>/2023/01/24/results-analysis/</url>
    
    <content type="html"><![CDATA[<h1 id="ab-testing-results-analysis">A/B Testing: Results Analysis</h1><h2 id="sanity-check">1. Sanity Check</h2><p>After we obtained the results data and before we make any analysis, we want to do some sanity check to ensure the experiment are running correctly and any differences are caused by the treatment instead of any other changes. A Sanity check refer to the simple process to verify the resutls by checking the consistency of those metrcis that are not supposed to be affected by the treatment(Invariant Metrics). There are two types of invariant metrics:</p><ol type="1"><li>Trust-related guardrail metrics: Metrics related to the business process but should not be effected by the treatment or should be configured the same for both group(e.g search amount for a watch-time duration test, cache hit rate, Telemetry fidelity)</li><li>Organiztional guradrail metrics: metrics that are important to the organization and expected to be an invariant for many experiments.(e. g. latency, GMV, PV)</li></ol><p>If these sanity checks fail, there is probably a problem with the underlying experiment design, infrastructure, or data processing.</p><h2 id="judgment-on-significance">2. Judgment on Significance</h2><h3 id="judgement-on-statistical-significance">2.1 Judgement on Statistical Significance</h3><p>The judgement on statistical significance should be based on p value calculated from the test results.</p><p><img src="/2023/01/24/results-analysis/1.png"></p><p>Note that the MDE is the real-time sensitivity estimated from the experiment results</p><h3 id="judgement-on-practical-significance">2.2 Judgement on Practical Significance</h3><p><strong>Confidence Interval</strong></p><p>From a frequentist probability theory POV, the confidence interval is a section describe how often the true value of a parameter would lie in the section given a significance level. In a testing we regard the observed difference as an estimation of the mean of the true difference, following a normal distribution. We can then calculated the CI through: <span class="math display">\[CI = [\mu- Z_{\frac{\alpha}{2}}*\sigma_{SE},\  \mu+ Z_{\frac{\alpha}{2}}*\sigma_{SE}]\]</span> where:</p><ul><li><span class="math inline">\(\mu\)</span> is the observed difference</li><li><span class="math inline">\(\sigma_{SE}\)</span> is the standard error estimated from the standard deviation from the sample</li></ul><p><strong>Practical Significance</strong></p><p>When checking on CI, the following situations may occur:</p><p><img src="/2023/01/24/results-analysis/2.png"></p><ol type="1"><li>The result is not statistically significant. It is also clear that there is no practical significance. This suggests that the change does not do much. You may either decide to iterate or abandon this idea.</li><li>The result is statistically and practically significant, which suggests lauching the feature.</li><li>The result is statistically significant but not practically significant. In this case, you are confident about the magnitude of change, but that magnitude may not be sufficient to outweigh other factors such as cost and thrive you business goal.</li><li>The boundry of the CI does exceed the PSB but it happens in both way. This ethier suggest the treatment effect is very unstable or the experiment is underpowered. Consider running a follow-up test with more units, providing greater statistical power</li><li>The result is likely practically significant but not statistically significant.There is a good chance that there is no impact at all. From a measurement perspective, the best recommendation would be to repeat this test but with greater power to gain more precision in the result.</li><li>The result is statistically significant, and likely practically significant. There is still a chance that the impact is not sufficient from a business perspective. While we still should consider repeating the test with more power, choosing to launch is a reasonable decision from a launch/no-launch decision</li></ol><p>From the analysis above we found only scenarios 2 and 6 could be considered launchable. Whether we should stick to scenario 2 depends on our preference. In most business practice we would presue scenario 2.</p><h3 id="judge-of-significance-in-multiple-testing-scenarios">2.3 Judge of Significance in Multiple Testing Scenarios</h3><h4 id="multiple-testing-scenarios">2.3.1 Multiple Testing Scenarios</h4><p><strong>Multiple Variants</strong></p><p>There are more then two variants. For example, suppose we want to examine the imporvement on CTR by changing the color of a button, but we have three alternative treatments. In this case we creat three tests. For each test, let <span class="math inline">\(\alpha = 0.05\)</span>, then: <span class="math display">\[P(no\ false  \ positive  \ in \ all \ three \ tests) = (1-\alpha)^3 = 0.857\]</span> The type I error of the <strong>overall experiment hypothesis</strong>, which is "changing color improves CTR" is high.</p><p><strong>Multiple Metrics</strong></p><p>Suppose we have only one 1 treatment but 100 metrics to test. Set <span class="math inline">\(\alpha = 0.05\)</span>, same as the multiple variants scenario, around 5 metrics would fall into the pitfall of type I error, which means they will be false positive, and this could mislead.</p><h4 id="corrections-of-significance-level-under-multiple-testing">2.3.2 Corrections of Significance Level under Multiple Testing</h4><p><strong>Bonferroni Correction</strong></p><p>Bonferroni Correction is a simple way to lower type I error by having smaller <span class="math inline">\(\alpha\)</span> for each test: <span class="math display">\[\alpha_i  = \frac{\alpha}{n}\]</span> where n is the number of tests(number of variants, number of metrics, or the product of them)</p><p>The bonferroni correction is easy to apply, but it is also to conservative. It increase the difficulty to reject the null hypothesis in each test.</p><p><strong>Control False Discovery Rate</strong></p><p>Define FDR as: <span class="math display">\[FDR  = E[\frac{n_{FP}}{n_{rej}}]\]</span> FDR tells in all tests that we judge as significant, how many of them are false positive. For example, suppose we have 1000 testing and reject 200 of them, and the FDR = 0.05, then we can expect around 10 metrics to be false positive. If we take this results as acceptable, we can move on to analysis. Otherwise, we should consider lower <span class="math inline">\(\alpha\)</span></p><p>In real application, the judgement of false positive can be difficult to detect. Thus, controlling PDR can be sometimes unaccessible.</p><p><strong>Benjaminiand Hochberg's Method</strong></p><p>Suppose we have n tests, each has a p value as a result. First, we can rank the list in a ascending order by P values. Then we correct the p value with: <span class="math display">\[q_i = p_i * \frac{n}{k}\]</span> Where k is the ranking of the <span class="math inline">\(i^{th}\)</span> test</p><table><thead><tr class="header"><th>T</th><th>P value</th><th>Q</th></tr></thead><tbody><tr class="odd"><td>T2</td><td>0.001</td><td>0.005</td></tr><tr class="even"><td>T5</td><td>0.003</td><td>0.0075</td></tr><tr class="odd"><td>T1</td><td>0.12</td><td>0.4</td></tr><tr class="even"><td>T3</td><td>0.045</td><td>0.54</td></tr><tr class="odd"><td>T4</td><td>0.048</td><td>0.048</td></tr></tbody></table><p>we then comepare the Q value with <span class="math inline">\(\alpha\)</span> to judge the significance.</p><p>This process can lower the overall type I error. However, we may also notice that through this method, alternatives with greater p value can pass while alternatives with smaller p values can fail, which sometimes may mislead.</p><p><strong>Two-step Rule-of-thumb</strong></p><p>Another method when dealing with multiple metrics is to segment the metrics in serval tiers, such as:</p><ul><li>First-order metrics: those you expect to be impacted by the experiment</li><li>Second-order metrics: those potentially to be impacted</li><li>Third-order metrics: those unlikely to be impacted</li></ul><p>and apply tiered significance levels to each group (e.g., 0.05, 0.01 and 0.001 respectively).</p><h2 id="validity-checktruthworthyness-analysis">3. Validity Check(Truthworthyness Analysis)</h2><p>The Validity Check is a process is a procedure to find out if the results are truthworthy. It is usually an analysis to rule out some potential effects that could threat the validity. Such analysis can be decomposed on two dimensions:</p><p><strong>Internal Threats/External Treats</strong>:</p><ul><li>internal: Making the testing results itself is incorrect without attempting to generalize the results to other population or time periods</li><li>external: Making the conclusion incorrect when trying to generalize it to other population or time periods</li></ul><p><strong>Overestimate/Underestimate</strong></p><ul><li>Overestimate: The testing results is significant but the real effect or generalized effect is not so</li><li>Underestimate: The testing results is insignificant but the real effect or generalized effect is not so</li></ul><h3 id="threats-to-internal-validity">3.1 Threats to Internal Validity</h3><h4 id="violation-of-sutva">3.1.1 Violation of SUTVA</h4><p>A random controlled experiment requires Stable Unit Treatment Value Assumption (SUTVA). It states that experiment units (e.g., users) do not interfere with one another. In some cases, this assumption could be violated</p><p><strong>Network Effect</strong></p><p>A feature might spillover to other user through the social network of treatment unit. This usually undermine the difference between control and treatment group. If the treatment is applied to all users, the real effect can be bigger. To deal with this kind of effects, we can implemented social network clustering and select randomized unit for control and treatment group in different clusters. There is also a method called ego-network randomization</p><p><strong>Two-sided marketplaces:</strong> For two-sided platform like auctions platform or Uber. The treatment on the unit might affect other unit through the "other-side". For example, lowering prices for riders in Treatment group make them more attractive to drivers, and there would be less drivers available for control group. In this case, the GMV difference between two groups are overestimated. The real differences between when the treatment applied to all users might be lower. To deal with this kind of effects, we can make geo-based or time-based isolation on treatment and control group</p><p><strong>Shared Resources:</strong> If the Treatment leaks memory and causes processes to slow down due to garbage collection and possibly swapping of resources to disk, all variants suffer.This could lead to underestimating of real effect. For example, the Treatment crashed the machine in certain scenarios. Those crashes also took down users who were in Control, so the delta on key metrics was not different â€”both populations suffered similarly.</p><h4 id="violation-of-intention-to-treatment">3.1.2 Violation of Intention-to-Treatment</h4><p>In an online experiment, the treatment group shoud be those whose treatment are "delivered" rather than "fulfilled". Our measuring is based on the offer, or intention to treatment, not whether it was actually applied. Analyzing only those who participate, results in selection bias and commonly overstates the Treatment effect. For example, if our treatment is "adding an subscribe button" and our target is to increase revenue, then our treatment group should be those who are demonstrated with the button instead of those who actually click the button. We can add a second success metric "CTR" to track the effectiveness of the button though.</p><h4 id="sample-ratio-mismatch"><strong>3.1.3 Sample Ratio Mismatch</strong></h4><p>If the ratio of users (or any randomization unit) between the variants is not close to the designed ratio, the experiment suffers from a Sample Ratio Mismatch (SRM). A SRM indicates the decision of exposing a unit to the treatment is not independent to treatment effect. This could lead to either overestimate or underestimate.</p><p>For example, the ratio designed for treatment and controlled group is one-to-one. Suppose the decision is randomly obtained through a coin flip, then the expected sample ratio should be 0.5. We can regard the sample ratio as a parameter and test it if through t distribution. If the p value is samll enough, we can make the claim that there's some problem with the coin that lead to a sample ratio mismatch.</p><p>The cause of the SMR, in most cases, is for the developer to worry. Debugging SRMs requires the developer to examine their randomization strategy during experiment configuration.</p><h3 id="threats-to-external-validity">3.2 Threats to External Validity</h3><h4 id="primacy-and-novelty-effect">3.2.1 Primacy and Novelty Effect</h4><p><strong>Primacy Effect:</strong> When a change is introduced, users may need time to adopt, as they are <em>primed</em> in the old feature, that is, used to the way it works. In other word, users are reluctant to changes. This effect would diminish over time, but if we made the conclusions while the primacy effect still exists, than we may underestimate the real treatment effect</p><p><strong>Novelty Effect:</strong> Being opposite to the primacy effect, the novelty effect refer to that a new feature might be attractive for the users at first, but not so interesting after the users try them for the first time. This effect would diminish over time, but if we made the conclusions while the novelty effect still exists, than we may overestimate the real treatment effect</p><p>Solutions for these two effects:</p><ul><li>ensure the experiment run long enough so that these two effects vanish over time</li><li>rule out these effects by constraining the target group in only first-day user</li><li>compare the CATE of first- time and existing user to see if the effects do exist</li></ul><p><img src="/2023/01/24/results-analysis/3.png"></p><h2 id="segmentation-difference-outlier">4. Segmentation Difference &amp; Outlier</h2><h3 id="segmentation-analysis">4.1 Segmentation Analysis</h3><p>Analyzing a metric by different segments can provide interesting insights and lead to discoveries. Things we can do about segmentation includes:</p><p><strong>Segmental View on Metrics</strong>: Inspecting the segmentation metrics values before and after the experiment. If the metrics are distinctly different for a group, then this group may have a strong difference comparing to other groups. We can dive in to the problem and make debugging or take this group out of the target group</p><p><strong>Segmental View on Effect</strong>: Inspecting the CATE of the segmentations. For any strongly distinct CATE, we can doubt that the treatment takes effect with a special mechanism on this particular group. We can dive in to the problem and make debugging or take this group out of the target group</p><p><strong>Migration Among Segmentations</strong> :</p><p>Suppose we want to examine the improvement of CTR of users brought by a treatment. We find the CTR of treatment and control group are respectively 25 v.s. 20 for Chinese users, and 15 v.s. 10 for non-Chinese users .Can we know make the conclusion that the treatment is effective?</p><p>The answer is no. We need to first ensure there are no unit migrations among segmentation. If the assignment of the feature make some chinese decide to change their language options and turn them to non-Chinese users. The overall treatment effect may go down</p><p>This indicates that analysis on segmentations can mislead due to migration. The segmentation should be done based on the status of units before the experiment. Otherwise, migrations among groups can happen</p><h3 id="outlier-influence">4.2 Outlier Influence</h3><p>The existence of outliers can drastically change the conclusion regarding significance.</p><p><img src="/2023/01/24/results-analysis/4.png"></p><p>Thus, it is necessary to eliminate the outliers in the samples before making conclusions. For example, a user who has 10000 pageviews is probability a robot. For outlier detection techniques, refer to <a href="http://zhengyuanyang.com/2022/10/07/outlier/">this article</a>.</p><h2 id="improvement-of-experiment-sensitivity">5. Improvement of Experiment Sensitivity</h2><h3 id="sensitivity-improvement">5.1 Sensitivity Improvement</h3><p>For sensitivity improvement methods, refer to <a href="http://zhengyuanyang.com/2023/02/18/sensitivity-improvement/">this article</a></p>]]></content>
    
    
    <categories>
      
      <category>A/B Testing &amp; Case Interview</category>
      
    </categories>
    
    
    <tags>
      
      <tag>A/B Testing</tag>
      
      <tag>Results Analysis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Probability Graphical Model</title>
    <link href="/2023/01/10/PGM/"/>
    <url>/2023/01/10/PGM/</url>
    
    <content type="html"><![CDATA[<h1 id="probability-graphical-model-basis">Probability Graphical Model: Basis</h1><h2 id="about-probability-graphical-model">1. About Probability Graphical Model</h2><p>The Probability Graphical Models are a series model that express the dependency/ joint distribution in a graphic way(edges and nodes). The apllications of PGM includes:</p><ul><li>PGM representation: present the correlation or causality relationship among variables in a graphical way</li><li>PGM learning: including parameter learning and structural learning</li><li>PGM inference: reasoning the correlation/causality structure of variables</li></ul><h2 id="terminology">2. Terminology</h2><p><strong>Factor</strong></p><p>A factor is a funtion of one or more variables <span class="math display">\[\phi(X_1,..X_n)\]</span> where <span class="math inline">\(\phi: Val(X_1,...X_n) \to R\)</span></p><p><strong>Scope</strong></p><p>The list of variables included in a factor: <span class="math inline">\(\{ X_1, ...X_n\}\)</span></p><p><strong>Factor Product</strong></p><p><img src="/2023/01/10/PGM/1.png"></p><p><strong>Factor Marginalization</strong></p><p><img src="/2023/01/10/PGM/2.png"></p><p><strong>Factor Reduction(Conditioning)</strong></p><p><img src="/2023/01/10/PGM/3.png"></p><h2 id="categories-of-pgm">3. Categories of PGM</h2><h3 id="bayesian-network">2.1 Bayesian Network</h3><p>The Bayesian Network use directed acyclic graph to represent the causally of random variables.</p><p>Each node <span class="math inline">\(X_i\)</span> has a contional probability distribution(CPD) <span class="math inline">\(P(X_i|Par(X_i))\)</span></p><p>where par returns all parent nodes of <span class="math inline">\(Xi\)</span> in the graph. If <span class="math inline">\(X_i\)</span>does not has parent nodes, then replace the CPD with <span class="math inline">\(P(X_i)\)</span></p><p>A BN represent the JPD of all variables included, which can be calculated from: <span class="math display">\[P(X_1,X_2,...X_n) = \prod_i^n P(X_i|par(X_i))\]</span> We can say a joint probability P factorize over a graph G, if P can be represented by the above equation.</p><p>The Naive Bayes Model is an example of the simplistic BN. In naive bayes, assumptions are made that each feature are caused by a categorical variables, while the features remain independent to each other</p><p><img src="/2023/01/10/PGM/4.png"></p><h3 id="markov-random-field">2.2 Markov Random Field</h3><h4 id="markov-chain-and-transition-probability-matrix">2.2.1 Markov Chain and <strong>Transition Probability Matrix</strong></h4><p><strong>Markov Chain</strong></p><p>For a series of random variable <span class="math inline">\(X_1,X_2,..X_n\)</span> we call this series a markov chain if: <span class="math display">\[P(X_m+1 = i_m+1| X_0=i_0,X_1=i_1,...X_m=i_m)  = P(X_m+1 = i_m+1|X_m=i_m)\]</span> In other word, the state of <span class="math inline">\(X_m+1\)</span> depends only on the previous one state, which is the value of <span class="math inline">\(X_m\)</span></p><p>In many applications, we can use a markov chain to model the transition of states over time for a single random variable.</p><p><strong>Transition Matrix</strong></p><p>For any moment n, if the probability <span class="math inline">\(P(X_{n+1} = j|X_n =i)\)</span> is independent to n, then we can this probability the one-step transition probability between state i and j, denoted as <span class="math inline">\(p_{i,j}\)</span></p><p>For all possible states of the random variable, the one-step probabilities between each two combinations consist the transition matrix. The sum of each row would be 1. Note that the sum of each column does not necessarily have to be 1.</p><h4 id="random-field-and-clique">2.2.2 Random Field and Clique</h4><p>In a random field, each position(node) represent a random variable and can be assigned with a value.</p><p>In a graph, a clique is a subset of nodes that each two nodes in this subset are connected</p><p>If adding any nodes to a clique would no longer make that subset a clique, we call sucn a clique a maximal clique</p><h4 id="markov-property-of-random-field">2.2.3 Markov property of Random Field</h4><p><strong>Global Markov Assumption</strong></p><p>For any two subsets of nodes S and T(S and T are not overlapped), given a separating subset C(a subset of nodes that all paths between S and T need to travel through this subset), if S and T are conditionally independent on C(<span class="math inline">\(P(S|T,C) = P(S| C)\)</span>)</p><p><strong>Local Markov Assumption</strong></p><p>Let V be any nodes in the graph, W be the adjacent nodes of V, O be other nodes in the graph. Given random variables <span class="math inline">\(X_W\)</span>, <span class="math inline">\(X_V\)</span> and <span class="math inline">\(X_O\)</span> are conditonally independent.</p><p><strong>Pairwise Markov Assumption</strong></p><p>Let U and V be two disconnected nodes in a graph, O be other nodes. Given random variables <span class="math inline">\(X_O\)</span>, <span class="math inline">\(X_U\)</span> and <span class="math inline">\(X_V\)</span> are conditionally independent</p><p>If any of the three assumption are satisfied in a random field, we call such a random field a Markov Random Field(MRF)</p><p>The Global Markov Assumption is the strongest one, the satisfaction of it implies the other two assumption</p><h4 id="potential-function-of-mrf">2.2.4 Potential Function of MRF</h4><p><strong>Potential Function</strong></p><p>The potential function is defined on a clique in a MRF. It measure the correlation among the variables in the clique. the potenial function should be a non-negative function, and it should have greater value where one feels two variable correlated. For example, we can define a potential function that have maximum when to factors are equal.</p><p>Usually, we would define the potential function as a exponential function. <span class="math display">\[\phi_Q(X_Q) = e^{-H_Q(X_Q)}\]</span> Where <span class="math inline">\(H_Q\)</span> is called an energy function. The reason to adopt an exponential potential is that we can add the energy functions together when we multiply a potential function with another.</p><p>The usually format of a energy function: <span class="math display">\[H_Q(X_Q) = \sum_{u,v\in Q,u \ne v} \alpha_{u,v}t(x_u,x_v) + \sum_{v \in Q}\beta_{u,v}s(x_v)\]</span> where:</p><ul><li><span class="math inline">\(\alpha, \beta\)</span> are hyper parameters</li><li>t, s are functions to measure the energy between two nodes and asingle nodes. The could be just <span class="math inline">\(t(x_u,x_v) = x_ux_v, \ s(x_v)= x_v\)</span></li></ul><p><strong>Joint Probability</strong></p><p>The joint probability a MRF represent can be calculated from a series of product of potential functions: <span class="math display">\[P(X_1,X_2,...X_n) = \frac{1}{Z} \prod_{Q \in C} \phi_Q(X_Q)\]</span> Where Z is a scaling constant to ensure the probability is legal. In real application, the calculation of Z is very difficult because the number of cliques can be huge. We can instead calculate P based on maximal cliques: <span class="math display">\[P(X_1,X_2,...X_n) = \frac{1}{Z^*} \prod_{Q \in C^*} \phi_Q(X_Q)\]</span> where <span class="math inline">\(C^*\)</span> is the collections of all maximal clique in the MRF or subset of MRF</p>]]></content>
    
    
    <categories>
      
      <category>Probability &amp; Statistics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Probability Graph Models</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Case Interview: Metrics Diagnosis</title>
    <link href="/2022/12/25/case-metrics-diagnosis/"/>
    <url>/2022/12/25/case-metrics-diagnosis/</url>
    
    <content type="html"><![CDATA[<h1 id="case-interview-metrics-diagnosis">Case Interview: Metrics Diagnosis</h1><h2 id="procedure-of-metrics-shift-diagnosis">1. Procedure of Metrics Shift Diagnosis</h2><p>This type of cases usually come as a important metrics shift(usually towards a negative direction), and the objective the problem is <strong>to find the root cause of the shift and try to fix it</strong></p><p>Framework:</p><ol type="1"><li><p><strong>Clarify the definition of the metric:</strong></p><p>how the metrics is defined. This help you decompose the metrics correctly. This is useful for metric decomposition</p></li><li><p><strong>Check Data:</strong></p><p>Check the log of the data source and data pipeline to make sure the shift is not caused by any bugs, logical errors or outliers</p></li><li><p><strong>Check external factors</strong>:</p><p>Figure out whether the shift is caused by any external factors, including:</p><ul><li><strong>Seasonality:</strong> Is there a seasonal factor in the lifecycle of the product? Like there would be a drastic decline in certain weeks or months of every year. Conduct year-on-year comparison to see such decline always appear in a particular stage in a year</li><li><strong>Industry/market trend</strong>: If there exist a descending trend in the industry? Look to the data of the metrics for the previous few weeks or month. Also see this trend happens on other products or competitors or industry. Figure out the scope of the trend</li><li><strong>Competitors</strong>: If the competitors are doing a sales campaign? Does the loss of the metrics goes to the competitors?</li><li><strong>Special events:</strong> Is there a change of policy? Is there any social events or phenomenon happening that it might have a potential impact on the metrics?</li></ul></li><li><p><strong>Check Internal facotrs</strong>:</p><ol type="1"><li><p><strong>Change or treatment on product:</strong></p><p>is there any change or treatment implemented on the product around the time of the metric's decline? if so, we can do a causal inference to evaluate the effect</p></li><li><p><strong>Decompose the metrics</strong>:</p><p>decompose the metrics in a additive or multiplicative way, for example: order amont = show pv * CTR * C_O, ETA = waiting time for a drive to take the order + time the driver arrive the pick up point + time the rider find the driver</p><p>For each sub-metrics, calculate the changing rate and find out which submetric is the most influential part of the original metrics, focus on these sub- metrics</p></li><li><p><strong>Segment the metric by user demographic channel, or user behavior</strong></p></li></ol><p>Segment the metric by dimensions like region, new/old user, platform, content category. For each subgroup, calculate its contributions ot the decline of the metrics. For example, if you find some facts like 90% of the decline are caused by new user, than you probably would suspect there's a association, like the gui is not friendly to new user</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>A/B Testing &amp; Case Interview</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Case Interview</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Bayesian Model in Machine Learning</title>
    <link href="/2022/12/13/bayesian-model/"/>
    <url>/2022/12/13/bayesian-model/</url>
    
    <content type="html"><![CDATA[<h1 id="bayesian-model-in-machine-learning">Bayesian Model in Machine Learning</h1><h2 id="naive-bayesian">1. Naive Bayesian</h2><h2 id="maximum-entropy-model">2. Maximum Entropy Model</h2><h2 id="bayesian-network">3. Bayesian Network</h2>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Bayesian Model</tag>
      
      <tag>Learning Model</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Sampling Methods for Machine Learning</title>
    <link href="/2022/12/05/sampling/"/>
    <url>/2022/12/05/sampling/</url>
    
    <content type="html"><![CDATA[<h1 id="sampling-and-simulation-for-machine-learning">Sampling and Simulation for Machine Learning</h1><h2 id="about-sampling-and-simulation">1. About Sampling and Simulation</h2><p>The word "Sampling" can be used in different context in ML. From a statistical perspective, Sampling is a process that collect a subset of units from the real sample population. The objective of sampling is to describe characteristics of sampling through statistics on the sample.</p><p>From a computational perspective, however, the word sampling means "Given a probability distribution, generate scenarios to represent the distribution", which means "Sampling", in a computer context, actually means "Simulation". To make a difference, in this article, sampling for a statistical context is called "Sampling", sampling for a computational context is called "simulation".</p><p><strong>For Sampling</strong></p><p>There are various sampling method that have each different application. Sampling methods can be categorized as:</p><ol type="1"><li><strong>Probability Sampling</strong>: Every Single unit in the population has a chance to be selected as a sample point</li><li><strong>Non- Probability Sampling</strong>: Some units in the population does not have a chance to be selected as a sample point</li></ol><p>From another dimension sampling methods can be categorized as:</p><ol type="1"><li><strong>Without Replacement </strong>: when a unit is selected, it would be taken out from the sample population</li><li><strong>With Replacement</strong>: when a unit is selected, it would not be taken out from the sample population</li></ol><p>This article focuses on sampling methods that has application in machine learning.</p><h2 id="sampling-method">2. Sampling Method</h2><h3 id="simple-random-sampling"><strong>2.1 Simple Random Sampling</strong></h3><p>In a random sampling, each unit in the sample population has a equal probability to be selected.</p><p><strong>Pros</strong>:</p><ul><li>Easy to apply</li></ul><p><strong>Cons</strong></p><ul><li>If the selection strategy is by any way associated with statistics through a confounder, a <strong>simpson paradox</strong> would be created</li><li>If the researcher has any interests on the group differences among partition of the sample frame, SRS is not accommodate to it</li></ul><h3 id="systematic-sampling">2.2 Systematic Sampling</h3><p>Systematic Sampling arranges all units in the population into some order, and then selecting elements at regular intervals through that ordered list.</p><p><strong>Pros</strong>:</p><ul><li>It help avoid selection bias. The sample point are uniformly distributed on the section sorted by a particular order</li></ul><p><strong>Cons</strong></p><ul><li>If there exists periodicity, and inner period of the order list is a multiple or factor of the interval we selected, the sample would be unrepresentative</li></ul><h3 id="stratified-sampling">2.3 Stratified Sampling</h3><p>Stratified Sampling separates units into some "Strata" according to some categorical characteristics. The percentage of these strata is called a <strong>sampling fraction</strong>. A subsection of the sample is then assigned to each strata so that the proportion of each category of sample points is still the sample as sampling fraction. In each strata, sample are selected through SRS or systematic sampling.</p><p><strong>Pros</strong>:</p><ul><li>It help avoid selection bias. The proportion of the category remains the same after sampling</li><li>Researcher can apply different sampling method on different subgroup. This allow them to choose most suitable method for a subgroup</li></ul><p><strong>Cons</strong></p><ul><li>Time-consuming and hard to design when a sample point has multiple characteristics</li></ul><p>Stratified Sampling is the basic idea of many over-sampling and under sampling methods.</p><h2 id="monte-carlo-simulation">3. Monte Carlo Simulation</h2><h3 id="inverse-transformation-sampling">3.1 Inverse Transformation Sampling</h3><p>We know that if a randam variable <span class="math inline">\(u = CDF(X)\)</span>, then $u U(0,1) $ (refer to this <a href="http://zhengyuanyang.com/2022/11/04/distribution/#distribution-transformation">article</a>). The Inverse Transformation Sampling generate such a uniformly distributed random variab <span class="math inline">\(u \sim U(0,1)\)</span>. Then the sample value X for each u would be <span class="math display">\[X = CDF^{-1}(u )\]</span> <strong>Pros:</strong> easy to apply</p><p><strong>Cons</strong>: given <span class="math inline">\(P(X)\)</span>,$ CDF^{-1}(X)$ cannot always been easily obtained</p><h2 id="mcmc-sampling">4. MCMC Sampling</h2><p>[WIP]</p><p>â€‹</p><h2 id="oversampling-and-undersampling">5. Oversampling and Undersampling</h2><p>Oversampling and Undersampling are not specific sampling or simulation methods. They are two topics in Data Processing. The objective of these two techniques is to solve the problem of the <strong>Imbalanced Sample</strong></p><p>[WIP]</p>]]></content>
    
    
    <categories>
      
      <category>Probability &amp; Statistics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Sampling</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Basic of Probability Theory for Data Science</title>
    <link href="/2022/12/02/Basic-prob/"/>
    <url>/2022/12/02/Basic-prob/</url>
    
    <content type="html"><![CDATA[<h1 id="basic-of-probability-theory-for-data-science">Basic of Probability Theory for Data Science</h1><h2 id="basic-concepts-for-probability">1. Basic Concepts for Probability</h2><p><strong>Random Experiment</strong>:</p><ul><li>A trail that can have more than one possible outcome.</li><li>The trail should be replicable under fixed conditions</li><li>The outcome of the trail is unpredictable</li></ul><p><strong>Event </strong>: A specific outcome of a random experiment(e.g X=1)</p><p><strong>Fundamental Event</strong>: The minimum grain of event defined according to the objective of the random experiment(Not possible or necessary to split into smaller grain). For example, for a throw of dice, the fundamental events would be face = 1,2,...6.</p><p><strong>Compound Event</strong>: A event consists of multiple fundamental events(e. g, for a throw of dice: Face &lt; 5)</p><p><strong>Sample Space</strong>: A collection consists of all possible fundamental events. (e. g, for two flips of a coin <span class="math inline">\(\Omega = \{(face,face),(back,face),(face,back),(back,back)\}\)</span>)</p><p><strong>Random Variable</strong>: A function that map each sample point <span class="math inline">\(\omega\)</span> in the sample space <span class="math inline">\(\Omega\)</span> into a real number <span class="math inline">\(X = X(\omega)\)</span> . strictly, the definition of a event is a collection <span class="math inline">\(\{\omega | X(\omega = a)\}\)</span>, but in most real implementation, just understand event as an outcome.</p><h2 id="interpretation-of-probability">2. Interpretation of Probability</h2><p>Probability describe how likely a event would happen. In the probability theory, the following axiom are give: <span class="math display">\[0 \le P(A) \le 1\]</span></p><p><span class="math display">\[P(\Omega) = 1\]</span></p><p><span class="math display">\[P( A_1+A_2) = P(A_1)+P(A_ 2)\]</span></p><p>Where <span class="math inline">\(\Omega\)</span> is a definite event(containing all fundamental events), <span class="math inline">\(A_1\)</span> and <span class="math inline">\(A_2\)</span> are exclusive</p><h3 id="classical-model-of-probability">2.1 Classical Model of Probability</h3><p>In Classical Interpretation of probability, two assumptions are considered satisfied:</p><ol type="1"><li>The sample space contains finite fundamental events</li><li>The happening of each fundamental event are equally likely</li></ol><p>Under such assumptions, the probability of an event A can be defined as <span class="math display">\[P(A) = \frac{n_a}{n_s}\]</span> where <span class="math inline">\(n_ s\)</span> is the number of fundamental events in the sample space, and <span class="math inline">\(n_ a\)</span> is the number of fundamental events in event A.</p><p>For most classical probability case, <span class="math inline">\(n_s\)</span> and <span class="math inline">\(n_ a\)</span> can be calculated from permutation and combination: <span class="math display">\[P_n^m = \frac{n! }{(n- m)!}\]</span></p><p><span class="math display">\[C_m^n = \frac{n! }{m!(n- m)!}\]</span></p><h3 id="geometric-model-of-probability">2.2 Geometric Model of Probability</h3><p>Define a geometric measure of a event(e. g length of line segment, area) <span class="math display">\[P(A) = \frac{M(A)}{M(S)}\]</span></p><h3 id="frequency-and-statistical-probability">2.3 Frequency and Statistical Probability</h3><p>Suppose n times of random experiment are conducted, and event A happened m times, the define the frequency of event A as: <span class="math display">\[\omega(A) = \frac{m}{n}\]</span> Then the Statistical Probability of event A is: <span class="math display">\[P(A) = \lim_{n\to\infty}w(A)\]</span> Note that probability is a inner properties of a random variable. Statistical Probability is a mathematic approximation of th real probability</p><h2 id="baisc-theroms-in-probability-theory">3. Baisc Theroms in Probability Theory</h2><p><span class="math display">\[P(A) = 1-P(\bar{A})\]</span></p><p><span class="math display">\[P(A-B) = P(A) - P(A\cap B)\]</span></p><p><span class="math display">\[P(A+B) = P(A) +P(B) - P(A\cap B)\]</span></p><h2 id="conditional-probability-joint-probability-and-independency">4. Conditional Probability, Joint Probability and Independency</h2><h3 id="conditional-probability">4.1 Conditional Probability</h3><p>Let A, B be two events in sample space <span class="math inline">\(\Omega\)</span>, the probability of the A given the condition that B has happened is called conditional probability, denoted as <span class="math inline">\(P(A| B)\)</span></p><p>The sample sapce of <span class="math inline">\(P(A| B)\)</span> is B, not <span class="math inline">\(\Omega\)</span>. Conditioning means "Compression" on the sample spcae. According to the axiom of probability theory, the probability of the whole sample space is 1. Thus, let A be the random variable X = a: <span class="math display">\[\sum_a P(A|B) = 1\]</span> A and B can be two events of a same variable, or each be a event for a separate variable.</p><h3 id="law-of-total-probability">4.2 Law of Total Probability</h3><p>Let <span class="math inline">\(B_1,B_ 2,...,B_n\)</span> be a series of collectively exhaustive events, A be another event: <span class="math display">\[P(A) = \sum_i^n P(B_i)P(A|B_i)\]</span></p><h3 id="joint-probability">4.3 Joint Probability</h3><p>Assume a two-dimension sample space is determined by two random experiment, which means we have two random variables X and Y for a sample space. Let A, B be a certain outcome of variable X and Y respectively, the probability taht events A and B both happen is called the joint probability of A and B, denoted as <span class="math inline">\(P(A, B)\)</span>. The joint probability has the following properties: <span class="math display">\[\sum_x\sum_y P(X=x,Y =y) = 1\]</span> If X and Y are independent: <span class="math display">\[P(X,Y) = P(X)P(Y)\]</span> For such a sample sapce: <span class="math display">\[P(A| B ) = \frac{P(A,B)}{P(B)}\]</span> associated with the Law of Total Probability: <span class="math display">\[P(A)= \sum_i^n P(B_i)P(A|B_i) = \sum_i^n P(A,B_i)\]</span></p><h3 id="bayesian-law">4.4 Bayesian Law</h3><p>Let <span class="math inline">\(A_1,A_ 2,...,A_n\)</span> be a series of collectively exhaustive events, B be another event: <span class="math display">\[P(A_i|B) = \frac{P(A_i)P(B|A_i)}{P(B)}=\frac{P(A_i)P(B|A_i)}{\sum_i^nP(A_i)P(B|A_i)}\]</span> where we call:</p><ul><li><span class="math inline">\(A_i\)</span>: hypothesis event, an event we want to attest its probability distribution through observations on evidence</li><li>B: evidence, an event used to update knowledge on the hypothesis event</li><li><span class="math inline">\(P(A)\)</span>: prior probability, representing the knowledge before the evidence emerge</li><li><span class="math inline">\(P(B|A)\)</span>: likehood, representing the probability of B under events A</li><li><span class="math inline">\(P( A_i|B)\)</span>: posterior probability, representing the updated knowledge after evidence emerge</li></ul><p>Specific examples of bayesian inference can be referred via this <a href="http://zhengyuanyang.com/2022/09/29/bayes-inference/#%E5%B8%B8%E8%A7%81%E9%A2%98%E5%9E%8B%E5%92%8C%E4%BE%8B%E9%A2%98%E8%A7%A3%E6%9E%90">article</a></p><h3 id="independency-of-events">4.5 Independency of Events</h3><p>If the probability of A is not affected by whether event B happen, then A is independent to B. In conditional probability form: <span class="math display">\[P(A) = P(A|B)\]</span></p><p><span class="math display">\[P(A,B) = P(A)P(B)\]</span></p><p>Note that <span class="math inline">\(A \perp \!\!\! \perp B\)</span> and <span class="math inline">\(A\cap B\)</span> cannot be both true</p><h2 id="probability-distribution-probability-density-function">5. Probability Distribution &amp; Probability Density Function</h2><h3 id="discrete-random-variable-and-probability-distribution">5.1 Discrete Random Variable and Probability Distribution</h3><p>If the possible value of a random variable is countable, then it is a discrete random variable. The probability distribution of a discrete random variable X is defined as a <strong>function</strong>: <span class="math display">\[P(X) = P(X=x_k)\]</span> The PDF has the following properties: <span class="math display">\[P(X) \ge 0\]</span></p><p><span class="math display">\[\sum_k P(X) = 1\]</span></p><h3 id="continuous-random-variable-and-probability-density">5.2 Continuous Random Variable and Probability Density</h3><p>If a randome variable can be any value on a range <span class="math inline">\([a , b]\)</span> and there exists a integratable function <span class="math inline">\(f( x)\)</span>, so that: <span class="math display">\[P( a&lt; X \le b  ) = \int_a^ b f(x)dx\]</span> Then X is called a continuous random variable, <span class="math inline">\(f(x )\)</span> is called the probability density function of X.</p><p>For a continuous random variable, the probability of each single sample point would be 0. Instead of an actual probability, the distribution of a continuous random variable is described by the probability density of each data point. The value of <span class="math inline">\(f(x)\)</span> on a specific point represents the probability density of that sample point: <span class="math display">\[f(x= a) = \lim_{\Delta \to \infty } P(a&lt;X \le a+ \Delta  )\]</span></p><h3 id="distribution-type">5.3 Distribution Type</h3><p>For details about distribution type, refer to <a href="http://zhengyuanyang.com/2022/11/04/distribution/">here</a></p><h2 id="expectation-and-variance">6. Expectation and Variance</h2><h3 id="expectation">6.1 Expectation</h3><p>For discrete variable: <span class="math display">\[E[X] = \sum_i^n x_iP(X=x_i)\]</span></p><p>For discrete variable: <span class="math display">\[E[X] = \int_{-\infty}^\infty xf(x)dx\]</span> if E[X] can converge</p><p>Properties of Expectation: <span class="math display">\[E[X+C] = E[X]+C\]</span></p><p><span class="math display">\[E[CX] = CE[X]\]</span></p><p><span class="math display">\[E[X + Y] = E[X]+E[Y] \qquad \forall X, Y\]</span></p><p><span class="math display">\[E[XY] = E[X]E[Y] \qquad if \ X \perp \! \! \perp Y\]</span></p><p><span class="math display">\[E[g(X)] = \sum_i^n g(x_i)P(X=x_i) \qquad or \qquad \int_{-\infty}^\infty g(x)f(x)dx\]</span></p><p><span class="math display">\[E[X|Y=y] = \sum_i^nx_iP(X=x_i|Y=y) \qquad or \qquad \int_{-\infty}^\infty xf(x|y)dx\]</span></p><h3 id="variance">6.2 Variance</h3><p><span class="math display">\[V[X] = E[(X-E[X])^2] = E[ X^ 2]-(E[X])^2\]</span></p><p>Properties of Variance: <span class="math display">\[V[C] = 0\]</span></p><p><span class="math display">\[V[X+C] = V[X]\]</span></p><p><span class="math display">\[V[CX] = C^2V[X]\]</span></p><p><span class="math display">\[V[X\pm Y] = V[X]+V[Y] \pm 2Cov[X, Y]\]</span></p><p><span class="math display">\[V[g(X)] = g&#39;(E[X])^2V[X]\]</span></p><h3 id="covariance">6.3 Covariance</h3><p><span class="math display">\[Cov[X, Y] = E[(X-E[X])(Y- E[Y])] = E[XY]-E[X]E[Y]\]</span></p><p>Covariance is a measure of the joint variability of two random variables, it represent thedegree that two variables variate samely in directions.</p><p>Properties of Variance: <span class="math display">\[Cov[X,Y] = 0 \qquad if \ X \perp \! \! \perp Y\]</span></p><p><span class="math display">\[Cov[X, Y] \le \sqrt {V[X]V[Y]}\]</span></p><p><span class="math display">\[Cov[X,X] = V[X]\]</span></p>]]></content>
    
    
    <categories>
      
      <category>Probability &amp; Statistics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Probability</tag>
      
      <tag>Basic Knowledge</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Structural Causal Model</title>
    <link href="/2022/11/10/structual-causal-model/"/>
    <url>/2022/11/10/structual-causal-model/</url>
    
    <content type="html"><![CDATA[<h1 id="introduction-of-structual-causal-model">Introduction of Structual Causal Model</h1><h2 id="about-structural-causal-model">1. About Structural Causal Model</h2><p>The Structural Causal Model(SCM) is another framework of causal inference. It is a way of describing the relevant features of the world and how they interact with each other. It is widely used in causal relationship digging.</p><h2 id="basis-of-graph-theory">2. Basis of Graph Theory</h2><p><strong>Graph</strong>: a collection of vertices(nodes) and edges. The nodes are connected by edges.</p><p><strong>Adjacent</strong>: If there is a edge between two nodes, then these two nodes are adjacent</p><p><strong>Compete Graph</strong>: A graph is a complete graph if every pair of nodes in it is adjacent</p><p><img src="/2022/11/10/structual-causal-model/1.png" style="zoom:15%;"></p><p><strong>Path</strong>: A sequence of adjacent nodes and their edges between node X and node Y is called a path between X and Y</p><p><strong>Directed/Undirected Graph</strong>: An edge can be directedor undirected. If all edges in a graph is directed, this graph is a directed graph</p><p><strong>Directed Path:</strong> If every edges in a path have same directions, then this path is a directed path</p><p><strong>Parent/Child</strong>: The Start and End nodes of the directed graph</p><p><strong>Ancestor/Descendant</strong>: For a directed path,the ancestor nodes are all nodes before this node, the descendant nodes are all nodes after that node</p><p><strong>Cyclic</strong>: when a directed graph contains a path that its starting node and ending node are the same node, then this path is called a cyclic</p><p><img src="/2022/11/10/structual-causal-model/2.png"></p><p><strong>DAG</strong>: A directed graph with no cyclics in it is called a Directed Acyclic Graph(DAG)</p><h2 id="basic-theory-of-scm">3. Basic Theory of SCM</h2><h3 id="causility">3.1 Causility</h3><p>In SCM, the causality is considered as function with a time order. For two variable X and Y, we call X a <strong>direct cause</strong> of Y if: <span class="math display">\[Y = f(X)\]</span> note that there's a time order for the happenings of X and Y. We cannot regard the cause as <span class="math inline">\(X= f^{-1}(Y)\)</span></p><p>We call X a <strong>indirect cause</strong> of Y is X is a cause of any cause(direct or indirect) of Y.</p><p>In SCM, the relationship of a direct cause X, an outcome Y and their causality f is presented with a parent node. a child node and the directed edge between them.</p><p>In most case, a causility would demonstrate statistical dependence on observations. From a probability aspect, we can also interpret this correlation as a joint probability. For an causal graph: <span class="math display">\[P(X_1,X_2,...X_n) = \prod_i^n P(X_i|par(X_i))\]</span> where <span class="math inline">\(par(X_i)\)</span> is all parent nodes of <span class="math inline">\(X_i\)</span>. If <span class="math inline">\(X_i\)</span> does not have a parent node(Exogenous), then just apply<span class="math inline">\(P(X_i)\)</span></p><h3 id="exogenousendogenous-variable">3.2 Exogenous/Endogenous Variable</h3><p>In SCM, the exogenous variables, usually denoted as U, are variables considered external to the model, and we would not explained how these variables are caused. Oppositely, the endogenous variable,usually denoted as V, are variables considered a descendant of at least one exogenous variable. Exogenous variables have no ancestors, only descendants, while endogenous variables have both ancestors and descendants.</p><p>With such assumption, we can represent the causality of variables with a DAG.</p><p><img src="/2022/11/10/structual-causal-model/3.png"></p><p>In a causality DAG, only when there's a directed path between two variables can we regard as there exists a direct or indirect causality between these two variable.</p><h3 id="intransitive-case">3.3 Intransitive Case</h3><p>As discussed in <a href="http://zhengyuanyang.com/2022/11/07/basic-causal-inference/">this article</a>, we know that correlation does not imply causality. On the opposite, if X causes Y, then in most case X and Y are statistically dependent. Nevertheless, there still exists some extreme case where causality does not show statistical correlation.</p><p>For example, suppose gene A can increase a person's risk of getting a cancer, while there exists another gene B that can depress people's risk of getting cancer. If we observe a sample where each person has both gene A and B, we probably would get the conclusion that both gene are independent to the rate of getting a cancer.</p><p>Another example is the "exclusive or" logic, if the two inputs are both binary variable with equal probability, and the output is a EO calculation of the two binary example, then the output are independent to each of the two inputs from a probability perspective.</p><p>Other cases might be found in real application, we cannot always expect that causality would always generate statistical significant difference. However, we still believe in most cases the significance would be showned, which is the basic assumption for causal inference</p><h3 id="basic-structure-for-causality-graph">3.4 Basic Structure for Causality Graph</h3><h4 id="chain-fork-and-colider">3.4.1 Chain, Fork and Colider</h4><p>The basic causal structure in SCM can be concluded into three types, and each type describes the relationship among three Causal Structure in SCM</p><p><strong>Chain</strong>: For a chain, the first node and the last node are statistically depent, association flows through the directed path, to block the association, we need to conditioning on <span class="math inline">\(X_ 2\)</span></p><p><img src="/2022/11/10/structual-causal-model/4.png"></p><p><strong>Fork</strong>: For a fork, the two descendant nodes are statistically depent, association flows through the path even if its indirected, to block the association, we need to conditioning on <span class="math inline">\(X_ 2\)</span></p><p><img src="/2022/11/10/structual-causal-model/5.png"></p><p><strong>Colider </strong>: For a colider, the two parent nodes are not statistically depent, the intermediate nodes naturally block the association without conditioning</p><p><strong>Conditioning </strong>: conditioning means segment samples into subgroups according to certain values. In a SCM context, if we condition the intermediate variable, we can regard it as a constant in causality:</p><ul><li>For a chain, before conditioning, <span class="math inline">\(X_3 = f(X_2,u_3) = f(g(X_1),u_3)\)</span>, after conditioning, <span class="math inline">\(X_3 = f(u_3)\)</span></li><li>For a fork, before conditioning, <span class="math inline">\(X_3 = f(X_2,u_3), X_1 = f(X_2,u_1)\)</span>, after conditioning, <span class="math inline">\(X_3 = f(u_3), X_1 = f(u_1)\)</span></li><li>For a colider, before conditioning, <span class="math inline">\(X_1 = f(u_1),X_ 3=f(u_ 3)\)</span>, after conditioning on <span class="math inline">\(X_2\)</span> or any of its descendants, although the cause of <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_3\)</span> remains the same, we now have <span class="math inline">\(X_ 2 = f(X_1,X_3) = c\)</span>, so statistical dependence would appear between <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_3\)</span></li></ul><p><img src="/2022/11/10/structual-causal-model/7.png"></p><p><img src="/2022/11/10/structual-causal-model/8.png"></p><h4 id="d-separate">3.4.2 D-separate</h4><p>D-separation is a method used to determine whether two nodes in a causal graph is statistically independent.</p><ul><li><span class="math inline">\(X \ and \ Y \ are \ d-sep \iff X \ and \ Y \ are \ statistically \ indepentdent\)</span></li><li>$X Â d-sep Â Y | Z X Â and Â Y Â are Â statistically Â indepentdentÂ | Z $</li></ul><p>From the previous section we know that in a V structure,</p><ol type="1"><li>If the cenral node are not conditioned, two nodes are blockd by a colider and unblocked(d-connected) by a chain or a fork.</li><li>If the cenral node are conditioned, two nodes are blockd by a chain or a fork and unblocked by a colider.</li></ol><p>If every paths between two nodes X and Y are blocked, we called X and Y d-separated.</p><h2 id="causality-search">4. Causality Search</h2><h3 id="test-on-causality-model">4.1 Test on Causality Model</h3><p>With the definition of the D-separation, we can test the causal model we assume by examine where the statistical independence inferred from the model can be validated through data. For example, for such a causal model:</p><p><img src="/2022/11/10/structual-causal-model/9.png"></p><p>The path <span class="math inline">\(W \to X \to Z_1\)</span> should be blocked if we conditioned on X, which means this model implies: <span class="math inline">\(Z_1 \perp \!\!\! \perp W\ |X\)</span></p><p>We can then regress a linaer model <span class="math inline">\(Z_1 = r_1W + r_2X\)</span>, if <span class="math inline">\(r_ 1\)</span> is obviously greater than 0, we can regard as the assumed causal model is incorrect. We can also apply other statistical method to test correlation.</p><p>Through this kind of ideas, we can infer the true causal model by testing potential causal models based on dataset</p><h3 id="equivalent-class">4.2 Equivalent Class</h3><p>For some causal relationship, we may found two different potential causal graph of it appears to have same statistical independent on data. For example, a fork and a chain have same relationship on statistical independence. When we try to infer the causal relationship, we might found some causility, or we can say the directions of some edgs in the DAG, cannot be decided through data. In this case, we call these potential models with same statistical independence appearance <strong>Equivalent Classes</strong></p><p><img src="/2022/11/10/structual-causal-model/10.png"></p><p>A intuitive method to judge whether two graph are equivalent classes is to check each V-structure in for both graph and earse the direction of the edges if the two V-struture are equivalent. If there are no directions left, then the two classes are equivalent. If there are remaining directed edges or V-structure that are different, then the two graphs are not equivalent.</p>]]></content>
    
    
    <categories>
      
      <category>Causal Inference</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Structural Causal Model</tag>
      
      <tag>Introduction</tag>
      
      <tag>Causal Graph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Potential Outcome Framework</title>
    <link href="/2022/11/07/potential-outcome/"/>
    <url>/2022/11/07/potential-outcome/</url>
    
    <content type="html"><![CDATA[<h1 id="introduction-of-potential-outcome-framework">Introduction of Potential Outcome Framework</h1><h2 id="potential-outcomes-framework">1. Potential Outcomes Framework</h2><p>The Potential Outcomes framework is a series of notation widely used in causal inference.</p><h3 id="conditioning-v.s.-intervening">1.1 Conditioning v.s. Intervening</h3><p>In statistics, conditioning and intervening is two different concepts.</p><p><strong>Conditioning</strong>: Segmenting a dataset into subset bu applying conditions on variables</p><p><strong>Intervening:</strong> Intervene a process with certain treatment, so that every unit is affected by treatment variable</p><p><img src="/2022/11/07/potential-outcome/1.PNG"></p><p>we use the <strong>do</strong> operands the represent that we intervene a process. Let Y donate the outcome statistics of the process, the probability of Y = y under a intervention such that T=t is noted as <span class="math inline">\(P(Y=y|do(T=t))\)</span> or <span class="math inline">\(P(y|do(t))\)</span></p><p>When there exists confounder in the process, the conditional probability does not equal the interventional probability: <span class="math display">\[P (Y|do(t),X) = E_X[P(Y|T=t,X)] \ne  P(Y|T=t,X)\]</span></p><h3 id="potential-outcomes">1.2 Potential Outcomes</h3><p>Suppose we want to evaluate the cause effect of a pill on a single person.</p><p><img src="/2022/11/07/potential-outcome/2.PNG"></p><p>Let T denotes whether this person take a pill, Y denotes the degree that his headache is relieved after taking the pill. The Cause Effect can be noted as: <span class="math display">\[Y|do(T=1) \ - Y|do( T =0) = Y(1)-Y(0)\]</span> The cause effect of a treatment on a single unit is called <strong>Individual Treatment Effect</strong>(ITE)</p><p>A problem of evaluating the effect this way is that for a single person we can only observe Y for once. If we intervene the treatment so that T = 1, we won't obtain any observations about Y(0).</p><p>In such case, we call Y(1),Y(0) the potential outcomes under T. A potential outcome is the outcome of the statistics under our potential treatment.</p><p>For a specific unit, suppose we applied treatment T=t on it, we call the observed outcome <span class="math inline">\(Y^F= Y(T=t)\)</span> the factual outcome. The potential outcome that not applying T=t, <span class="math inline">\(Y^{CF} = Y(T\ne t)\)</span> is called the counterfactual outcome. <span class="math inline">\(Y^{CF }(T =1) = Y^F(T=0)\)</span></p><h3 id="average-treatment-effect">1.3 Average Treatment Effect</h3><p>Due to the problem discussed in 1.2, we usually cannot get the ITE of a treatment directly. However, if we do not put specific emphasis on the effect of individual, we can obtain the overall effect size by calculating the <strong>Average Treatment Effect(</strong>ATE) of a treatment on a population: <span class="math display">\[ATE = E[ITE] =E[Y^F(T=1)] - E[Y^{CF}(T=1)] = E[Y(1)] - E[Y(0)]\]</span> When there exists no confounders: <span class="math display">\[E[Y(1)] = E[Y|T=1]\]</span></p><p>When there exists any confounders: <span class="math display">\[E[Y(1)] = E_X[E[Y|T=1,X=x]]\]</span> here the X follows its original distribution <span class="math inline">\(X \sim D(\theta)\)</span></p><p>However, when we try to interpret the effect size from observational data, what we actually obtained is <span class="math display">\[E[Y|T=1] - E[Y|T=0] = E_{X_1}[E[Y|T=1,X_1]] - E_{X_0}[E[Y|T=0,X_0]]\]</span> Here <span class="math inline">\(X_T\)</span> and <span class="math inline">\(X_C\)</span> follow conditional probability distributions given T instead of X's original distribution: <span class="math inline">\(X_1 = (X| T =1), X_0 = (X|T=0)\)</span>, <span class="math inline">\(X_1 \sim D(\theta_1), X_0 \sim D(\theta_0)\)</span></p><p>when confounder exists, X would have different distribution on the treatment and control group, thus <span class="math display">\[P(X_1) \ne^d P(X_0)\]</span> Thus, when confounder exists: <span class="math display">\[E[Y(1) - Y(0)] = E_X[E[(Y|T=1,X)] - E[(Y|T=0,X)]] \ne E[Y|T=1] - E[Y|T=0]\]</span></p><p>In most real application cases, there are multiple confounders in the causal inference process. To estimate the ATE, we need to "block" the effects of confounder. We call the treatment effect under a segmentation a Conditional Average Treatment Effect(CATE) and calculate the weighted average of the CATE as the ATE estimation. The weight is the probability of the segmentation in the whole population. Such kind of methods are called <strong>Backdoor Adjustment</strong></p><h3 id="basic-assumptions-about-potential-outcomes">1.4 Basic Assumptions about Potential Outcomes</h3><p><strong>Stable Unit Treatment Value Assumption(SUTVA)</strong>: The potential outcome of any unit won't be changed by treatment on other units. This assumption emphasize the independency of units</p><p><strong>Positivity Assumption</strong>: For units of any possible values of background variable, any assigned treatment is possible. <span class="math display">\[P(T=t|X=x) \in (0,1) \quad \forall t\ and \ x\]</span> <strong>Consistency Assumption </strong>: If T=t is applied on a group of unit, then the outcomes of all units in that group would be Y(T=t). <span class="math display">\[T = t \Rightarrow Y=Y(t)\]</span> The consistency assumption make sure we have $Y(t) = Y|T=t $ when there's no confounders</p><p><strong>Ignorability Assumption</strong>: The determination of the treatment T is independent to the potential outcomes: <span class="math display">\[(Y(1),Y(0)) \perp \!\!\! \perp T\]</span> Under the Ignorability Assumption: <span class="math display">\[E[Y(1)] = E[Y(1)|T=1] = E[Y| T=1]\]</span> The Ignorability Assumption is usually considered satisfied when we conduct a random control trail. If we randomized the determination of the treatment, this assumption implies the influence of the confounders are blocked. However, in a non-experimental context, since T is not randomized, the influence of the confounder still exists, and the Ignorability Assumption is not satisfied. In such scenarios, we would weaken Ignorability Assumption into the following assumption.</p><p><strong>Conditional Ignorability Assumption</strong>: Given background variables X, the determination of the treatment T is independent to the potential outcomes <span class="math display">\[(Y(1),Y(0))|X \perp \!\!\! \perp T\]</span> Under the conditional Conditional Ignorability Assumption: <span class="math display">\[E[Y(1)|X=x_i] = E[Y(1)|T=1,X=x_i] = E[Y| T=1,X=x_i]\]</span> With these assumption, we can make the following statement for a causal inference process:</p><ul><li><p>The SUTVA, Positivity and Consistency should always be satisfied</p></li><li><p>If a RCT is conducted, we can regard as <span class="math inline">\((Y(1),Y(0)) \perp \!\!\! \perp T\)</span>, and The ignorability assumption can be considered satisfied. Thus a RCT is a best solution for causal inference</p></li><li><p>If RCT is not implementable, we can condition on the confounder to satisfy the conditional ignorability assumption and estimate the CATE, then we may estimate the distribution of the confounders and calculate the exception of the CATE to obtain ATE</p><p><img src="/2022/11/07/potential-outcome/3.PNG"></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Causal Inference</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Distribution</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Introduction of Causal Inference</title>
    <link href="/2022/11/07/basic-causal-inference/"/>
    <url>/2022/11/07/basic-causal-inference/</url>
    
    <content type="html"><![CDATA[<h1 id="introduction-of-causal-inference">Introduction of Causal Inference</h1><h2 id="about-causal-inference">1. About Causal Inference</h2><p>Causal Inference refer to the process that we want to discover the real causality between variables based on data. Specifically, there are two domains of causal inference:</p><ul><li>Causality Discovery: find the causal structure among variables</li><li>Causal Effect Estimation: give a quantitative evaluation on the causal effect of a variable to another</li></ul><h2 id="why-causal-inference">2. Why Causal Inference</h2><p>The core reason why we cannot discover causal realtionship and estimate causal effect through traditional statistical methods is that: <strong>Correlation does not imply Causality</strong>. Use traditional Statistics methodology, which is basically based on statistical dependence, on causal reasoning would lead to bias</p><h3 id="simpson-paradox-confounder">2.1 Simpson Paradox: Confounder</h3><p>Suppose we have two treatment A and B for a certain disease and want to evaluate if A has better effect by cure rate. There are two categories pf patients: mild patients and severe patients. Suppose the truth is condition of patients have effects on both the selection of treatment and the cure rate:</p><p><img src="/2022/11/07/basic-causal-inference/1.png"></p><p>However, since we failded to recognize the ture causal relationship among these variables, we assume there's no other facor other than treatment and effect:</p><p><img src="/2022/11/07/basic-causal-inference/2.png"></p><p>Under these assumption, we obtained the following data:</p><table><thead><tr class="header"><th>Treatment</th><th>Mild</th><th>Severe</th><th>Total</th></tr></thead><tbody><tr class="odd"><td>A</td><td><span class="math inline">\(\frac{30}{100} = 30\%\)</span></td><td><span class="math inline">\(\frac{210}{1400} = 15\%\)</span></td><td><span class="math inline">\(\frac{240}{100} = 16\%\)</span></td></tr><tr class="even"><td>B</td><td><span class="math inline">\(\frac{100}{500} = 20\%\)</span></td><td><span class="math inline">\(\frac{5}{50} = 10\%\)</span></td><td><span class="math inline">\(\frac{105}{550} = 19\%\)</span></td></tr></tbody></table><p>Here a simpson paradox appears: treatment A is better than treatment B on every segments, but the overall effect of A is actually lower.</p><p>The occurrence of simpson paradox usually suggest the existence of <strong>confounder</strong> variables. If one or more variables have causal effects on both of two variable, we call these variables confounders of the two variables. In this case, the condition is a confounder.</p><p>Let Y denote the cure rate, X denote the condition of patients, and T denote the selection of treatment. For these data, what we observed is: <span class="math display">\[E[Y|T= A] - E[Y| T= B] = 16\%-19\% = -3\%\]</span> under the wrong assumption that there's no confounding variables, we believe: <span class="math display">\[E[Y(A) - Y(B)] =E[(Y|T=A) - (Y|T=B)] = E[Y|T= A] - E[Y| T= B] = -3\%\]</span> and we draw the conclusion that A has negative effect.</p><p>However, the truth is, the when there are confounders, the true interpretation of the results ought to be: <span class="math display">\[E[Y(A) - Y(B)] = E_x[E[(Y|T=A,C) - (Y|T=B,C)]] = \sum_i P(C=i)E[(Y|T=A,C) - (Y|T=B,C)]\]</span></p><p><span class="math display">\[E[Y(A) - Y(B)] = \frac{600}{2050}*(0.3-0.2)+\frac{215}{2050}(0.15-0.1) = 3.4\%\]</span></p><p>What we obtained from the data is: <span class="math display">\[E[Y|T= A] - E[Y| T= B] = E_x[E[Y|T=A,X]] - E_x[E[Y|T=B,X]] = -3\%\]</span> Note that the X here follows a conditional probability distribution given T instead of its original distribution: <span class="math display">\[E_x[E[Y|T=A,X]] = \sum_iP(X = i|T=A)E[Y|T=A,X=i]\]</span> As the conditional probability distribution of X given <span class="math inline">\(T = A\)</span> and <span class="math inline">\(T=B\)</span> are different <span class="math display">\[E_x[E[(Y|T = A,X) - (Y|T=B,X)] \ne E_X[Y|T= A,X] - E_X[Y| T= B,X]\]</span> When there's confounder, the statistical denpendy can not accurately represent the causality. In this case, treatment A has positive effect on cure rate. However, since the patients who choose cure A are mostly severe patients and has lower cure rate, the condition variable create a negative association between T and Y. Thus the statistical correction of T and Y are undermined because of X.</p><p>When there exists confounders: <span class="math display">\[E[Y|do(T= A)] - E[Y|do(T=B)] \ne E[Y|T= A] - E[Y| T= B]\]</span></p><h3 id="berkson-paradox-selection-bias">2.2 Berkson Paradox: Selection Bias</h3><p>Suppose X and Y represent the academic performance and professional experience of a student, and we want to know if X has a causality on Y. Suppose the real situation is X and Y are independent. Also, there's a fact that students with high academic scores and outstanding work experience are more likely to be admitted by a university. Let Z donate the probability of a student being admitted by a university, the true causal structure of the problem is:</p><p><img src="/2022/11/07/basic-causal-inference/3.png"></p><p>However, we failed to recognize such a variable Z that both caused by X and Y. When we draw the sample, we go to a university to investigate the academic performance and professional experience of its students. Thus, all samples drawn are student admitted by university.</p><p><img src="/2022/11/07/basic-causal-inference/4.png"></p><p>To make it easy, consider X, Y and Z as binary variables. Suppose we have following data:</p><table><thead><tr class="header"><th></th><th>Y = high</th><th>Y =low</th></tr></thead><tbody><tr class="odd"><td>X = high</td><td><span class="math inline">\(\frac{130}{150}\)</span></td><td><span class="math inline">\(\frac{40}{155}\)</span></td></tr><tr class="even"><td>X= low</td><td><span class="math inline">\(\frac{50}{155}\)</span></td><td><span class="math inline">\(\frac{5}{150}\)</span></td></tr></tbody></table><p>In each cell, the numerator and the denominator respectively represent the number of admitted students and all students. Its easy to find that X and Y are independent by conducting a <span class="math inline">\(\chi^2\)</span> test based on the denominator values.</p><p>Suppose there exists no confounders. The real ATE should be: <span class="math display">\[E[Y|X= high] - E[Y|X=low] = (150+155) - (155+150) = 0\]</span> However, as we conditioned on Z, the ATE we know observed become: <span class="math display">\[E[Y| X =high, Z = admitted] - E[Y|X=low,Z = admitted] = (130-40)-(50-5) = 45\]</span> We draw incorrect conclusions that X have positive causal effects on Y. The reason is that the the admitted student cannot represent the whole population. In this case, Z is a selection variable, it is caused by both X and Y. If we condition on Z, then association is created between X and Y, and we cannot accurately estimate the causal effect from X to Y through statistical dependency. This is called a selection bias.</p><h3 id="reverse-causation">2.3 Reverse Causation</h3><p>Suppose we want to discover the causal relationship from longer marriage to longer life. The truth is that having a longer marriage has no positive on one's longevity. However, on the other hand, elder people usually have longer marriage as they spent more time. Thus, the true causal relationship between X(longevity) and Y(marriage length) is:</p><p><img src="/2022/11/07/basic-causal-inference/5.png"></p><p>However, according to our assumption, the causality is reversed, we expected to test the following structure:</p><p><img src="/2022/11/07/basic-causal-inference/6.png"></p><p>without any doubts, we would find a statistical dependency between X and Y as statistical association is not directed. However, letting people have longer marriage does not help extend thei lifetime. The causality we discovered is wrong as it is reversed.</p><h2 id="basic-methodology-of-causal-inference">3. Basic Methodology of Causal Inference</h2><h3 id="experimental-data-and-observational-data">3.1 Experimental data and Observational Data</h3><p><strong>Observational Data</strong></p><p>Data are observed and collected for each subjects. No manipulations(intervening) on these subjects occur. We can condition on certain variables, but what we have would then be a subset of the original data</p><p><strong>Experimental Data</strong></p><p>Subjects are manipulated(intervened). The mechanism the data generated are artificially changed.</p><p>Causal inference is very easy on experimental data, while can be much more difficult on observational data.</p><h3 id="randomized-control-experiment">3.2 Randomized Control Experiment</h3><p>We can estimate causality based on Experimental Data through Randomized Control Experiment(RCT).</p><p>Suppose we want to explore the causal relationship from increasing exercise to physical health. Let</p><ul><li>T: denote whether increase exercise</li><li>Y: physical condition of a unit</li><li>X: any confounder that can create a statistical correction between T and Y, such as gender, weight and age</li><li>Z: any common results of Y and T, such as physical condition evaluation score</li></ul><p>To collect observational data, we just record the T, Y and X of units we can observed</p><p>To collect experimental data, we need to split all subject into treatment group(increase exercise) and control group(not increase exercise). The process of deciding which group to assign for a subject should be completely randomized. This means X should have same distribution for treatment group and control group. We can such a scenario Covariate Balance <span class="math display">\[P(X|T=1)=^d P(X|T=0)\]</span></p><p>Under such intervention, we can regard as the causality from X to T are <strong>blocked</strong>(cannot demonstrate dependency). Also, such a randomized selection ensure that there's no conditioning on Z.</p><p><img src="/2022/11/07/basic-causal-inference/7.png"></p><p>The randomized process ensured there's no other floating association from T to Y other than the directed chain path, which is the one we care about. Under this scenarios, we can estimate causal effect directly from</p>]]></content>
    
    
    <categories>
      
      <category>Causal Inference</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Basic Knowledge</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Common Distribution Types</title>
    <link href="/2022/11/04/distribution/"/>
    <url>/2022/11/04/distribution/</url>
    
    <content type="html"><![CDATA[<h1 id="common-distribution-types">Common Distribution Types</h1><h2 id="random-variable-and-probability-distribution">1. Random Variable and Probability Distribution</h2><p><strong>Random Variable</strong></p><p>A random variable is a quantity whose values depends on the outcome of a random event. Random variable is terminology for numerical data. The probability that the value of a random variable X equals a certain outcome can be given as <span class="math inline">\(P(X = x_1)\)</span></p><p><strong>Distribution</strong></p><p>The probability distribution function is a function <span class="math inline">\(P = f(x)\)</span>, where:</p><ul><li>x donates the possible values of random variable</li><li>y donates the probability when X = x</li></ul><p>Note that the integrate of PDF is 1.</p><p><strong>Parameter</strong></p><p>A parameter is used to determine the shape of a type of PDF. Different type of PDF has different kinds of parameters. <span class="math display">\[P = f_X(x,\theta)\]</span></p><h2 id="discrete-distribution">2. Discrete Distribution</h2><h3 id="bernoulli-distribution">2.1 Bernoulli Distribution</h3><p>A trial is performed with probability p of success, and X is a random variable indicates success or not. In such case, X has 2 possible values(1 means success), and it follows a bernoulli distribution. <span class="math inline">\(p\)</span> is the only parameter for a Bernoulli Distribution.</p><p>The PDF of a bernoulli distribution: <span class="math display">\[f(x) = p^ x (1-p)^{1-x}\]</span> The expectation of a bernoulli distribution is: <span class="math display">\[E[X] = \sum_i x_i f( x) = 0+p =p\]</span></p><p>The variance of a bernoulli distribution is: <span class="math display">\[Var[X] = \sum_i(x_i-E[x]^2)f(x) = p(1-p)\]</span></p><h3 id="binomial-distribution">2.2 Binomial Distribution</h3><p>Let randome variable X donates the number of success we achieved in n independent bernoulli trials. Each trail has a same probability p of success. The parameters of a Binomial Distribution includes n and p</p><p>The PDF of a binomial distribution: <span class="math display">\[f_X(X = k,n,p) = \frac{n!}{k!(n-k)!}p^k(1-p)^{n-k}\]</span> where k = 0,1,2...n</p><p><img src="/2022/11/04/distribution/1.png"></p><p>The expectation of a binomial distribution is: <span class="math display">\[E[X] = np\]</span></p><p>The variance of a binomial distribution is: <span class="math display">\[Var[X] = np(1-p)\]</span> Some properties of binomial distribution:</p><ul><li>if <span class="math inline">\(X \sim bin( n, p), Y \sim bin(m,p)\)</span>, then <span class="math inline">\(X+Y \sim bin(n+m,p)\)</span></li><li>If p is small, <span class="math inline">\(Bin(n,p)\)</span> is approximately <span class="math inline">\(Pois(\lambda)\)</span></li><li>if n is large and p is not near 0 and 1, <span class="math inline">\(Bin(n,p)\)</span> is approximately <span class="math inline">\(N(np, np(1-p)\)</span></li></ul><h3 id="geometric-distribution">2.3 Geometric Distribution</h3><p>A Geometric Distribution basically have same story like a binomial distribution, except now the X donates times of trails before first success. The only parameter of a Geometric Distribution is p.</p><p>The PDF of a Geometric Distribution: <span class="math display">\[f(X=k) = (1-p)^{k-1}p\]</span> <img src="/2022/11/04/distribution/6.PNG"></p><p>The expectation of a Geometric Distribution is: <span class="math display">\[E[X] = \frac{1}{p}\]</span></p><p>The variance of a Geometric Distribution is: <span class="math display">\[Var[X] = \frac{1-p}{p^2}\]</span> Property of Geometric Distribution:</p><ul><li>Memoryless: if <span class="math inline">\(x \sim Geom(p)\)</span>, then <span class="math inline">\(P(T&gt;t+s|T&gt;t) = P(T&gt;s)\)</span>. This suggests no matter how many previous failures happened, the variable representing the time to succeed from the current moment still follows a <span class="math inline">\(\sim Geom(p)\)</span></li></ul><h3 id="possion-distribution">2.4 Possion Distribution</h3><p>Suppose an event(X = x) happens with a certain probability(usually low probability), let X be the times that event happens in a unit time, then X follows a Possion Distribution. <span class="math inline">\(\lambda\)</span> is the only parameter for a Possion Distrbution, which is the expectation of X.</p><p>The PDF of a Possion Distribution: <span class="math display">\[f_X(X = k,\lambda) = \frac{e^ {-\lambda}\lambda^k}{k!}\]</span> where k = 0,1,2...<span class="math inline">\(\infty\)</span></p><p><img src="/2022/11/04/distribution/2.png"></p><p>The expectation of a poisson function is: <span class="math display">\[E[X] = \lambda\]</span></p><p>The variance of a poisson function is: <span class="math display">\[Var[X] = \lambda\]</span> Some properties of poisson distribution:</p><ul><li>if <span class="math inline">\(X \sim pois(\lambda_1), Y \sim pois(\lambda_2)\)</span>, then <span class="math inline">\(X+Y \sim pois(\lambda_1+\lambda_2)\)</span></li><li><span class="math inline">\(X|(X+Y=n) \sim Bin(n,\frac{\lambda_1}{\lambda_1+\lambda_2})\)</span></li><li>if n is large and p is not near 0 and 1, <span class="math inline">\(Bin(n,p)\)</span> is approximately <span class="math inline">\(N(np, np(1-p)\)</span></li></ul><h2 id="continuous-distribution">3. Continuous Distribution</h2><h3 id="normal-distribution">3.1 Normal Distribution</h3><p>If how the certain value of a continuous random variable X is unknown, we can assume it follows a normal distribution. The parameters of a normal distribution include <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span></p><p>The PDF of a normal distribution: <span class="math display">\[f(x) = \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}\]</span> The expectation of a normal distribution is: <span class="math display">\[E[X] = \mu\]</span></p><p>The variance of a normal distribution is: <span class="math display">\[Var[X] = \sigma^2\]</span> Some properties of normal distribution:</p><ul><li>if <span class="math inline">\(X \sim N(\mu_1,\sigma_1^2), Y \sim N(\mu_2,\sigma_2^2)\)</span>, then <span class="math inline">\(X+Y \sim N(\mu_1+\mu_2,\sigma_1^2 + \sigma_2^2)\)</span></li><li>if <span class="math inline">\(X \sim N(\mu_1,\sigma_1^2)\)</span>, then $aX+b N(a+ b, (a)^2) $</li><li>if <span class="math inline">\(X_1,X_2,..X_n\)</span> all follows normal distribution, than <span class="math inline">\(X_1^2+X_2^2+...X_n^2\)</span> follows <span class="math inline">\(\chi^2(n)\)</span></li></ul><h3 id="exponential-distribution">3.2 Exponential Distribution</h3><p>The Exponential Distribution describe same story as poisson distribution, exception the random variable X now donates the time interval between two occurrence of the events. The only parameter for exponential distribution is <span class="math inline">\(\beta\)</span>, where <span class="math inline">\(\beta = \frac{1}{\lambda}\)</span>, representing the probability of occurrence of the event in a unit time.</p><p>The PDF of an exponential distribution: <span class="math display">\[f(x) = f(x) = \left\{             \begin{array}{lr}             \lambda e^{-\lambda x} &amp; x \ge 0 \\             0 &amp; x&lt;0\\             \end{array}\right.\]</span></p><p><span class="math display">\[\lambda = \frac{1}{\beta}\]</span></p><p><img src="/2022/11/04/distribution/3.png"></p><p>The expectation of an exponential distribution is: <span class="math display">\[E[X] = \beta\]</span></p><p>The variance of an exponential distribution is: <span class="math display">\[Var[X] = \beta^2\]</span> Some properties of an exponential distribution:</p><ul><li>Memoryless: if <span class="math inline">\(x \sim Expo(\beta)\)</span>, then <span class="math inline">\(P(T&gt;t+s|T&gt;t) = P(T&gt;s)\)</span></li><li>if <span class="math inline">\(X \sim Expo(\lambda)\)</span>, then <span class="math inline">\(\lambda X \sim Expo(1)\)</span></li><li><span class="math inline">\(X \sim Expo(\lambda_1), Y \sim Expo(\lambda_2)\)</span>, then <span class="math inline">\(Z = aX+bY \sim Expo(\frac{\lambda_1\lambda_2(e^{-\lambda_2 z/b}-e^{-\lambda_1z/a})}{b\lambda_1 - a\lambda_2})\)</span>, if X and Y are i.i.d., then <span class="math inline">\(Z =X+Y \sim Expo(\lambda)\)</span></li><li>if we have independent <span class="math inline">\(X_i \sim Expo( \lambda_ i)\)</span>, then <span class="math inline">\(min(X_1,X_2,..X_k) \sim Expo(\lambda_1+\lambda_2+...+\lambda_k)\)</span></li><li>if we have independent <span class="math inline">\(X_i \sim Expo( \lambda)\)</span>, then <span class="math inline">\(max(X_1,X_2,..X_k) \sim Expo(\lambda)+Expo(2\lambda)+...+Expo(k\lambda)\)</span></li></ul><h3 id="gamma-distribution">3.3 Gamma Distribution</h3><p>Suppose in the exponential distribution scenario, you want to observe the event for <span class="math inline">\(\alpha\)</span> times before you stop, then the time you need to do that would follows a Gamma distribution <span class="math display">\[f(x) = \frac{x^{\alpha-1}\lambda^\alpha e^{-\lambda x}}{\Gamma(\alpha) }\]</span></p><p><span class="math display">\[\Gamma(\alpha) = (\alpha-1)! \qquad \alpha \ is \ Z\]</span></p><p><span class="math display">\[\Gamma(\alpha) = (\alpha-1)\Gamma(\alpha-1) \qquad \alpha \ is \ R\]</span></p><p><span class="math display">\[\Gamma(\frac{1}{2}) = \sqrt{\pi}\]</span></p><p>The expectation of a gamma distribution is: <span class="math display">\[E[X] = \alpha \beta\]</span></p><p>The variance of a gamma distribution is: <span class="math display">\[Var[X] = \alpha \beta^2\]</span> Some properties of gamma distribution:</p><ul><li><p>if <span class="math inline">\(X \sim \Gamma(\alpha_1,\beta), Y \sim \Gamma(\alpha_2,\beta)\)</span>, then <span class="math inline">\(X+Y \sim \Gamma(\alpha_1+\alpha_2, \beta)\)</span></p></li><li><p>When <span class="math inline">\(\alpha = 1\)</span>, a gamma distribution is equivalent to a exponential distribution</p></li></ul><h3 id="beta-distribution">3.4 Beta Distribution</h3><p>The beta distribution is the conjugate prior distribution of a binomial distribution in a Bayesian Inference Context. Thus, it can be interpreted as the PDF of the parameter of a binomial distribution, which is the probability to success in the trail. In other world, it is a likelihood function.</p><p>The PDF of a exponential distribution: <span class="math display">\[f(x) = \frac{1}{B(\alpha,\beta)}x^{\alpha-1}(1-x)^{\beta-1}\]</span> where:</p><ul><li><p><span class="math inline">\(\alpha\)</span> is the number of observations of success</p></li><li><p><span class="math inline">\(\beta\)</span> is the number of observations of failure</p></li><li><p><span class="math inline">\(B(\alpha, \beta)\)</span> is a standard B function. It is applied to make the integrate of the PDF one</p><p><img src="/2022/11/04/distribution/4.png"></p></li></ul><p>The expectation of a beta distribution is: <span class="math display">\[E[X] = \frac{\alpha}{\alpha + \beta}\]</span></p><p>The variance of a gamma distribution is: <span class="math display">\[Var[X] = \frac{\alpha \beta}{(\alpha+\beta)^2(\alpha+\beta+1)}\]</span> Some properties of beta distribution:</p><ul><li><p>if <span class="math inline">\(X \sim \Gamma(a,\lambda), Y \sim \Gamma(b,\lambda)\)</span>, X and Y are independent, then <span class="math inline">\(\frac{X}{X+Y} \sim B(a,b)\)</span></p></li><li><p>After n trial, if x success is observed, the distribution of p pf a trail is updated to <span class="math inline">\(B(\alpha+x,\beta+n-x)\)</span></p></li></ul><h3 id="chi2-distribution">3.5 <span class="math inline">\(\chi^2\)</span> Distribution</h3><p>Suppose k independent random variable <span class="math inline">\(Z_1,..Z_ k\)</span> all follow standard normal distribution, then define random variable X as <span class="math inline">\(\sum_iZ_i^2\)</span>, then X follows a <span class="math inline">\(\chi^2\)</span> distribution. k is the only parameter of <span class="math inline">\(\chi^2\)</span> distribution, representing the number of independent variable(degree of freedom)</p><p>The PDF of a <span class="math inline">\(\chi^2\)</span> distribution: <span class="math display">\[f(x) = \frac{1}{2^{\frac{k}{2}}\Gamma(\frac{k}{2})}x^{\frac{k}{2}-1}e^{\frac{-x}{2}}\]</span> <img src="/2022/11/04/distribution/5.png"></p><p>The expectation of a <span class="math inline">\(\chi^2\)</span> distribution is: <span class="math display">\[E[X] = k\]</span></p><p>The variance of a <span class="math inline">\(\chi^2\)</span> distribution is: <span class="math display">\[Var[X] = 2k\]</span> Some properties of <span class="math inline">\(\chi ^2\)</span> distribution:</p><ul><li><p>If <span class="math inline">\(\chi^2(k_1)\)</span> and <span class="math inline">\(\chi^2(k_2)\)</span> are independent, then <span class="math inline">\(\chi^2(k_1) + \chi^2(k_2) \sim \chi^2(k_1+k_2)\)</span></p></li><li><p>When k is large, a <span class="math inline">\(\chi^2\)</span> distribution is similar to a normal distribution</p></li></ul><h2 id="multivariate-distribution">4. Multivariate Distribution</h2><p>A Multivariate Distribution is the joint PDF of a vector of variables</p><h3 id="multinomial-distribution">4.1 Multinomial Distribution</h3><p>Suppose there are n items fall into k buckets, where the probabilities each items fall into the k buckets is <span class="math inline">\(\vec{p} = (p_1,p_2,...p_k)\)</span>, let <span class="math inline">\(X_i\)</span> donates the number of items fall into the <span class="math inline">\(i^th\)</span> bucket, then a vector <span class="math inline">\(\vec{X} = (X_1,X_2,...X_k)\)</span> follows a Multinomial Distribution MulNm(n,<span class="math inline">\(\vec{p}\)</span> )</p><p>The Joint PDF of a Multinomial Distribution is: <span class="math display">\[P(\vec{X} = \vec{n})=\frac{n!}{n_1!n_2!...n_k!}p_1^{n_1}p_2^{n_2}...p_ k^ {n_k}\]</span> where <span class="math inline">\(\vec{n}\)</span> is a specifc combination of numbers of items fall into each buckets:<span class="math inline">\(\vec{n} = (n_1,n_2...n_k)\)</span>, and $n_ 1+n _2+...+n_k = n $</p><p>The Expectation Vector <span class="math inline">\(\vec{ E }\)</span> would be <span class="math inline">\((np_1,np_2,...np_k)\)</span></p><p>The Variance vector <span class="math inline">\(\vec{ V }\)</span> would be <span class="math inline">\((np_1(1-p_ 1),np_2(1-p_2),...np_k(1-p_k))\)</span></p><p>The Covariance for <span class="math inline">\(X_i\)</span> and <span class="math inline">\(X_j\)</span> would be <span class="math inline">\(Cov(X_i,X_j) = -np_ip_j\)</span></p><h3 id="multivariate-normal-distribution">4.2 Multivariate Normal Distribution</h3><p>For a vector <span class="math inline">\(\vec{X} = (X_1,X_2,...X_k)\)</span> , if every linear combination of this vector is normally distributed, then <span class="math inline">\(\vec{ X }\)</span> follows a Multivariate Normal Distribution MulNorm(<span class="math inline">\(\vec{\mu},\vec{\sigma^2}\)</span>).</p><p>The Joint PDF of a MVN Distribution is: <span class="math display">\[f(\vec{X}) = \frac{1}{\sqrt{(2\pi)^k|\Sigma|}} e^{-\frac{1}{2}(X-\mu)^T\Sigma(X-\mu)}\]</span> Where <span class="math inline">\(|\Sigma|\)</span> is the determinant of the Covariance Matrix</p><p>The Covariance for <span class="math inline">\(X_i\)</span> and <span class="math inline">\(X_ j\)</span> is calculated by: <span class="math display">\[Cov(X_i,X_j) = E[(X_i-\mu_{X_i})(X_ j- \mu_{X_j})] = E[X_iX_j]-E[X_i]E[X_j]\]</span></p><h2 id="distribution-transformation">5. Distribution Transformation</h2><p>Suppose the PDF of a random variable x is <span class="math inline">\(f_X(x)\)</span>, define <span class="math inline">\(y = t(x)\)</span>, then: <span class="math display">\[x = t^-{1}(y)\]</span> let the CDF of X and Y be <span class="math inline">\(F_X,F_Y\)</span> <span class="math display">\[P(Y&lt;y) = P(X&lt;x)\]</span></p><p><span class="math display">\[F_Y(y) = F_X(t^{-1}(y))\]</span></p><p><span class="math display">\[f_Y(y) = F&#39;_Y(y) = (t^{-1}(y))&#39;f_X(t^{-1}(y))\]</span></p><p>With Such rules , let <span class="math inline">\(Y = F(X)\)</span> <span class="math display">\[f_Y(y) = (F^{-1}(y))&#39;f_X(F^{-1}(y)) = F(F^{-1}(y))&#39;F^{-1}(y) = F(F^{-1}(y))&#39; = y&#39; = 1\]</span> Thus, if a randam variable <span class="math inline">\(u = CDF(X)\)</span>, then $u U(0,1) $</p><table style="width:100%;"><thead><tr class="header"><th>From</th><th>Transformation</th><th>to</th></tr></thead><tbody><tr class="odd"><td><span class="math inline">\(Expo(\lambda)\)</span></td><td><span class="math inline">\(Y = 1-e^{-\lambda x}\)</span></td><td>U(0,1)</td></tr><tr class="even"><td>U(0,1)</td><td><span class="math inline">\(Y=\sqrt{2}h^{-1}(2X-1)\)</span>, <span class="math inline">\(h(x) = \frac{2}{\sqrt{\pi}}\int_0^xe^{-t^ 2}dt\)</span></td><td>N(0,1)</td></tr></tbody></table><p>In some case, we use a transformation to let <span class="math inline">\(f_Y(y)\)</span> have an approximate formulation as the target distribution. Then we define an error function to measure the loss of y and E[y] under target distribution, and train the parameters of the tranformation</p><table><thead><tr class="header"><th>From</th><th>Transformation</th><th>to</th></tr></thead><tbody><tr class="odd"><td><span class="math inline">\(Expo(\lambda)\)</span></td><td><span class="math inline">\(Y =\frac{X^\theta-1}{\theta}\)</span></td><td><span class="math inline">\(N(\mu,\sigma^2)\)</span></td></tr><tr class="even"><td><span class="math inline">\(Expo(\lambda)\)</span></td><td><span class="math inline">\(Y=log_\thetaï¼ˆ1+Xï¼‰\)</span></td><td><span class="math inline">\(N(\mu,\sigma^2)\)</span></td></tr></tbody></table><p>There are many improved transformation algorithm like Box-cox, Yeo-johnson and Box-Muller. For more transformation methods for data distribution in machine learning, refer to <a href>ongoing</a>.</p><h2 id="a-distribution-type-and-their-parameters">A: Distribution Type and their parameters</h2><p><img src="/2022/11/04/distribution/7.png"></p>]]></content>
    
    
    <categories>
      
      <category>Probability &amp; Statistics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Distribution</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Encoding Methods for Categorical Variable</title>
    <link href="/2022/10/22/encoding/"/>
    <url>/2022/10/22/encoding/</url>
    
    <content type="html"><![CDATA[<h1 id="encoding-methods-for-categorical-variable">Encoding Methods for Categorical Variable</h1><h2 id="about-encoding">1. About Encoding</h2><p>Encoding is a process that map categorical variable to numerical variable. For nost models, untransformed categorical data is not accepted as inputs. Five types of encoder introduced below.</p><h2 id="label-encoder">2. Label Encoder</h2><p>Label Encoder is one of the simplest encoding methods. It gives a label to each category</p><p>A categorical variable before encoding:</p><table><thead><tr class="header"><th>Species</th></tr></thead><tbody><tr class="odd"><td>Cat</td></tr><tr class="even"><td>Dog</td></tr><tr class="odd"><td>Bird</td></tr></tbody></table><p>after encoding:</p><table><thead><tr class="header"><th>Species</th></tr></thead><tbody><tr class="odd"><td>0</td></tr><tr class="even"><td>1</td></tr><tr class="odd"><td>2</td></tr></tbody></table><p>A Label Encoder has following properties:</p><ul><li>It changes a categorical variable into a multivalued discrete variable</li><li>It does not generate extra variable, thus is memory-saving</li><li>The encoded data has a magnitude relationship, thus Label encoder should be applied to ordinal variable instead of nominal variable</li><li>It does not change the number of categories</li></ul><h2 id="one-hot-encoder">3. One-hot Encoder</h2><p>One-hot encoder expand the categorical variable into c variables, where c is number of categories. For categories, these variables are exclusive.</p><p>A categorical variable before encoding:</p><table><thead><tr class="header"><th>Species</th></tr></thead><tbody><tr class="odd"><td>Cat</td></tr><tr class="even"><td>Dog</td></tr><tr class="odd"><td>Bird</td></tr></tbody></table><p>after encoding:</p><table><thead><tr class="header"><th>Cat</th><th>Dog</th><th>Bird</th></tr></thead><tbody><tr class="odd"><td>1</td><td>0</td><td>0</td></tr><tr class="even"><td>0</td><td>1</td><td>0</td></tr><tr class="odd"><td>0</td><td>0</td><td>1</td></tr></tbody></table><p>For some kinds of data, the generated variables could also be non-exclusive</p><table><thead><tr class="header"><th>Color</th><th>R</th><th>G</th><th>B</th></tr></thead><tbody><tr class="odd"><td>White</td><td>0</td><td>0</td><td>0</td></tr><tr class="even"><td>Purple</td><td>255</td><td>0</td><td>100</td></tr><tr class="odd"><td>Orange</td><td>100</td><td>120</td><td>10</td></tr></tbody></table><p>A One-hot Encoder has following properties:</p><ul><li>It changes a categorical variable into c multivalued/binary discrete variables</li><li>It generates c-1 extra variable, thus is memory-costing when c is big. It suits variable with few categories</li><li>It can be applied to both ordinal and nominal variable</li><li>It does not change the number of categories</li><li>Dummy-variables and True-False encoder are very similar to one-hot encoder, only small differences exist</li></ul><h2 id="target-encoder">4. Target-Encoder</h2><p>Target encoder transform the categorical variables according to the output variable.</p><p>For numerical output, the target encoder replace categorical variable with the mean of samples under each category</p><table><thead><tr class="header"><th>X(species)</th><th>Y(Weight)</th><th>X'</th></tr></thead><tbody><tr class="odd"><td>cat</td><td>10</td><td>12.5</td></tr><tr class="even"><td>cat</td><td>15</td><td>12.5</td></tr><tr class="odd"><td>dog</td><td>20</td><td>25</td></tr><tr class="even"><td>dog</td><td>30</td><td>25</td></tr></tbody></table><p>For categorical output, the target encoder replace categorical variable with <span class="math inline">\(P(y= y_i|x=x_i)\)</span></p><table><thead><tr class="header"><th>X(species)</th><th>Y(Size)</th><th>X1(size-Small)</th><th>X2(size-medium)</th><th>X3(size-BIG)</th></tr></thead><tbody><tr class="odd"><td>cat</td><td>big</td><td>0.25</td><td>0.25</td><td>0.5</td></tr><tr class="even"><td>cat</td><td>big</td><td>0.25</td><td>0.25</td><td>0.5</td></tr><tr class="odd"><td>cat</td><td>medium</td><td>0.25</td><td>0.25</td><td>0.5</td></tr><tr class="even"><td>cat</td><td>small</td><td>0.25</td><td>0.25</td><td>0.5</td></tr><tr class="odd"><td>dog</td><td>big</td><td>0.33</td><td>0</td><td>0.66</td></tr><tr class="even"><td>dog</td><td>big</td><td>0.33</td><td>0</td><td>0.66</td></tr><tr class="odd"><td>dog</td><td>small</td><td>0.33</td><td>0</td><td>0.66</td></tr></tbody></table><p>A Target Encoder has following properties:</p><ul><li>It changes a categorical variable into some continuous variables</li><li>For continuous and binary outputs, it does not generate extra variables, for multivalued categorical output, it generate k variables, where k is the number of categories of output variable. When k &lt; c, the target encoder can be more memory-saving than one-hot encoder</li><li>It can be applied to both ordinal and nominal variable</li><li>It does not change the number of categories</li><li>There several improved target encoders like smooth target encoder and bayesian target encoder</li></ul><h2 id="frequency-encoder">5.Frequency Encoder</h2><p>The frequency encoder convert categorical variable into discrete variables by counting each category's frequency in training dataset:</p><p>A categorical variable before encoding:</p><table><thead><tr class="header"><th>Species</th></tr></thead><tbody><tr class="odd"><td>Cat</td></tr><tr class="even"><td>Cat</td></tr><tr class="odd"><td>Dog</td></tr><tr class="even"><td>Bird</td></tr></tbody></table><p>after encoding:</p><table><thead><tr class="header"><th>Species</th><th>X'</th></tr></thead><tbody><tr class="odd"><td>Cat</td><td>2</td></tr><tr class="even"><td>Dog</td><td>1</td></tr><tr class="odd"><td>Bird</td><td>1</td></tr></tbody></table><p>A Frequency Encoder has following properties:</p><ul><li>It changes a categorical variable into a discrete variable</li><li>It does not generate extra variables, thus is memory-saving</li><li>The might be collision of variables, and change the number of categories, thus this endocing method does not fit small dataset</li><li>There would be magnitude in transformed variables</li></ul><h2 id="binary-encoder">6. Binary Encoder</h2><p>Binary Encoder use $log_2N $ variables to express the original variable with N categories</p><table><thead><tr class="header"><th>Species</th></tr></thead><tbody><tr class="odd"><td>Cat</td></tr><tr class="even"><td>Dog</td></tr><tr class="odd"><td>Bird</td></tr><tr class="even"><td>Snake</td></tr></tbody></table><p>A variable with four categories can be expressed in a 2-dimension vector</p><table><thead><tr class="header"><th>Species</th><th>X1</th><th>X2</th></tr></thead><tbody><tr class="odd"><td>Cat</td><td>0</td><td>0</td></tr><tr class="even"><td>Dog</td><td>0</td><td>1</td></tr><tr class="odd"><td>Bird</td><td>1</td><td>0</td></tr><tr class="even"><td>Snake</td><td>1</td><td>1</td></tr></tbody></table><p>The binary encoder has similar properties as One-hot Encoder, but:</p><ul><li>It saves more memory</li><li>The generated variables is less interoperable</li></ul><h2 id="hash-encoder">7. Hash Encoder</h2><p>The Hash Enocder map the original variable into a low-dimension space, and use the length of hash bin as transformed values. It is usually applied in a text processing scenario.</p><p>A text variable before encoding:</p><table><thead><tr class="header"><th>Message</th></tr></thead><tbody><tr class="odd"><td>I love python python is good</td></tr><tr class="even"><td>I dont like python</td></tr><tr class="odd"><td></td></tr></tbody></table><p>A text variable after encoding:</p><table><thead><tr class="header"><th>text</th><th>I</th><th>love</th><th>Python</th><th>is</th><th>good</th><th>dont</th><th>like</th></tr></thead><tbody><tr class="odd"><td>I love python python is good</td><td>1</td><td>1</td><td>2</td><td>1</td><td>1</td><td>0</td><td>0</td></tr><tr class="even"><td>I dont like python</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td></tr><tr class="odd"><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table><p>A Hash Encoder has following properties:</p><ul><li>It changes a categorical variable into some discrete variables</li><li>Comparing to One-hot Encoder, it saves memory when the original variable is complex and repeatable, like text and graph</li><li>The might be collision of variables, and change the number of categories, thus this endocing method does not fit small dataset</li></ul><h2 id="embedding-encoder">8. Embedding Encoder</h2><p>Embedding methods is a techniques transforms the original categorical variable into a vector that reflect the similarity of the original categories. It is more frequently used in deep learning scenarios like NLP. Generally speaking, it can be regraded as a kind of encoding methods.</p><p>[ongoing]</p>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Feature Engineering</tag>
      
      <tag>Encoding</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Normality Test and Distribution Type Transformation</title>
    <link href="/2022/10/22/distribution-type/"/>
    <url>/2022/10/22/distribution-type/</url>
    
    <content type="html"><![CDATA[<h1 id="normality-test-and-distribution-type-transformation">Normality Test and Distribution Type Transformation</h1><h2 id="normality-and-distribution-type-transformation">1. Normality and Distribution Type Transformation</h2><p>In feature engineering, sometimes we need to transform the distribution type to make the data fit the model. In most scenarios, we want to transform a non-normal distributed variable into a normal distributed variable.</p><h2 id="normality-test">2. Normality Test</h2><p>Before transformation, we need first to examine the normality of the data to decide which features to transform.</p><h3 id="visualized-method">2.1 Visualized Method</h3><p><strong>Histogram</strong></p><p>The histogram is one of the simplest method to test normality. If the histogram are bimodal cureve or a trailing curve, then there is a normality problem</p><p><strong>P-P Plot and Q-Q Plot</strong></p><p>P-P plot use the cumulative frequency of the sample as a X -axis, the cumulative probability of the variable under a normal distribution assumption as a Y-axis</p><p><img src="/2022/10/22/distribution-type/1.png"></p><p>If the points in the graph are approximately around a line from (0,0) to (1,1), then sample reflect a normal distribution. Otherwise, there is a normality problem</p><p>The Q-Q Plot is a variant of P-P Plot. The only difference is the axis is now the quantile instead of the cumulative probability.</p><h3 id="hypothesis-testing-method">2.2 Hypothesis Testing Method</h3><p><strong>Skewness and Kurtosis</strong></p><p>Skewness and Kurtosis are both statistics.</p><p>Skewness is the standardized 3rd central moment of the sample: <span class="math display">\[S = \frac{1}{n-1}\sum_{i=1}^n(x_i-\bar{x}^3)/s^3\]</span> The kurtosis is the standardized 4rd central moment. In calculation we usually minus 3 to let the kurtosis of normal distribution be 0 <span class="math display">\[K = \frac{1}{n-1}\frac{\sum_{i=1}^n(x_i-\bar{x}^4)}{s^4}-3\]</span> where s is the standard deviation</p><p>When the variable folllows a normal distribution, both statistics should be 0. Thus we can use a hypothesis testing on these two parameters two decide normality. Let <span class="math inline">\(SE_S, SE_K\)</span> denote the standard error: <span class="math display">\[SE_S = \frac{6N(N-1)}{(N-2)(N+1)(N+3)}\]</span></p><p><span class="math display">\[SE_K = \frac{4(N^2-1)SE_s}{(N-3)(N+5)}\]</span></p><p>Construct Z score :<span class="math inline">\(Z_S = \frac{S}{SE_s}, Z_K = \frac{K}{SE_K}\)</span>. Given <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, we can do a Z test to decide normality.</p><p>A improved version of testing based on Skewness and Kurtosis is <strong>D'Agostino's K-squared test</strong>, which construct a <span class="math inline">\(\chi^2\)</span> test statistics by combining skewness and kurtosi. It is a common and powerful method for normality test.</p><p><strong>K-S Testing</strong></p><p>Kolmogorovâ€“Smirnov test is method to test if a empiric distribution is different from a theoretical distribution. In other word, if the variable distributed as we want.</p><p>Let <span class="math inline">\(F_n,F_0\)</span> respectively represent the CDF of the empiric distribution and the theoretical distribution. n is the sample size. Construct test statistics as <span class="math display">\[D_n = sup_x \ |F_n(x) - F_0(x)|\]</span> where sup represent the supremum. If <span class="math inline">\(F_n = F_0\)</span> , the limit of <span class="math inline">\(D_n\)</span> should be zero. Given significance level <span class="math inline">\(\alpha\)</span>, find <span class="math inline">\(t_\alpha\)</span> such that <span class="math inline">\(P( \sqrt{n}D_n \ge t_\alpha) = \alpha\)</span>, the rejection area then would be <span class="math inline">\([\frac{t_\alpha}{\sqrt{n}},+\infty)\)</span></p><p>In normality test, we can use K-S test to decided whether the variable follows a normal distribution by replacing supreme with maximum. <span class="math inline">\(F_n,F_0\)</span> would be the observed cumulative frequency of sample and cumulatively probability under normal distribution assumption</p><p><strong><span class="math inline">\(\chi^2\)</span> Test for fitness</strong></p><p>The <span class="math inline">\(\chi^2\)</span> Test for fitness works similarly like the K-S test in normality test. Construct the <span class="math inline">\(\chi^2\)</span> test statistics with observed cumulative frequency of sample and cumulatively probability. <span class="math inline">\(\chi^2\)</span> Test for fitness is easier when the test statistics are discrete. For continuous variable, we need to discretize the variable</p><h2 id="distribution-type-transformation">3. Distribution Type Transformation</h2><h3 id="monte-carlo-integral">3.1 Monte Carlo Integral</h3><p>A theoretical method to inverse the CDF of the variable and transform the distribution into a normal distribution, for specific details, refer to <a href="http://zhengyuanyang.com/2022/11/04/distribution/#distribution-transformation">this article</a></p><p><strong>Box-Muller</strong></p><p>A simpler way to obtain normal-distributed vairable from uniformly distributed variable is the Box-Muller. Given two uniformly distributed variables <span class="math inline">\(U_1, U_2\)</span>: <span class="math display">\[Z_1 = \sqrt{-2lnU_1}cos(2\pi U2)\]</span></p><p><span class="math display">\[Z_2 \ \sqrt{-2 lnU1} sin(2\pi U2)\]</span></p><p>It can be proved that <span class="math inline">\(Z_1, Z_2 \sim N(0,1)\)</span>. Through this method, we can transform pairwise variable without knowing the error function of the single variable. However, the CDF of both variables should still be known.</p><p>In real application, it is difficult to obtain the accurate cumulative density function. Thus, MC method only works well when the CDF of the variable is given in a closed form. In most scenarios, we would use other transformation to approximate a normal distribution</p><h3 id="log-transformation">3.2 Log Transformation</h3><p>We can try to approximate normal distribution through log transformation: <span class="math display">\[X&#39; = log_a(X+k)\]</span> Where a and k are parameterswe can adjust. Greater a has stronger power to correct skewness. Usually we would try <span class="math inline">\([e, 10]\)</span>. K is a positive correction term ensuring there's no negative, zerr or extreme small values in the data.</p><h3 id="power-transformation">3.3 Power Transformation</h3><p>We can try to approximate normal distribution through power transformation: <span class="math display">\[X&#39; = X^a\]</span> when the vairable is a ratio, we can also add a arcsin transformation: <span class="math display">\[X&#39; = arcsin(X^a)\]</span> Improved power transformer includes:</p><p><strong>Box-Cox</strong> <span class="math display">\[X&#39; = \left\{\begin{aligned}\frac{X^\lambda-1}{\lambda} \qquad&amp;  \lambda \ne0\\ln(X) \qquad &amp; \lambda = 0 \\\end{aligned}\right.\]</span> <strong>Yeo-Johnson</strong></p><p><span class="math display">\[X&#39; = \left\{\begin{aligned}&amp;\frac{(X+1)^\lambda-1}{\lambda} \qquad&amp;  \lambda \ne0, X\ge 0\\&amp;ln(X)+1 \qquad &amp; \lambda = 0, X \ge 0\\&amp;\frac{-[(-X+1)^{2-\lambda}-1]}{2-\lambda} \qquad&amp; \lambda \ne 2, X&lt;0\\&amp;-ln(-X+1) \qquad&amp;\lambda=2, X&lt;0\end{aligned}\right.\]</span> where<span class="math inline">\(\lambda\)</span> is a parameter that can be optimized through Maximum Likelihood Estimation(MLE). The Box-Cox transformer requires X to be strictly positive, while the Yeo-Johnson transformer can accept any numbers.</p>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Distribution Type Transformation</tag>
      
      <tag>Feature Engineering</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Scaler in Machine Learning</title>
    <link href="/2022/10/21/scaler/"/>
    <url>/2022/10/21/scaler/</url>
    
    <content type="html"><![CDATA[<h1 id="scaler-in-machine-learning">Scaler in Machine Learning</h1><h2 id="about-scaling">1. About Scaling</h2><p>When adopting multiple variables, many models would be effected by the difference of scales of variables. For example, distance-based clustering would enlarge the impact of variables with larger scale. Another example is that Gradient D Descending is harder to converge on unscaled data. Data Scaling can significantly improve the performance and efficiency of some models, while on other models, like tree model or Naive Bayes, data scaling does not make an influence.</p><p>â€‹</p><h2 id="scaler">2. Scaler</h2><p>Scaler is those algorithm used to scaling data. They usually do not change the type of the data distribution. Four types of sclaer are listed as follows:</p><h2 id="standard-scaler">2.1 Standard Scaler</h2><p>The Standard Scaler does the following transformation <span class="math display">\[x&#39; = \frac{x-\bar{x}}{s}\]</span> where</p><ul><li><p><span class="math inline">\(\bar{x}\)</span> is the average of the original data</p></li><li><p>s is the standard deviation of the original data</p></li><li><p>x' is the Z-score of thr original data.</p></li></ul><p>The Standarad Scaler has following properties:</p><ul><li><p>The original data should fit a normal distribution. This is not a necessary hypothesis but the scaler <strong>works better if the original data has strong normality.</strong> After the transformation, the data follows N(0,1)</p></li><li><p>If the original data is not normally distributed, the standard sclater will not change it's type of distribution. In such case, consider distribution transformation methods before applying standard scaler.</p><p><img src="/2022/10/21/scaler/1.PNG"></p></li><li><p>The <strong>range of transformed data is not for fixed</strong>. But most data points should lie in [-3,3].</p></li><li><p>The <strong>Outlier has an significant influence on the scaling</strong>. Consider applying outlier detection method before scaling</p></li></ul><h3 id="minmax-scalermean-normalization">2.2 MinMax Scaler/Mean Normalization</h3><p>The MinMax Scaler does the following transformation <span class="math display">\[x&#39; = \frac{x-x_{min}}{x_{max}-x_{min}}\]</span> The MinMax Scaler has following properties:</p><ul><li>The MinMax scaler is a linear transformation, it does not change the type of distribution, and <strong>it does not have hypothesis on data distribution</strong></li><li>The <strong>range of data after transformation would be [0,1]</strong></li><li>The Outlier has an significant influence on the scaling. Consider applying outlier detection method before scaling</li></ul><p>A variant of MinMax Scaler is the Mean Normalization, which is given as: <span class="math display">\[x&#39; = \frac{x-\bar{x}}{x_{max}-x_{min}}\]</span> The Mean Normalization has similar properties as MinMax Scaler, but the range of transformed data would be [-1,1]</p><h3 id="robust-scaler">2.3 Robust Scaler</h3><p>The Robust Scaler does the following transformation <span class="math display">\[x&#39; = \frac{x-x_{median}}{IQR}\]</span> where IQR is the difference of 75% percentile and 25% percentile</p><p>The MinMax Scaler has following properties:</p><ul><li>The Robust Scaler does not change the type of distribution, and <strong>it does not have hypothesis on data distribution</strong></li><li>The Robust Scaler reduce the influences of the outlier. If the outlier cannot be eliminated due to some reasons, we can consider this scaling method</li><li>The range of the transformed data is not fixed</li></ul><h3 id="l1l2-scaler">2.4 L1/L2 Scaler</h3><p>The L1/L2 Scaler does the following transformation <span class="math display">\[x_i&#39; = \frac{x_i}{|x|}\]</span></p><p><span class="math display">\[x_i&#39; = \frac{x_i }{||x ||}\]</span> where</p><ul><li>x is a feature vector: {<span class="math inline">\(x_1,x_ 2,...x_ n\)</span>}</li><li><span class="math inline">\(|x|,||x||\)</span> is the L1, L2 norm of the feature vector</li></ul><p>The L1/L2 Scaler has following properties:</p><ul><li>The L /L2 Scaler is a sample-level transomation, it can be applied on a single sample</li><li>The range of the transformed data is [-1,1]</li><li>The parameters of the distribution of the transformed data is hard to predict, since the calculated norm of each sample is different</li></ul>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Feature Engineering</tag>
      
      <tag>Scaler</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Basic Procedure of A/B Testing</title>
    <link href="/2022/10/17/AB-Test/"/>
    <url>/2022/10/17/AB-Test/</url>
    
    <content type="html"><![CDATA[<h1 id="basic-procedure-of-ab-testing">Basic Procedure of A/B Testing</h1><h2 id="about-ab-testing">About A/B Testing</h2><p>A/B testing is a user research technology. It is a random controlled experiment usually involves two variants: treatment group and control group. From a hypothesis perspective, an A/B test is a two-sample independent test for difference.</p><h2 id="step1-problem-statement">Step1: Problem Statement</h2><p>An A/B test should always have an business drive. This can usually be concluded into several product sense framework like AAARR and STAR</p><p><a href>ongoing</a></p><h2 id="step-2-pre-experiment-analysis">Step 2: Pre-experiment Analysis</h2><p>The purpose of pre-experiment analysis is to figure out an specific solution for the problem stated, in other words, the treatment. Common techniques include EDA, user segmentation and machine learning.</p><p>In a A/B testing case interview, the treatment are usually provided by the interviewer. The task for the interviewee would be to infer the business drive beneath the treatment and find according metrics to measure success.</p><h2 id="step-3-metrics-selection">Step 3: Metrics Selection</h2><p>This task is very similar to another type of case <a href>"measure success"</a>. However, for an A/B test, the following facts about a metric should be considered:</p><ul><li>Sensitivity: The metrics should be sentitive and timely. Avoid metrics that needs a long time to demonstrate changes.</li><li>Attributable: Avoid those metrics associated with high-level business goal. These metrics are impacted by many facotrs. They can be insensitive to a particular experiment or be hard for us to attribute the significance on a single treatment.</li><li>Aggregated: The metric should be defined on an aggregation of a measure that is meaningful to every unit. Only by doing that can be regard the meaure on a single unit as a random variable and apply CLT.</li><li>Measurable : The metrics should be clearly defined and measurable. They should not exceed the time or space frame of the experiment</li></ul><h2 id="step-4-experiment-design">Step 4: Experiment Design</h2><h3 id="define-experiment-groups">Define Experiment Groups</h3><p><strong>Randomized Unit</strong></p><p>The randomized unit is the smallest grain that the metrics defined on. In most applications, the randomized unit is a user. Options for finer grains exists:</p><ul><li>Page Level: the smallest unit is a page view</li><li>Session Level: the smallest unit is a group of web page viewed in a single visit</li><li>User Level: the smallest unit is a user. The minimal grain of the metrics should be associated with a user ID, device ID or coockies, such as a UV. Shared account/device can lead to undercounting, while multiple account/device by one user can lead to overcounting. Cookies can be erased, leading to overcounting of users</li></ul><p>Finer grain can increase the number of available units and lower the varianve. Nevertheless, do not use finer grain if the objective of the feature is meant for the user level, such as user experience or user engagement. The analysis unit and the randomized unit is not on the same level if we do so. This can lead to Violation of SUTVA and lead to misinterpretation.</p><p>For example we want to know the probability a user clicked a new button. If we use CTR, based on a PV, then let n denote the number of users, <span class="math inline">\(K_i\)</span> denote the number of PV by the user i. Let <span class="math inline">\(N =\sum_iK_i\)</span> denote the total number of PV, and <span class="math inline">\(X_{i,j}\)</span> be a bernoulli variable denoting whether the user i click the button in his <span class="math inline">\(j^{th}\)</span> PV(suppose a user can only click the button once).</p><p>The CTR is defined as: <span class="math display">\[CTR = \frac{\sum_i\sum_jX_{i,j}}{N}\]</span> This definition is logically right, however, if the real randomization strategy is applied on user, not PV, then there is a violation of SUTVA. The randomization strategy ensures the user are exposed with the treatment randomly, not the PV. The behavior from the same user in different PV can be not independent. In other word, when i is fixed, <span class="math inline">\(X_{i, 1},X_{i, 2},...X_{i, j}\)</span> can be correlated. This lead to mismatch of randomization unit and analyzing unit. In this case, we cannot calculate the variance of CTR using the i.i.d assumption. The variance can then be incorrectly estimated and lead to a misinterpretation in the experiment.</p><p>Insteadly, we can aggregate the metric in to the average Click Through Probability: <span class="math display">\[average \ CTP = \sum_i^n\frac{ \frac{\sum_j^{K_i} X_{i,j}}{K_i} }{n}\]</span> It first aggregate the metrics to the probability that a single user click through <span class="math inline">\(\frac{\sum_j^{K_i} X_{i,j}}{K_i}\)</span> and use it as the analysis unit, which is consistent with the randomization strategy. According to the CLT, this variable should follow a normal distribution, and user are randomized, thus the CTP for each user should be i.i.d. We can then estimate the standard error under the i.i.d assumption.</p><p><strong>Target Group</strong></p><p>The target population the feature meant for. This is usually a subset of all users conditioned on the following dimensions:</p><ul><li>Region: Country, Province</li><li>New/Old User</li><li>Language: English, Chinese</li><li>Industry: Cloth/Furniture/...</li><li>Conversion Stage: We should focus on the users that the feature are meant to perform on. If a user have not yet gome through the user funnel and do not hold a chance to experience the feature, they should not be selected for the experiment</li></ul><h3 id="from-historical-data">From Historical Data</h3><p>Some parameters need to gathered from historical data:</p><p><strong>Baseline of Metrics</strong>: The historical level of metrics on control group and treatment group. The value should be the same(or very close). If there's a difference, conduct a pre-difference analysis(A/A test, metric decomposition)</p><p><strong>Variance</strong>: The estimation of variance on the target population. Since we have not calculate the sample size and split the samples into control and treatment group, it is difficult to estimate the vairiances for two different population from samples. A solution is to assume the variance of both population are the same and estimate the variance through the variance of all samples. If there are any histroical split, like a previous A/B test or A/A test, we can consider estimate both variance.</p><h3 id="from-business-goal">From Business Goal</h3><p><strong>Practical Significance Boundary</strong></p><p>The minimal extent of difference of interest from a business aspect. Usually the researcher first define a minimal relative difference(MRD, usually 1%~5%), and calculate PSB through baseline*MRD. The PSB is taken as an expected MDE to calculate the minimum sample size</p><h3 id="for-hypothesis-testing">For Hypothesis Testing</h3><p>The details of the hypothesis testing can be found in <a href="http://zhengyuanyang.com/2022/03/25/Hypothesis-Testing/#formula">this article</a>.</p><p><strong><span class="math inline">\(\alpha \ and \ \beta\)</span></strong></p><p>Decide the significance level and statistical power. Usually, we set <span class="math inline">\(\alpha = 0.05\)</span> and <span class="math inline">\(\beta = 0.8\)</span> as an initial value</p><p><strong>Minimum Sample Size</strong></p><p>The sample size is decided throguh experience formula. For A/B testing:</p><p>A mean test: <span class="math display">\[n = \frac{(\sigma_1^2+\sigma_2^2)(z_{\alpha/2}+z_{\beta})^2}{\delta^2}\]</span> A ratio test: <span class="math display">\[n = \frac{Z_{\alpha/2}\sqrt{\frac{p_1+p_2}{2}(1-\frac{p_1+p_2}{2})}+Z_\beta\sqrt{p_1(1-p_1)+p_2(1-p_2)}}{p_1-p_2}\]</span> In real applications, for a mean test, if we feel like the respective variances are hard to obtian or we can't decide whether we would apply a Z-test, we can simply apply the <strong>rule of thumb</strong>: <span class="math display">\[n = 16\frac{s^2}{\delta^2 } \qquad for \quad  two-tail\]</span></p><p><span class="math display">\[n = 8\frac{s^2}{\delta^2 } \qquad for \quad  one-tail\]</span></p><p><strong>Test Duration</strong></p><p>The longer the experiment runs, the more sample we can obtained. Usually the sample size can be calculated from: <span class="math display">\[Days \ of \ test = \frac{ Minimum \ sample \ size}{Daily \ available \ unit \ traffics}\]</span></p><p>However, the following aspects need to be considered when deciding the test duration</p><ul><li><strong>Day of week effect:</strong> Weekends might lead to different user behavior had raise up the metrics. It's important to ensure that your experiment capture the weekly cycle</li><li><strong>Seasonality:</strong> Holidays or annual events that can have a impact on the metrics. Try to avoid or correct the effect of these events if the test are for plain time</li><li><strong>Primacy and novelty effects:</strong> Some existing users might tend to be reluctant to change(Primacy Effect), while other existing users might tend to welcome change. Both effects will diminish as time growing. To ensure the stability of the test, the duration should cover the period when these two effects are working</li></ul><p><strong>Experiment Type</strong></p><p>An A/B testing is an test to examine differential of metrics between control group and treatment group. Thus, in most case we selecte a T/Z test.</p><p>For an A/B testing, the experiment should be a two-sample independent test. If the <span class="math inline">\(\sigma\)</span> of the population is unknown, we should consider a T test. If the <span class="math inline">\(\sigma\)</span> is known, for example it is a ratio test, we should apply a Z-test if available samples are more than 30, and a T test if the number is less than 30.</p><p><img src="/2022/10/17/AB-Test/1.png"></p><p><strong>Construct Test Statistics</strong></p><p>The construction of test statistics is decided by the type of experiment and the assumption that whether the variance of the two group are the same. We can consider examining the equality of variance through a F-test based on the experiment samples or any historical data.</p><h2 id="step-5-experiment-deployment">Step 5: <strong>Experiment Deployment</strong></h2><p><strong>Traffic Distribution</strong></p><p>As an A/B test is a random controlled experiment, the randomness of assignment of units must be ensured. The simplest method to ensure concurrent experiments for different tratments do not influence eanch other is the Simple Layer Method, which is to divide all traffic with each experiment variant receiving a specified fraction of the total traffic:</p><p><img src="/2022/10/17/AB-Test/2.png"></p><p>Nevertheless, this method requires that the total needed sample size for all concurrent experiments does not exceed the total available traffics. This put limits on the number of concurrent experiments</p><p>To handle with numerous concurrent experiments cases, we can apply multiple-layer orthogonal traffic method, where each layer is a copy of all or a fraction of total traffic. The re-assignment of a unit accross two layers are random. The groups of experiments are allocated on this layers and each group are expected to receive units randomly from all groups of the above layer.</p><p><img src="/2022/10/17/AB-Test/3.png"></p><p><strong>When to Stop</strong></p><p>The typical rule for experiment stopping is <strong>No Data Peeking</strong>: wait until the experiment reach its duration and then analyze the results. However, in real applications, we might need to monitor the experiment and decide whether to end an experiment after the duration is reached. When the duration is reached:</p><p><img src="/2022/10/17/AB-Test/4.png"></p><h2 id="step-6-experiment-results-analysis">Step 6: Experiment Results Analysis</h2><p>The analysis process of the experiment results can be found in <a href>this article</a></p><h2 id="step-7-lauch-decision">Step 7: Lauch Decision</h2><p>After we are assured that the effect of the treatment is significant and truthworthy, there's still some aspects we need to consider before we deciding to lauch the new feature</p><p><strong>Metrics Trade-off</strong></p><p><strong>Lauch Costs</strong></p><p><strong>Rampling Process</strong></p>]]></content>
    
    
    <categories>
      
      <category>A/B Testing &amp; Case Interview</category>
      
    </categories>
    
    
    <tags>
      
      <tag>A/B Testing</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Distance in Machine Learning</title>
    <link href="/2022/10/08/distance/"/>
    <url>/2022/10/08/distance/</url>
    
    <content type="html"><![CDATA[<h1 id="distance-in-machine-learning">Distance in Machine Learning</h1><h2 id="euclidean-distance">1. Euclidean Distance</h2><p>The Euclidean distance between two data point X and Y is given as: <span class="math display">\[d = \sqrt{\sum(x_i-y_i)^2}\]</span></p><ul><li><p>E Distance is one of the most frequently used distances in machine learning, for its direct and intuitive demonstration.</p></li><li><p>E Distance treat all dimensions as same, thus would be effected by scale of variable. To eliminate that, we can used standard euclidean distance, by replace data values x with: <span class="math display">\[x&#39; = \frac{x-\bar{x}}{s}\]</span></p></li></ul><h2 id="manhattan-distance">2. Manhattan Distance</h2><p><img src="/2022/10/08/distance/MD.png"></p><p>In this demo, the euclidean distance between the beginning and the end in a district shown as the is the green line. However, as we cannot walk through the building straightforward, we must move vertically or horizontally along the blocks. This distance is called Manhattan distance.</p><p>The manhattan distance is the sum of <strong>axis difference</strong> between two data points. It is given as: <span class="math display">\[d = \sum_i^m |x_i-y_i|\]</span></p><ul><li>The manhatten distance only involves summing calculation. So it is faster then float calculation, and it does not generate accuracy lost.</li></ul><h2 id="chebyshev-distance">3. Chebyshev Distance</h2><p><img src="/2022/10/08/distance/2.png" alt="0.5" style="zoom:50%;"></p><p>The manhattan distance is the maxnium of <strong>axis difference</strong> between two data points. It is given as: <span class="math display">\[D = max |x_i-y_i|\]</span></p><h2 id="minkowski-distance">4.Minkowski Distance</h2><p>Minkowski Distance is the distance between two points in a p norm space <span class="math display">\[d = (\sum|x_i-y_i|^p)^\frac{1}{p}\]</span></p><ul><li>when p = 1, MK distance equals Manhattan Distance</li><li>when p = 2, MK distance equals Euclidean Distance</li><li>when p = <span class="math inline">\(\infty\)</span>, MK distance equals Chebyshev Distance</li></ul><p>The norm p is a hyper-parameter can be adjusted. It is more flexible, but choosing p can be difficult</p><h2 id="mahalanobis-distance">5. Mahalanobis Distance</h2><p>Mahalanobis Distance is the Euclidean distance in a standard principal component space(Space after PC decomposition). <span class="math display">\[D(X) = \sqrt{(X-\mu)^TS^{-1}(X-\mu)}\]</span> where:</p><ul><li>X is the feature vector of a sample</li><li>S is the covariance matrix of all features</li><li><span class="math inline">\(\mu\)</span> is the mean vector of all samples</li></ul><p>The M distance between two data point can be given as: <span class="math display">\[D(X,Y) = \sqrt{(X-Y)^TS^{-1}(X-Y)}\]</span></p><ul><li>The M distance is not effcted my scale of data, and it can avoid the correlation among features. Thus it can be a better metrics for measuring distance between data point and central point</li><li>The M distance is usually applied in outlier detection, combined with Grubb's Test</li><li>when the covariance matrix is a identity matrix, which means the distributions of features are independent to each other, the M distance equals to the E distance</li></ul><p><img src="/2022/10/08/distance/4.png"></p><p><img src="/2022/10/08/distance/5.png"></p><h2 id="cosine-distance">6. Cosine Distance</h2><p>The Cosine Distance uses cos of the inner angle of two vectors to represent their distance <span class="math display">\[d = 1- cos(\theta) = 1- \frac{a\cdot b}{|a|*|b|}\]</span></p><ul><li><p>The rule of cosine similarity of two vector is "according -&gt; 1, Orthogonal -&gt;, inverse -&gt; -1". Such rule remains same even when the dimension is extremely high. Since the Euclidean distance could be effected by the number of dimensions, consine distance can be a better measure when it comes to high-dimension data. FOr example, a long sentence and a short sentence share a same meaning can have large euclidean distance, but small cosine distance</p></li><li><p>cosine distance is not a strictly defined distance for mathematics, as it does not satisfy triangle inequality</p></li></ul><h2 id="jaccard-distance">7. Jaccard Distance</h2><p>The Jaccard Distance uses Jaccard similarity to represent distance: <span class="math display">\[d = 1-J(A,B) = 1-\frac{|A \cap B|}{|A \cup B|}\]</span> Where J(A,B) is the ratio of two set's intersection and their union</p><ul><li>Jaccard distance can represent the similarity of two set instead of to points. For example, it can measure the similarity of two customer's shopping records. It can be applied in user segmentation and recommendation</li></ul><h2 id="string-related-distance">8. String Related Distance</h2><p><strong>Hamming Distance:</strong> For two string s1 and s2, the hamming distance is the minimun times needed to transform s1 to s2 by replacing a single character</p><p><strong>Edit Distance</strong>ï¼šFor two string s1 and s2, the edit distance is the minimun times needed to transform s1 to s2 by adding,deleting or replacing a single character</p><h2 id="other-measure-similar-to-distance">9. Other Measure similar to Distance</h2><p>Some measures, just like cosine distance, are not strictly defined distance by mathematics, but can take effects in a similar way, including:</p><ul><li>Correlation Distance(for two variables)</li><li>KL divergence(for two distributions)</li><li>Mutual Information(for two variables)</li></ul>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Distance</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Outlier Detection in Feature Engineering</title>
    <link href="/2022/10/07/outlier/"/>
    <url>/2022/10/07/outlier/</url>
    
    <content type="html"><![CDATA[<h1 id="outlier-detection-and-processing">Outlier Detection and Processing</h1><h2 id="about-outlier">1. About Outlier</h2><p><strong>What is an outlier</strong></p><p>In statistics, an outlier is a data point that significantly differs from other observations.</p><p><strong>Why we need outlier detection? </strong></p><p>Outliers can lead to bias in machine learning. Many models, especially those have strong hypothesis on data distribution(LR,K- Means) would be influenced, or even be unable to converge if outliers exist in training data. Some business and engineering problem, like fraud detection and quality control, are also a outlier detection problem in nature. For this article, we only look to the outlier detection for feature engineering.</p><h2 id="statistical-method">2. Statistical Method</h2><h3 id="one-dimension-method">2.1 One-dimension Method</h3><h4 id="six-sigma-method">2.1.1 Six <span class="math inline">\(\sigma\)</span> Method</h4><p>Given a <strong>one-dimension</strong> variable X that satisfies <strong>Gaussian Distribution</strong>: <span class="math inline">\(X~N(\mu,\sigma)\)</span>, where <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> is the mean and standard error of the sample:</p><p>If a point <span class="math inline">\(x \notin (\mu-3\sigma,\mu+3\sigma)\)</span>, then x can be flagged as an outlier</p><h4 id="grubbs-test">2.1.2 Grubb's Test</h4><p>Grubbs' Test is a kind of hypothesis testing that based ib the following hypothesis:</p><p><span class="math inline">\(H_0\)</span>: There are no outlier in the observations</p><p><span class="math inline">\(H_1\)</span>: There are only one outlier in the observations</p><p>There are several constraints for Grubb's Test:</p><ul><li>The Grubb's test can detect <strong>one outlier in a single test</strong>. If we want to test all data point, we can replace G statistics with z-score to test all samples. If we belive there are a large number of outliers exsits, we should consider other method.</li><li>To apply G test, the variable must follow a <strong>Gaussian Distribution</strong></li><li>The test variable must be <strong>univariate</strong>, if we want to apply the test on multivariate vector, we can calculate the distance between <span class="math inline">\(x_i\)</span> and <span class="math inline">\(\bar{x}\)</span>, and use the distance d as the test variable</li></ul><p>Define statistics G as: <span class="math display">\[G = \frac{\max|X_i - \bar{X}|}{s}\]</span> which is the z-score of the farthest data point</p><p>If: <span class="math display">\[G &gt; \frac{N- 1}{\sqrt{N}}\sqrt{\frac{t_{\frac{\alpha}{2N},N-2}^2}{N-2+t_{\frac{\alpha}{2N},N-2}^2}}\]</span></p><p>Where:</p><ul><li>N is the sample size</li><li>t represents the t score, suppose the orignal dataset can be trasformed to a t distribution</li><li><span class="math inline">\(\frac{\alpha}{2N}\)</span> is the significance level (If it's a single-side test, then <span class="math inline">\(\frac{\alpha}{N}\)</span>)</li><li>N-2 is the degree of freedom</li></ul><p>Then maxnium/minimum of these data points can be flagged as an outlier</p><h4 id="boxplot">2.1.3 BoxPlot</h4><p>Boxplot is depicted as follows:</p><p><img src="/2022/10/07/outlier/2.png"></p><p>It shows the maximun, 75 percentile, median, 25 percentile and minimum of a dataset.</p><p>Note that the maxinum and minimum are not the original values of the data, instead it's calculated as: <span class="math display">\[Max = \min(M,Q_3+1.5IQR )\]</span></p><p><span class="math display">\[Min = \max(m,Q1-1.5IQR)\]</span></p><p>whereï¼š</p><ul><li>M,m is the actual maximum, minimum of the dataset</li><li>Q1,Q3 is the 25,75 percentile of the dataset</li><li>IQR is the intermediate quantiles range of the data, <span class="math inline">\(IQR = Q3-Q1\)</span>, which is the length of the box</li><li>if the actual maximum is smaller than the calculated maximum, then plot with the actual maximun, and there are no outliers. The same apply to minimun</li><li>The data points outside the range of calculated minimum and maximum would be labeled as outliers</li></ul><p><img src="/2022/10/07/outlier/3.png"></p><h3 id="high-dimension-method">2.2 High-dimension method</h3><h4 id="chi2-test">2.2.1 <span class="math inline">\(\chi^2\)</span> Test</h4><p>[ongoing]</p><h4 id="gaussian-distribution-detection">2.2.2 Gaussian Distribution Detection</h4><p>The P value for a high-dimenstion data point is quiet difficult to calculate. We can instead set a threshold <span class="math inline">\(\epsilon\)</span>, suppose a data set <span class="math inline">\(D = \{ x^{(i)} : 0\le i \le m \}\)</span> ,let <span class="math display">\[\mu = \frac{1}{m}\sum_i^m x^{(i)},\sum=\frac{1}{m}\sum(x^{(i)}-\mu)(x^{(i)}-\mu)^T\]</span></p><p><span class="math display">\[p(x) = \frac{1}{2\pi^\frac{n}{2}|\sum|^\frac{1}{2}}exp(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu))\]</span></p><p>if <span class="math inline">\(p(x) &lt; \epsilon\)</span>, the data point can be regard as an outlier</p><h2 id="distance-based-method">3. Distance-based Method</h2><p>For details of distance metrics, refer to <a href="http://zhengyuanyang.com/2022/10/08/distance/">this article</a></p><h3 id="angle-based-method">3.1 Angle-based Method</h3><p><img src="/2022/10/07/outlier/1.png"></p><p>From this graph it is obvious to discover that the inner angle consists of an outlier and any two other points have almost same size. Thus we can define the Angle-based outlier factor as: <span class="math display">\[ABOF(o) = VAR_{x, y \ne o}[\frac{\vec{ox}\cdot \vec{oy}}{dist(o,x)^2dist(o,y)^2}]\]</span> where:</p><ul><li>o is any points in the dataset</li><li>x, y is all other point in the dataset</li><li>dist is the distance metirc, usually euclidean distance</li></ul><p>THe ABOF of an point is the variance of the consine of it and all data pairs consists of other data points. The smaller ABOF a data point has, the more likely it would be an outlier</p><p>The complexity of ABOF is <span class="math inline">\(O(n^ 3)\)</span>. Besides, when applying euclidean distance, the scale of data would have an effect</p><h3 id="nearest-neighbor-method">3.2 Nearest Neighbor Method</h3><p>The steps of Nearest neighbor method is given as follow</p><ul><li>Calculate the KNN of a data point</li><li>Add up the distances of the KNN</li><li>Repeat for every points and sort the sum of distance in descending order</li><li>The points with larger sum of distance is more likely to be outliers</li></ul><p>The tranditional KNN is not suitable for sparse dataset. To improve this, we can apply the following metrics to make judgement:</p><p><strong>Local Outlier Factor(LOF) </strong>: The ratio of the local average density of the KNN of the data point and the local average density of the point itself, the greater LOF a point has, the more likely it would be an outlier</p><p><strong>Connectivity Oulier Factor(COF) </strong>: Outlier are points p where average chaining distance of p is higer than average chaining distanc of p's neighbors. Points with higher COF has sparser surrounding than its neighbors</p><h3 id="distance-based-test">3.3 Distance-based Test</h3><p>As mentioned in 2.1.2, for high dimension data, we can apply tests on the distance of X and <span class="math inline">\(\bar{X}\)</span> instead of the original vector.</p><h2 id="model-based-method">4. Model-based Method</h2><h3 id="clustering-model">4.1 Clustering Model</h3><p>Clustering model can be used as outlier detection methods.</p><ul><li>For distance-based clustering, like K-Means, outliers are points have largest distance to their cluster centroids</li><li>For density-based clustering, like DB-SCAN, outliers would be labeled by the model</li></ul><p>For details of clustering algorithm, refer to <a href>ongoing</a></p><h3 id="one-class-svm">4.2 One-class SVM</h3><h3 id="isolation-forest">4.3 Isolation Forest</h3><h3 id="pca">4.4 PCA</h3><p>PCA can also be utilized as an outlier detection method. In PCA, we would decompose the covariance matrix, the <span class="math inline">\(m^{th}\)</span> eigenvector <span class="math inline">\(\vec{e_m}\)</span> represent present the direction of the <span class="math inline">\(m^{th}\)</span> principle component, and the eigenvalue <span class="math inline">\(\lambda_m\)</span> is the variance on that direction, which also indicates the importance of principal component. Therefore, <span class="math inline">\(\vec{x}\cdot \vec{e_m}\)</span> represents mapping all original features to the direction of <span class="math inline">\(m^{th}\)</span> principal component and adding up all decomposed vectors on that direction, as <span class="math inline">\(\vec{x}\)</span> is standardized.</p><p>Thus, we can define the deviation extent of an sample on a certain principle component direction: <span class="math display">\[d_m = \frac{\vec{x_i}\cdot \vec{e_m}}{\lambda_m}\]</span> The role of <span class="math inline">\(\lambda\)</span> is to make deviation extent more comparable, as the size of variance can be different to some degree.</p><p>With such definition, we might discover the deviation extent of an outlier could probably larger on each direction are generally higer, as shown below:</p><p><img src="/2022/10/07/outlier/4.png"></p><p>we can define the Anomaly score of a data point as: <span class="math display">\[Score(x_i) = \sum_m d_m\]</span> The higher this score is, the more likely a data point would be an outlier.</p><p>This score is equalvalent to the Mahalanobis Distance between the data sample and the mean, as the M distance is the euclidean distance in standard principal components space: <span class="math display">\[D = \sqrt{(X-\mu)^TS^{-1}(X-\mu)}=\sqrt{X^TE\lambda^{-1}E^{-1}X} = \sqrt{\frac{(EX)^2}{\lambda}} = \sqrt{d}\]</span> In this equation:</p><ul><li>X is standardized vector, <span class="math inline">\(\mu\)</span> is thus 0</li><li><span class="math inline">\(S^{-1}\)</span> is the inverse of the covariance matrix</li><li><span class="math inline">\(\lambda\)</span> is the eigenvalues matrix, which is a diagnal matrix, <span class="math inline">\(\lambda^{-1} = \frac{1}{\lambda}\)</span></li><li>E is the eigenvalues matrix, which is a orthonormal matrix, <span class="math inline">\(E^{-1} = E^T\)</span></li></ul>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Outlier</tag>
      
      <tag>Data Preprocess</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ç¬”è¯•ä¸­è¾ƒéš¾SQLè€ƒé¢˜æ€»ç»“</title>
    <link href="/2022/09/30/SQL-problems/"/>
    <url>/2022/09/30/SQL-problems/</url>
    
    <content type="html"><![CDATA[<h1 id="ç¬”è¯•å¸¸è§sqléš¾é¢˜">ç¬”è¯•å¸¸è§SQLéš¾é¢˜</h1><h2 id="ç”¨æˆ·è¿žç»­ç™»å½•">1. ç”¨æˆ·è¿žç»­ç™»å½•</h2><p><img src="/2022/09/30/SQL-problems/1.PNG"></p><p><strong>æ€è·¯</strong>ï¼š</p><ol type="1"><li><p>ä»¥ç”¨æˆ·ä¸ºç»„ï¼Œæ—¥æœŸä¸ºåºï¼Œæ¯ä¸€è¡Œè®°å½•åŠ ä¸Šä¸€ä¸ªè¡Œå·</p><p>æ³¨æ„ï¼Œä¸€ä¸ªç”¨æˆ·ä¸€å¤©å¯ä»¥ç™»å½•å¤šæ¬¡ï¼Œå¦‚æžœå…¨éƒ¨æŽ’å·ï¼Œè¿™ä¸ªæ–¹æ³•å°±å¤±æ•ˆäº†ï¼Œæ‰€ä»¥åŠ ä¸€ä¸ªgroup byï¼Œä½†æ˜¯ä¸èšåˆï¼Œè¿™ç›¸å½“äºŽé€‰æ‹©äº†distinctï¼ˆuser_id sales_dateï¼‰çš„ç»„åˆ</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <br>    user_id,<br>    sales_date,<br>    <span class="hljs-built_in">row_number</span>() <span class="hljs-keyword">over</span>(<span class="hljs-keyword">partition</span> <span class="hljs-keyword">by</span> user_id <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> sales_date) rn<br><span class="hljs-keyword">from</span> sales_tb<br><span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> user_id,<span class="hljs-type">date</span>()<br></code></pre></td></tr></table></figure></li><li><p>å°†ä¸Šè¡¨ä½œä¸ºcteï¼Œç”¨user_id, date_sub(current_date, interval rn day) group byï¼Œ è¿™æ ·ç›¸å½“äºŽæŠŠè¿žç»­çš„å¤©æ•°èšåˆåˆ°äº†åŒä¸€ä¸ªå¤©ï¼ˆ1/3 -1ï¼Œ 1/4 -2ï¼Œ 1/6 - 3 ä¸­æ–­ï¼‰</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">with</span> cte <span class="hljs-keyword">as</span> (<br><span class="hljs-keyword">select</span> <br>    user_id,<br>    sales_date,<br>    <span class="hljs-built_in">row_number</span>() <span class="hljs-keyword">over</span>(<span class="hljs-keyword">partition</span> <span class="hljs-keyword">by</span> user_id <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> sales_date) rn<br><span class="hljs-keyword">from</span> sales_tb<br><span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> user_id,sales_date<br>)<br><span class="hljs-keyword">select</span> <br><span class="hljs-built_in">count</span>(<span class="hljs-operator">*</span>) <br><span class="hljs-keyword">from</span> cte <br><span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> user_id, date_sub(sales_date,<span class="hljs-type">interval</span> rn <span class="hljs-keyword">day</span>) <br><br></code></pre></td></tr></table></figure></li></ol><h3 id="å˜ä½“è¿žç»­ç­¾åˆ°é¢†å–é‡‘å¸">å˜ä½“ï¼šè¿žç»­ç­¾åˆ°é¢†å–é‡‘å¸</h3><p><img src="/2022/09/30/SQL-problems/4.PNG"></p><p>æ€è·¯ï¼š</p><ol type="1"><li>ä¸Žä¸Šé¢˜ä¸€æ ·ï¼Œå°†uidå’Œç™»å½•æ—¥æœŸcombine-distinctåŽï¼ŒåŠ ä¸Šä¸€åˆ—è¡Œå·</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs SQL"><span class="hljs-keyword">SELECT</span><br>uid,<br><span class="hljs-type">date</span>(in_time) <span class="hljs-keyword">as</span> login_date,<br><span class="hljs-built_in">row_number</span>() <span class="hljs-keyword">over</span>(<span class="hljs-keyword">partition</span> <span class="hljs-keyword">by</span>  uid <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> <span class="hljs-type">date</span>(in_time)) <span class="hljs-keyword">as</span> rn<br><span class="hljs-keyword">from</span> <br>tb_user_log<br><span class="hljs-keyword">where</span> <span class="hljs-type">date</span>(in_time) <span class="hljs-operator">&gt;=</span> <span class="hljs-string">&#x27;2021-07-07&#x27;</span> <span class="hljs-keyword">and</span> <span class="hljs-type">date</span>(in_time) <span class="hljs-operator">&lt;</span> <span class="hljs-string">&#x27;2021-11-01&#x27;</span><br>             <span class="hljs-keyword">and</span> sign_in <span class="hljs-operator">=</span> <span class="hljs-number">1</span><br>            <span class="hljs-keyword">and</span> artical_id <span class="hljs-operator">=</span> <span class="hljs-number">0</span><br><span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">BY</span> uid, <span class="hljs-type">date</span>(in_time)<br></code></pre></td></tr></table></figure><ol start="2" type="1"><li>å°†ä¸Šè¡¨ä½œä¸ºcteï¼ŒåŒæ ·é€šè¿‡å‡åŽ»è¡Œå·çš„æ–¹å¼ï¼Œå°†è¿žç»­çš„ç­¾åˆ°å¤©æ•°èšåˆåˆ°ä¸€å¤©ï¼ˆpast dayï¼‰</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs SQL"><span class="hljs-keyword">select</span> <br>uid,<br>date_sub(login_date, <span class="hljs-type">interval</span> rn <span class="hljs-keyword">DAY</span>) ad,<br><span class="hljs-built_in">count</span>(<span class="hljs-operator">*</span>) <span class="hljs-keyword">as</span> days,<br><span class="hljs-built_in">FLOOR</span>(<span class="hljs-built_in">count</span>(<span class="hljs-operator">*</span>)<span class="hljs-operator">/</span><span class="hljs-number">7</span>) <span class="hljs-keyword">as</span> fac,<br><span class="hljs-built_in">count</span>(<span class="hljs-operator">*</span>)<span class="hljs-operator">%</span><span class="hljs-number">7</span> <span class="hljs-keyword">as</span> res<br><span class="hljs-keyword">from</span> cte <br><span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">by</span> uid, date_sub(login_date, <span class="hljs-type">interval</span> rn <span class="hljs-keyword">DAY</span>)<br></code></pre></td></tr></table></figure><ol start="3" type="1"><li>å°†ä¸Šè¡¨ä½œä¸ºcte2ï¼Œ å¢žåŠ ä¸¤åˆ—<ol type="1"><li>å°†past day + lagï¼ˆday countsï¼‰+ 1ï¼Œ è¿™æ ·ç›¸å½“äºŽæ‰¾åˆ°äº†åŒuidä¸‹ä¸Šä¸€æ¬¡è¿žç»­ç™»å½•äº†å‡ å¤©ï¼Œç”±äºŽå½“å‰è¡Œçš„past day æ˜¯ç”±å…¶æ‰€ä»£è¡¨çš„è¿žç»­ç­¾åˆ°å¤©æ•°çš„ä¸€å¤©å‡æŽ‰å…¶è¡Œå·æ‰€å¾—åˆ°çš„ï¼Œè€Œè¿™ä¸ªè¡Œå·æ¯”ä¸Šä¸€è¡Œçš„æœ€å¤§è¿žç»­ç­¾åˆ°å¤©æ•°å†å¤§1ï¼Œæ‰€ä»¥æ˜¯past + lag + 1</li><li>æ ¹æ®å¤©æ•°è®¡ç®—åŠé‡‘å¸æ•°é‡</li></ol></li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs SQL"><span class="hljs-keyword">select</span> <br>    uid,<br>    date_add(ad, <span class="hljs-type">interval</span> (ifnull(<span class="hljs-built_in">lag</span>(days) <span class="hljs-keyword">over</span>(<span class="hljs-keyword">partition</span> <span class="hljs-keyword">by</span> uid <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> ad),<span class="hljs-number">0</span>)<span class="hljs-operator">+</span><span class="hljs-number">1</span>) <span class="hljs-keyword">DAY</span>) cd,<br>    <span class="hljs-keyword">case</span><br>    <span class="hljs-keyword">when</span> res <span class="hljs-operator">&lt;</span> <span class="hljs-number">3</span> <span class="hljs-keyword">then</span> fac<span class="hljs-operator">*</span><span class="hljs-number">15</span> <span class="hljs-operator">+</span> res<br>    <span class="hljs-keyword">when</span> res <span class="hljs-operator">&gt;=</span> <span class="hljs-number">3</span> <span class="hljs-keyword">then</span> fac<span class="hljs-operator">*</span><span class="hljs-number">15</span> <span class="hljs-operator">+</span> res<span class="hljs-operator">+</span><span class="hljs-number">2</span><br>    <span class="hljs-keyword">end</span> coin<br><span class="hljs-keyword">from</span> cte2<br></code></pre></td></tr></table></figure><ol start="4" type="1"><li>ä»¥ä¸Šè¡¨ä¸ºcte3ï¼Œæ ¹æ®uidï¼Œæœˆä»½èšåˆï¼Œå¾—åˆ°ç»“æžœï¼Œæ³¨æ„æ—¶é—´æ ¼å¼æŠ½å–å‡½æ•°çš„è¿ç”¨</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs SQL"><span class="hljs-keyword">select</span> <br>    uid,<br>    date_format(cd,&quot;%Y%m&quot;),<br>    <span class="hljs-built_in">sum</span>(coin)<br><span class="hljs-keyword">from</span> cte3<br><span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> uid, date_format(cd,&quot;%Y%m&quot;)<br></code></pre></td></tr></table></figure><h3 id="æŠ€å·§mysql-æ—¶é—´æ ¼å¼åŒ–å‡½æ•°">æŠ€å·§ï¼šMySQL æ—¶é—´æ ¼å¼åŒ–å‡½æ•°</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <br>date_format(target_datetime, <span class="hljs-string">&#x27;%Y-%m-...&#x27;</span>)<br><span class="hljs-keyword">from</span><br>tb_time<br></code></pre></td></tr></table></figure><p>æ ¼å¼å…·ä½“ä»£ç å¦‚ä¸‹</p><p><img src="/2022/09/30/SQL-problems/2.PNG"></p><p><img src="/2022/09/30/SQL-problems/3.PNG"></p><h2 id="åŒä¸€æ—¶é—´æœ€å¤§è§‚çœ‹äººæ•°">2. åŒä¸€æ—¶é—´æœ€å¤§è§‚çœ‹äººæ•°</h2><p><img src="/2022/09/30/SQL-problems/5.PNG"></p><p>æ€è·¯ï¼š</p><ol type="1"><li>å°†è¿›å…¥å’Œç™»å‡ºunionèµ·æ¥ï¼Œå¹¶æŠŠè¿›å…¥è®°ä¸º1ï¼Œé€€å‡ºè®°ä¸º-1</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs SQL"><span class="hljs-keyword">select</span> <br>    artical_id,<br>    uid,<br>    in_time <span class="hljs-keyword">as</span> tn,<br>    <span class="hljs-number">1</span> person<br><span class="hljs-keyword">from</span> tb_user_log<br><span class="hljs-keyword">where</span> artical_id <span class="hljs-operator">!=</span> <span class="hljs-number">0</span><br><span class="hljs-keyword">UNION</span><br><span class="hljs-keyword">select</span> <br>    artical_id,<br>    uid,<br>    out_time <span class="hljs-keyword">as</span> tn,<br>    <span class="hljs-number">-1</span> person<br><span class="hljs-keyword">from</span> tb_user_log<br><span class="hljs-keyword">where</span> artical_id <span class="hljs-operator">!=</span> <span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><ol start="2" type="1"><li>ä»¥ä¸Šè¡¨ä¸ºcteï¼Œä»¥æ–‡ç« ä¸ºç»„ï¼Œæ ¹æ®æ–‡ç« ï¼Œæ—¶é—´ç‚¹ï¼Œäººæ•°æŽ’åºï¼Œç”¨sumè®°å½•å½“å‰å®žæ—¶äººæ•° running total</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs SQL"><span class="hljs-keyword">select</span><br><span class="hljs-operator">*</span>,<br><span class="hljs-built_in">sum</span>(person) <span class="hljs-keyword">over</span>(<span class="hljs-keyword">partition</span> <span class="hljs-keyword">by</span> artical_id <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> artical_id, tn <span class="hljs-keyword">asc</span>, person <span class="hljs-keyword">DESC</span> <span class="hljs-keyword">rows</span> <span class="hljs-keyword">BETWEEN</span> UNBOUNDED PRECEDING <span class="hljs-keyword">and</span> <span class="hljs-keyword">CURRENT</span> <span class="hljs-type">ROW</span> ) <span class="hljs-keyword">as</span> p_count<br><span class="hljs-keyword">from</span> <br>cte1<br></code></pre></td></tr></table></figure><ol start="3" type="1"><li>ä»¥ä¸Šè¡¨ä¸ºcteï¼Œé€‰å–å„æ–‡ç« ç»„åˆ«ç»„åˆ«ä¸­å®žæ—¶äººæ•°æœ€å¤§çš„æ—¶é—´èŠ‚ç‚¹</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs SQL"><span class="hljs-keyword">select</span> artical_id, <span class="hljs-built_in">max</span>(p_count) <span class="hljs-keyword">as</span> max_read<br><span class="hljs-keyword">from</span> cte2 <br><span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> artical_id<br><span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> max_read <span class="hljs-keyword">desc</span><br></code></pre></td></tr></table></figure><h2 id="æ–°ç”¨æˆ·çš„æ¬¡æ—¥ç•™å­˜çŽ‡">3. æ–°ç”¨æˆ·çš„æ¬¡æ—¥ç•™å­˜çŽ‡</h2><p><img src="/2022/09/30/SQL-problems/6.PNG"></p><ol type="1"><li>ç”±äºŽè·¨å¤©ç™»å…¥ç™»å‡ºç®—éƒ½æ´»è·ƒï¼Œæ‰€ä»¥å°†inå’Œout unionèµ·æ¥ï¼Œç„¶åŽç”¨group by uidï¼Œdate(time) æ¥åŽ»é™¤ä¸€å¤©å†…é‡å¤çš„æ´»è·ƒè®°å½•ï¼ˆç›¸å½“äºŽåªè®°å½•æ¯å¤©æœ‰æ²¡æœ‰æ´»è·ƒï¼‰</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs SQL"><span class="hljs-keyword">select</span> <br>    uid,<span class="hljs-type">date</span>(in_time) <span class="hljs-keyword">as</span> tn<br><span class="hljs-keyword">from</span> tb_user_log<br><span class="hljs-keyword">union</span><br><span class="hljs-keyword">select</span> <br>    uid, <span class="hljs-type">date</span>(out_time) <span class="hljs-keyword">as</span> tn<br><span class="hljs-keyword">from</span> tb_user_log<br><span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> uid,<span class="hljs-type">date</span>(tn)<br></code></pre></td></tr></table></figure><ol start="2" type="1"><li>ä»¥ä¸Šå›¾ä¸ºcte<ol type="1"><li>å¢žåŠ ä¸€åˆ—åˆ¤æ–­è¯¥ç”¨æˆ·æœ¬æ¬¡ç™»å½•æ—¶æ˜¯å¦ä¸ºæ–°ç”¨æˆ·ï¼ˆä»¥ç”¨æˆ·ä¸ºç»„ï¼Œæ—¶é—´ä¸ºåºï¼Œç»™æ¯ä¸€æ¬¡ç™»å½•ä¸€ä¸ªrow numberï¼Œ æ–°ç”¨æˆ·row_numbeä¸º1ï¼‰</li><li>left joinè‡ªèº« on ï¼ˆ1.day+1 = 2.dayï¼‰ï¼Œå¢žåŠ ä¸€åˆ—åˆ¤æ–­è¯¥ç”¨æˆ·åœ¨åŽä¸€å¤©æ˜¯å¦æ´»è·ƒï¼ˆleft joinè‡ªèº«ï¼Œå¦‚æžœåŽä¸€å¤©æœªæ´»è·ƒï¼Œåˆ™ä¼šå¾—åˆ°nullï¼‰</li></ol></li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs SQL"><span class="hljs-keyword">select</span> a1.<span class="hljs-operator">*</span>, <br>    <span class="hljs-keyword">case</span><br>    <span class="hljs-keyword">when</span> <span class="hljs-built_in">row_number</span>() <span class="hljs-keyword">over</span>(<span class="hljs-keyword">partition</span> <span class="hljs-keyword">by</span> a1.uid <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> a1.tn) <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">then</span> <span class="hljs-string">&#x27;NEW&#x27;</span><br>    <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;OLD&#x27;</span><br>    <span class="hljs-keyword">end</span> user_status,<br>    <span class="hljs-keyword">case</span><br>    <span class="hljs-keyword">when</span> a2.uid <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span> <span class="hljs-keyword">then</span> <span class="hljs-number">1</span><br>    <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br>    <span class="hljs-keyword">end</span> next_day<br><span class="hljs-keyword">from</span> active a1<br><span class="hljs-keyword">left</span> <span class="hljs-keyword">join</span> active a2 <span class="hljs-keyword">ON</span><br>date_add(a1.tn,<span class="hljs-type">interval</span> <span class="hljs-number">1</span> <span class="hljs-keyword">day</span>) <span class="hljs-operator">=</span> a2.tn<br><span class="hljs-keyword">and</span><br>a1.uid <span class="hljs-operator">=</span> a2.uid<br></code></pre></td></tr></table></figure><ol start="3" type="1"><li>ä»¥ä¸Šè¡¨ä¸ºcteï¼Œåœ¨whereè¯­å¥ä¸­åŠ å…¥åªè®¡ç®—æ–°ç”¨æˆ·ï¼Œæœˆä»½ä¸º11ç­‰æ¡ä»¶ï¼Œgroup byèšåˆï¼Œè®¡ç®—æ¯å¤©çš„çš„ä»Šæ—¥æ–°ç”¨æˆ·æ¬¡æ—¥ç•™å­˜æ•°/ä»Šæ—¥æ–°ç”¨æˆ·æ€»æ•°</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs SQL"><span class="hljs-keyword">select</span> <br>tn,<br>round(<span class="hljs-built_in">sum</span>(next_day)<span class="hljs-operator">/</span><span class="hljs-built_in">count</span>(<span class="hljs-operator">*</span>),<span class="hljs-number">2</span>) <span class="hljs-keyword">as</span> uv_left_rate<br><span class="hljs-keyword">from</span> cte <span class="hljs-keyword">where</span> user_status  <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;NEW&#x27;</span><br> <span class="hljs-keyword">and</span> <span class="hljs-keyword">month</span>(tn) <span class="hljs-operator">=</span> <span class="hljs-number">11</span><br><span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> tn<br><span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> tn <br></code></pre></td></tr></table></figure><h2 id="è¡Œåˆ—ç½®æ¢">4.è¡Œåˆ—ç½®æ¢</h2><p>è¦å¯¹æ¯ä¸€åˆ—çš„å€¼è¿›è¡Œèšåˆï¼Œåœ¨æŠŠå…¶ä½œä¸ºä¸€è¡Œè¾“å‡º</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs SQL"><span class="hljs-keyword">select</span> <span class="hljs-string">&#x27;column_1&#x27;</span>,<span class="hljs-built_in">sum</span>(column_1), <span class="hljs-built_in">count</span>(column_1) <br><span class="hljs-keyword">from</span> orders<br><span class="hljs-keyword">union</span><br><span class="hljs-keyword">select</span> <span class="hljs-string">&#x27;column_2&#x27;</span>,<span class="hljs-built_in">sum</span>(column_2), <span class="hljs-built_in">count</span>(column_2) <br><span class="hljs-keyword">from</span> orders<br></code></pre></td></tr></table></figure><h3 id="æŠ€å·§ä»Žcsvå¯¼å…¥æ–‡ä»¶">æŠ€å·§ï¼šä»Žcsvå¯¼å…¥æ–‡ä»¶</h3><p>æ ‡å‡†çš„å¯¼å…¥è¯­æ³•ä¸º</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs SQL">LOAD DATA INFILE <span class="hljs-string">&#x27;path&#x27;</span><br><span class="hljs-keyword">INTO</span> <span class="hljs-keyword">TABLE</span> tb<br>FIELDS TERMINATED <span class="hljs-keyword">BY</span> <span class="hljs-string">&#x27;,&#x27;</span><br>ENCLOSED <span class="hljs-keyword">BY</span> <span class="hljs-string">&#x27;&quot;&#x27;</span><br>LINES TERMINATED <span class="hljs-keyword">BY</span> <span class="hljs-string">&#x27;\n&#x27;</span><br>IGNORE <span class="hljs-number">1</span> LINES<br></code></pre></td></tr></table></figure><p>æ³¨æ„ï¼š</p><ol type="1"><li><p>æ–‡ä»¶å¿…é¡»æ”¾åœ¨MYSQLæŒ‡å®šçš„å®‰å…¨æ–‡ä»¶å¤¹ä¸­ï¼Œæ‰èƒ½å¯¼å…¥ï¼Œå¯ä»¥ä½¿ç”¨è¯­å¥</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs SQL"><span class="hljs-keyword">SHOW</span> VARIABLES <span class="hljs-keyword">LIKE</span> <span class="hljs-string">&#x27;secure_file_priv&#x27;</span><br></code></pre></td></tr></table></figure><p>æ¥æŸ¥çœ‹</p></li><li><p>æ–‡ä»¶è·¯å¾„ä¸­çš„åæ–œæ /</p></li><li><p>è‹¥åœ¨windowsæ–‡ä»¶å¤¹ä¸‹ï¼Œè¡Œæˆªæ­¢ç¬¦åº”ä¸º ''</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs SQL">LINES TERMINATED <span class="hljs-keyword">BY</span> <span class="hljs-string">&#x27;\r\n&#x27;</span><br></code></pre></td></tr></table></figure></li><li><p>IGNORE ç”¨äºŽè·³è¿‡è¡¨å¤´è¡Œ</p></li></ol><h2 id="é€‰å–ç»„å†…æœ€å°çš„å¦ä¸€ç§æ€è·¯">5. é€‰å–ç»„å†…æœ€å°çš„å¦ä¸€ç§æ€è·¯</h2><p><img src="/2022/09/30/SQL-problems/7.PNG"></p><p>æ€è·¯ï¼š</p><p>è¿™é‡Œä¸ä½¿ç”¨çª—å£å‡½æ•°å’Œå­è¯­å¥ï¼Œå› ä¸ºé‚£æ ·ä¸æ–¹ä¾¿æŸ¥æ‰¾minï¼ˆdateï¼‰æ‰€å¯¹åº”çš„device</p><ol type="1"><li>ä»¥æ‰€æœ‰è¯¥ç”¨æˆ·çš„event_dateä¸ºå­æŸ¥è¯¢ï¼Œé€‰å–ç»„å†…å°äºŽç­‰äºŽä»»ä½•event_dateçš„ event dateï¼Œå¾—åˆ°çš„å°±æ˜¯ç»„å†…æœ€å°å€¼ï¼Œä¸”å¯ä»¥ç®€å•çš„å¾—åˆ°æœ€å°å€¼å¯¹åº”è¡Œçš„å…¶ä»–æ•°æ®</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs SQL"><span class="hljs-keyword">SELECT</span> player_id, device_id <span class="hljs-keyword">from</span> Activity a1<br><span class="hljs-keyword">WHERE</span> event_date <span class="hljs-operator">&lt;=</span> <span class="hljs-keyword">ALL</span>(<span class="hljs-keyword">SELECT</span> event_date <span class="hljs-keyword">FROM</span> Activity a2 <span class="hljs-keyword">WHERE</span> a1.player_id <span class="hljs-operator">=</span> a2.player_id );<br></code></pre></td></tr></table></figure><h2 id="é€‰å–ç¬¬äºŒé«˜çš„è–ªæ°´">6. é€‰å–ç¬¬äºŒé«˜çš„è–ªæ°´</h2><p><img src="/2022/09/30/SQL-problems/8.PNG"></p><p>æ€è·¯ï¼š</p><p>å¯ä»¥ä½¿ç”¨dense_rankè¿›è¡ŒæŽ’åºï¼Œä½†è¿™é‡Œä½¿ç”¨å¦ä¸€ç§æ–¹å¼</p><ol type="1"><li>é€‰å‡ºdistinctçš„salaryï¼Œé™åºæŽ’åˆ—ï¼Œç„¶åŽä½¿ç”¨limit offsetè¿›è¡Œç­›é€‰</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs SQL"><span class="hljs-keyword">SELECT</span> <span class="hljs-keyword">DISTINCT</span><br>    Salary <span class="hljs-keyword">AS</span> SecondHighestSalary<br><span class="hljs-keyword">FROM</span><br>    Employee<br><span class="hljs-keyword">ORDER</span> <span class="hljs-keyword">BY</span> Salary <span class="hljs-keyword">DESC</span><br>LIMIT <span class="hljs-number">1</span> <span class="hljs-keyword">OFFSET</span> <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><ol start="2" type="1"><li>åŠ ä¸Šifnull</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span><br>    IFNULL(<br>      (<span class="hljs-keyword">SELECT</span> <span class="hljs-keyword">DISTINCT</span> Salary<br>       <span class="hljs-keyword">FROM</span> Employee<br>       <span class="hljs-keyword">ORDER</span> <span class="hljs-keyword">BY</span> Salary <span class="hljs-keyword">DESC</span><br>        LIMIT <span class="hljs-number">1</span> <span class="hljs-keyword">OFFSET</span> <span class="hljs-number">1</span>),<br>    <span class="hljs-keyword">NULL</span>) <span class="hljs-keyword">AS</span> SecondHighestSalary<br></code></pre></td></tr></table></figure><h3 id="æŠ€å·§æœ‰å…³limitå’Œoffsetçš„ä½¿ç”¨">æŠ€å·§ï¼šæœ‰å…³limitå’Œoffsetçš„ä½¿ç”¨</h3><ol type="1"><li><p>å½“limitåŽè·Ÿä¸€ä¸ªå‚æ•°æ—¶ï¼Œè¡¨ç¤ºä»Žå¤´å¼€å§‹é€‰å–è‹¥å¹²è¡Œ</p><p><code>select * from tb limit 3</code></p></li><li><p>å½“limitåŽè·Ÿä¸¤ä¸ªå‚æ•°æ—¶ï¼Œè¡¨ç¤ºä»Žå¤´å¼€å§‹è·³è¿‡aè¡Œï¼Œå†é€‰å–ä¹‹åŽçš„bè¡Œ</p><p><code>select * from tb limit 2,3 --è·³è¿‡1-2è¡Œï¼Œé€‰å–3-5è¡Œ</code></p></li><li><p>limit offset ç»„åˆä½¿ç”¨æ—¶ï¼ŒlimitåŽåªè·Ÿä¸€ä¸ªå‚æ•°è¡¨ç¤ºé€‰å–å¤šå°‘è¡Œï¼ŒoffsetåŽä¸€ä¸ªå‚æ•°ï¼Œè¡¨ç¤ºè·³è¿‡å¤šå°‘è¡Œ</p><p><code>select * from tb limit 3 offset 2 --æ•ˆæžœåŒ 2.</code></p></li></ol><h2 id="æŠ€å·§ä»Žjsonå¯¼å…¥æ•°æ®">7.æŠ€å·§ï¼šä»Žjsonå¯¼å…¥æ•°æ®</h2><p>ä¼¼ä¹Žæœ‰ä¸“é—¨çš„å¯¼å…¥å·¥å…·ï¼Œæš‚æ—¶å¯ä»¥ä½¿ç”¨<a href="https://data.page/json/csv">æ­¤ç½‘å€</a>,è¾“å…¥jsonæ ¼å¼çš„æ•°æ®ï¼ˆä¸ç”¨è¾“å…¥è¡¨å¤´)ï¼Œå°†å…¶è½¬åŒ–ä¸ºcsvæ–‡ä»¶ï¼Œåœ¨å‚è€ƒ<a href="#æŠ€å·§ï¼šä»Žcsvå¯¼å…¥æ–‡ä»¶">ä»Žcsvå¯¼å…¥æ–‡ä»¶</a></p><h2 id="é€‰æ‹©è¿žç»­ä¸”ä¸ºç©ºçš„åº§ä½">8. é€‰æ‹©è¿žç»­ä¸”ä¸ºç©ºçš„åº§ä½</h2><p><img src="/2022/09/30/SQL-problems/9.PNG"></p><p>æ€è·¯ï¼š</p><p>æ­¤é¢˜åº”è¯¥ä¸Ž<a href="#1.%20ç”¨æˆ·è¿žç»­ç™»å½•">ç”¨æˆ·è¿žç»­ç™»å½•</a>åŒºåˆ†å¼€æ¥ï¼Œæ­¤é—®é¢˜éœ€è¦è¾“å‡ºæ‰€æœ‰è¿žç»­çš„è¡Œå·ï¼Œè€Œä¸éœ€è¦èšåˆï¼Œæ‰€ä»¥ç”¨row numberåˆ¤æ–­å¹¶ä¸æ°å½“</p><ol type="1"><li>å°†è¡¨æ ¼å’Œè‡ªèº«joinèµ·æ¥ï¼Œon<ol type="1"><li>absï¼ˆ1.seat - 2.seatï¼‰= 1</li><li>1.free = 2.free = 1</li></ol></li><li>è¿™æ ·å‡ºçŽ°åœ¨è¡¨æ ¼ä¸­çš„æ¯ä¸€è¡Œéƒ½ä¸€å®šæœ‰ä¸€ä¸ªneighborï¼Œ ä¸”neighbourä¹Ÿä¸ºç©ºåº§ï¼Œæœ€åŽå†é€‰æ‹©distinct</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs SQL"><span class="hljs-keyword">select</span> <span class="hljs-keyword">distinct</span> a.seat_id<br><span class="hljs-keyword">from</span> cinema a <span class="hljs-keyword">join</span> cinema b<br>  <span class="hljs-keyword">on</span> <span class="hljs-built_in">abs</span>(a.seat_id <span class="hljs-operator">-</span> b.seat_id) <span class="hljs-operator">=</span> <span class="hljs-number">1</span><br>  <span class="hljs-keyword">and</span> a.free <span class="hljs-operator">=</span> <span class="hljs-literal">true</span> <span class="hljs-keyword">and</span> b.free <span class="hljs-operator">=</span> <span class="hljs-literal">true</span><br><span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> a.seat_id<br></code></pre></td></tr></table></figure><h2 id="æŠ€å·§ä½¿ç”¨concat">9.æŠ€å·§ï¼šä½¿ç”¨concatï¼ˆï¼‰</h2><p>concat()çš„ä½œç”¨æ˜¯æŠŠä¸¤ä¸ªåˆ—è¿žæŽ¥æˆä¸€ä¸ªåˆ—ï¼Œå½“è¦ä½¿ç”¨ç±»ä¼¼å¦‚ä¸‹è¯­å¥æ—¶</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> <span class="hljs-keyword">table</span> <span class="hljs-keyword">where</span> concat(a,b) <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> (<span class="hljs-keyword">select</span> concat(c,d) <span class="hljs-keyword">from</span> cte)<br></code></pre></td></tr></table></figure><p>æ­¤è¯­å¥é€»è¾‘ä¸ºï¼šåªè¦a,bä¸åŒæ—¶ç­‰äºŽæŸäº›ç‰¹å®šç»„åˆï¼Œå°±å¯ä»¥é€‰æ‹©</p><h2 id="ç´¯ç§¯æ±‚å’Œå·®">10. ç´¯ç§¯æ±‚å’Œ/å·®</h2><p>å¦‚å›¾ï¼Œè‹¥å¹²ä½ä¹˜å®¢è¦ç™»ä¸Šå¤§å·´ï¼Œæ¯ä½ä¹˜å®¢æœ‰ä¸€ç™»è½¦æ¬¡åºï¼Œä¹˜å®¢çš„ä½“é‡åˆ—åœ¨è¡¨ä¸­ï¼Œå¤§å·´è½¦èƒ½å®¹çº³1000KGçš„é‡é‡ï¼Œè¦æ±‚è¿”å›žæœ€åŽä¸€åèƒ½å¤Ÿä¸Šè½¦çš„ä¹˜å®¢çš„å§“å</p><p><img src="/2022/09/30/SQL-problems/10.PNG"></p><p>æ€è·¯ï¼šæŒ‰ç…§ç™»è½¦é¡ºåºï¼Œè®¡ç®—ç™»è½¦ä¹˜å®¢ä½“é‡çš„running totalï¼š</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs SQL"><span class="hljs-keyword">with</span> cte <span class="hljs-keyword">as</span> (<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span>, <br>  <span class="hljs-built_in">sum</span>(weight) <span class="hljs-keyword">over</span>(<span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> turn <span class="hljs-keyword">rows</span> <span class="hljs-keyword">BETWEEN</span> UNBOUNDED PRECEDING <span class="hljs-keyword">and</span> <span class="hljs-keyword">CURRENT</span> <span class="hljs-type">ROW</span>) <span class="hljs-keyword">as</span> roll_sum<br><span class="hljs-keyword">from</span> Quene <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> turn<br></code></pre></td></tr></table></figure><p>ç­›é€‰ä½“é‡running totalå°äºŽç­‰äºŽ1000çš„ä¹˜å®¢ï¼Œå¹¶èŽ·å–æœ€åŽä¸€ä½ä¹˜å®¢çš„å§“å</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs SQL"><span class="hljs-keyword">with</span> allow <span class="hljs-keyword">as</span> (<br>    <span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <br><span class="hljs-keyword">from</span> cte <br><span class="hljs-keyword">where</span> roll_sum <span class="hljs-operator">&lt;=</span><span class="hljs-number">1000</span><br>)<br><span class="hljs-keyword">select</span> person_name <br><span class="hljs-keyword">from</span> allow <br><span class="hljs-keyword">where</span> turn <span class="hljs-operator">=</span> (<span class="hljs-keyword">select</span> <span class="hljs-built_in">max</span>(turn) <span class="hljs-keyword">from</span> allow)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Database</category>
      
    </categories>
    
    
    <tags>
      
      <tag>SQL</tag>
      
      <tag>Interview</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>é¢è¯•ä¸­çš„è´å¶æ–¯æŽ¨æ–­é—®é¢˜</title>
    <link href="/2022/09/29/bayes-inference/"/>
    <url>/2022/09/29/bayes-inference/</url>
    
    <content type="html"><![CDATA[<h1 id="é¢è¯•ä¸­çš„è´å¶æ–¯æŽ¨æ–­é—®é¢˜">é¢è¯•ä¸­çš„è´å¶æ–¯æŽ¨æ–­é—®é¢˜</h1><h2 id="æœ‰å…³è´å¶æ–¯æŽ¨æ–­">1. æœ‰å…³è´å¶æ–¯æŽ¨æ–­</h2><p>è´å¶æ–¯æŽ¨æ–­æ˜¯ä¸€é¡¹ç»Ÿè®¡æŠ€æœ¯ï¼ŒåŸºäºŽè´å¶æ–¯å®šç†ï¼Œé€šè¿‡è§‚å¯Ÿè¯æ®æ¥æ›´æ–°å‡è®¾çš„æ¦‚çŽ‡ã€‚è´å¶æ–¯æŽ¨æ–­å°†å‚æ•°çœ‹ä½œä¸€ä¸ªå˜é‡ï¼Œå› æ­¤å¯ä»¥ç”¨äºŽå‚æ•°ä¼°è®¡ï¼Œä½†æ˜¯åœ¨æ•°æ®å²—ä½é¢è¯•ä¸­ï¼Œä¸€èˆ¬ä»¥è®¡ç®—åŽéªŒæ¦‚çŽ‡çš„æ–¹å¼è€ƒå¯Ÿ</p><p>å®šä¹‰ï¼š</p><ul><li>Hï¼šå‡è®¾å˜é‡ï¼Œä»£è¡¨æŸä¸€äº‹ä»¶å„ç§å¯èƒ½ç»“æžœï¼Œæœä»Žç‰¹å®šåˆ†å¸ƒï¼Œå…¶æ¦‚çŽ‡å¯†åº¦å‡½æ•°ä¸º<span class="math inline">\(f_H\)</span>ï¼ˆå…ˆéªŒæ¦‚çŽ‡åˆ†å¸ƒï¼‰</li><li>Eï¼šè¯æ®å˜é‡ï¼Œç”¨äºŽæ›´æ–°å…ˆéªŒæ¦‚çŽ‡ï¼Œæœä»Žç‰¹å®šåˆ†å¸ƒï¼Œå…¶æ¦‚çŽ‡å¯†åº¦å‡½æ•°ä¸º<span class="math inline">\(f_E\)</span>ï¼ˆè¾¹é™…ä¼¼ç„¶å‡½æ•°ï¼Œè¯æ®åˆ†å¸ƒï¼‰</li><li><span class="math inline">\(f_{E|H}\)</span>ï¼š ä¼¼ç„¶å‡½æ•°ï¼Œå³åœ¨å›ºå®šHçš„å‰æä¸‹ï¼ŒEçš„æ¦‚çŽ‡å¯†åº¦å‡½æ•°</li></ul><p>æ ¹æ®è´å¶æ–¯å®šç†åŠå…¨æ¦‚çŽ‡å…¬å¼ï¼š <span class="math display">\[f_{post}(H=\hat{H}|E=\hat{E}) = \frac{f_{E|H=\hat{H}}(E=\hat{E})f_H(H=\hat{H})}{f_E(E=\hat{E})} = \frac{f_{E|H=\hat{H}}(E=\hat{E})f_H(H=\hat{H})}{\int_{-\infty}^\infty f_{E|H}(E=\hat{E})f_H(H)\mathrm{d}H}\]</span> å…¶ä¸­ï¼š</p><ul><li><span class="math inline">\(f_{post}\)</span> ç§°ä½œåŽéªŒæ¦‚çŽ‡åˆ†å¸ƒï¼Œæ˜¯åŸºäºŽè¯æ®æ›´æ–°åŽçš„å…ˆéªŒæ¦‚çŽ‡åˆ†å¸ƒ</li><li><span class="math inline">\(\hat{H}\)</span> ä¸ºå‡è®¾çš„æŸä¸€ç‰¹å®šå–å€¼</li><li><span class="math inline">\(\hat{E}\)</span> ä¸ºè¯æ®çš„è§‚æµ‹å€¼</li></ul><p>å¼ï¼ˆ1ï¼‰å¯ä»¥ç®€å†™ä¸ºï¼š <span class="math display">\[P(H|E)= \frac{P(E|H)P(H)}{P(E)} = \frac{P(E|H)P(H)}{\sum_i^m P(E|H_i)P(H_i)} = \frac{P(E|H)P(H)}{P(E|H_i)P(H_i)+P(E|\bar{H_i})P(\bar{H_i})}\]</span></p><h2 id="åŽéªŒæ¦‚çŽ‡è®¡ç®—çš„åŸºæœ¬æ¡†æž¶">2. åŽéªŒæ¦‚çŽ‡è®¡ç®—çš„åŸºæœ¬æ¡†æž¶</h2><p>æ•°æ®åˆ†æžåŠæ•°æ®ç§‘å­¦é¢è¯•ä¸­ï¼Œå¤§å¤šæ•°çš„è´å¶æ–¯æŽ¨æ–­é—®é¢˜éƒ½æ˜¯å…·ä½“å–å€¼ä¸‹çš„åŽéªŒæ¦‚çŽ‡è®¡ç®—é—®é¢˜ï¼Œä¸”ä¸€èˆ¬å‡è®¾å˜é‡çš„æ ·æœ¬ç©ºé—´æœ‰é™ï¼Œå…ˆéªŒåˆ†å¸ƒæ˜¯ç¦»æ•£çš„ï¼Œå› æ­¤å…¶åŸºæœ¬åšé¢˜æ¡†æž¶å¯ä»¥å½’ç»“å¦‚ä¸‹ï¼š</p><ol type="1"><li>æ˜Žç¡®é—®é¢˜ä¸­çš„å‡è®¾å˜é‡å’Œè¯æ®å˜é‡åˆ†åˆ«æ˜¯ä»€ä¹ˆ, å¯¹äºŽå‡è®¾å˜é‡ï¼Œç¡®å®šä¸€ä¸ªå®Œå¤‡äº‹ä»¶ç»„</li><li>æ ¹æ®è¦æ±‚çš„ç»“æžœï¼Œç¡®å®šå…³å¿ƒçš„å‡è®¾äº‹ä»¶<span class="math inline">\(A_ k\)</span>å’Œè¯æ®äº‹ä»¶B, å¹¶ç¡®å®šå…ˆéªŒæ¦‚çŽ‡P(A)</li><li>å¯¹äºŽå®Œå¤‡äº‹ä»¶ç»„ä¸­æ¯ä¸€ä¸ªå‡è®¾äº‹ä»¶<span class="math inline">\(A_ i\)</span>, è®¡ç®—ç›¸åº”çš„ä¼¼ç„¶æ€§<span class="math inline">\(P(B| A_i)\)</span></li><li>æ ¹æ®è´å¶æ–¯å®šç†åŠå…¨æ¦‚çŽ‡å…¬å¼è®¡ç®—åŽéªŒæ¦‚çŽ‡<span class="math inline">\(P(A_i| B)\)</span>ï¼Œ å¦‚æžœæœ‰å¤šè½®è¿­ä»£ï¼ŒæŠŠå‰ä¸€è½®çš„åŽéªŒæ¦‚çŽ‡å½“ä½œåŽä¸€è½®çš„å…ˆéªŒæ¦‚çŽ‡</li></ol><h2 id="å¸¸è§é¢˜åž‹å’Œä¾‹é¢˜è§£æž">3. å¸¸è§é¢˜åž‹å’Œä¾‹é¢˜è§£æž</h2><h3 id="æ£€æµ‹é—®é¢˜">3.1 æ£€æµ‹é—®é¢˜</h3><p><strong>ä¾‹é¢˜</strong>ï¼šå·²çŸ¥æŸè‚ºç‚Žçš„æ‚£ç—…çŽ‡ä¸º0.01%ã€‚çŽ°åœ¨éœ€è¦åšæ£€æµ‹ï¼Œå¦‚æžœè¢«æµ‹è€…æ‚£ç—…åˆ™è¢«æ£€æµ‹ä¸ºé˜³æ€§çš„æ¦‚çŽ‡ä¸º99%ã€‚å¦‚æžœè¢«æµ‹è€…æ²¡æœ‰ç—…åˆ™è¢«æ£€æµ‹ä¸ºé˜´æ€§çš„æ¦‚çŽ‡ä¸º99.9%ã€‚çŽ°åœ¨ä¸€ä¸ªäººæ£€æŸ¥ç»“æžœæ˜¯é˜³æ€§ã€‚é—®çœŸæ­£å¾—ç—…çš„æ¦‚çŽ‡æ˜¯å¤šå°‘ï¼Ÿ</p><p>æ­¤ç±»é—®é¢˜çš„ç‰¹ç‚¹ä¸ºï¼šå…ˆéªŒåˆ†å¸ƒå’Œè¯æ®åˆ†å¸ƒéƒ½ä¸ºäºŒå€¼/å¤šå€¼åˆ†å¸ƒ</p><ul><li>å‡è®¾å˜é‡ï¼šæ‚£è€…çœŸæ­£å¾—ç—…ï¼Œæœ‰å¾—ç—…å’Œä¸å¾—ç—…ä¸¤ç§ç»“æžœ</li><li>è¯æ®å˜é‡ï¼šæ‚£è€…è¢«æ£€æµ‹å‡ºå¾—ç—…ï¼Œæœ‰æ£€æµ‹å‡ºå¾—ç—…å’Œæ£€æµ‹å‡ºä¸å¾—ç—…ä¸¤ç§ç»“æžœ</li></ul><p>ä»¤ï¼š</p><ul><li>Aäº‹ä»¶ä¸ºæ‚£è€…çœŸæ­£å¾—ç—… <span class="math inline">\(P(A) = P(H=true\ positive)\)</span></li><li>Bäº‹ä»¶ä¸ºæ‚£è€…è¯Šæ–­å¾—ç—…<span class="math inline">\(P(B) = P(E = diagnosed \ positive)\)</span></li></ul><p><span class="math display">\[P(A) = 0.01\%\]</span></p><p><span class="math display">\[P(B|A) = 99\%\\\]</span></p><p><span class="math display">\[P(B) = P(B|A)P(A)+P(B|\bar{A})P(\bar{A}) = 99\%*0.01\% + 0.1\%*99.99\%\]</span></p><p>å¯è®¡ç®—å¾—åˆ°åŽéªŒæ¦‚çŽ‡ä¸ºï¼š <span class="math display">\[P(A|B) = 9.01\%\]</span> å¯è§è¯Šæ–­åŽåŽï¼Œæ‚£è€…å¾—ç—…æ¦‚çŽ‡ä¸Šå‡ï¼ŒåŽŸæœ¬è®¤ä¸ºå¾—ç—…æ¦‚çŽ‡ä¸º0.01%ï¼Œç»è¿‡ä¸€ä¸ªåªåŒ…å«ä¸€ä¸ªäººçš„æ ·æœ¬é‡æ–°è®¡ç®—ï¼Œæ›´æ–°ä¸ºäº†9.01%</p><h3 id="ç¡¬å¸é—®é¢˜">3.2 ç¡¬å¸é—®é¢˜</h3><p>å‡è®¾æœ‰100æžšç¡¬å¸ï¼Œå…¶ä¸­70æžšä¸ºæ­£å¸¸ï¼Œ30æžšä¸ºç¼ºé™·ï¼Œä»Žä¸­å–å‡º1æžšæŠ•æŽ·10æ¬¡ï¼Œ10æ¬¡ä¸­9æ¬¡ä¸ºæ­£é¢ï¼Œ1æ¬¡ä¸ºè´Ÿé¢ã€‚å½“ç¡¬å¸æ­£å¸¸æ—¶ï¼ŒæŠ•å‡ºæ­£é¢çš„æ¦‚çŽ‡ä¸º0.5ï¼Œå½“ç¡¬å¸ç¼ºé™·æ—¶ï¼ŒæŠ•å‡ºæ­£é¢çš„æ¦‚çŽ‡ä¸º0.8ã€‚æ±‚ç¡¬å¸ç¼ºé™·çš„æ¦‚çŽ‡</p><p>æ­¤ç±»é—®é¢˜çš„ç‰¹ç‚¹ä¸ºï¼Œå…ˆéªŒåˆ†å¸ƒæ˜¯äºŒå€¼åˆ†å¸ƒï¼Œè¯æ®åˆ†å¸ƒæ˜¯ä¼¯åŠªåˆ©åˆ†å¸ƒ</p><ul><li>å‡è®¾å˜é‡ï¼šç¡¬å¸æœ‰ç¼ºé™·ï¼Œæœ‰æ˜¯å¦ä¸¤ç§å¯èƒ½</li><li>è¯æ®å˜é‡ï¼šæŠ•å‡ºnæ¬¡æ­£é¢ï¼Œå…¶æ¦‚çŽ‡ä¸º<span class="math inline">\(p^n*q^{1-n}\)</span></li></ul><p>ä»¤ï¼š</p><ul><li>Aäº‹ä»¶ä¸ºç¡¬å¸æœ‰ç¼ºé™· <span class="math inline">\(P(A) = P(H = defective)\)</span></li><li>Bäº‹ä»¶ä¸ºæŠ•å‡º9æ¬¡æ­£é¢<span class="math inline">\(P(B) = P(E = 9 \ head)\)</span></li></ul><p><span class="math display">\[P(A) = 0.3\]</span></p><p><span class="math display">\[P(B|A) = 0.8^9*0.2^1\\\]</span></p><p><span class="math display">\[P(B) = P(B|A)P(A)+P(B|\bar{A})P(\bar{A}) = 0.8^9*0.2^1 *0.3 + 0.5^9*0.5^1*0.7\]</span></p><p>å¯è®¡ç®—å¾—åˆ°åŽéªŒæ¦‚çŽ‡ä¸ºï¼š <span class="math display">\[P(A|B) = 91.2\%\]</span> ä¸Žæ­¤ç±»ä¼¼çš„é—®é¢˜æœ‰æœ‹å‹è¯´è°Žé—®é¢˜ç­‰</p><h4 id="æœ‹å‹è¯´è°Žé—®é¢˜">3.2.1 æœ‹å‹è¯´è°Žé—®é¢˜</h4><p>å‡è®¾æŸåœ°ä»Šå¤©ä¸‹é›¨çš„æ¦‚çŽ‡æ˜¯<span class="math inline">\(\frac{1}{2}\)</span>ï¼Œä½ åœ¨å‰å¾€æŸåœ°å‰å‘3ä¸ªå½“åœ°çš„æœ‹å‹è¯¢é—®æ˜¯å¦ä¸‹é›¨ï¼Œæ‰€æœ‰äººéƒ½è¯¥è¯‰ä½ ä¸‹é›¨äº†ï¼Œä½†æ˜¯æ¯ä¸ªäººéƒ½æœ‰<span class="math inline">\(\frac{1}{3}\)</span>çš„æ¦‚çŽ‡è¯´è°Žï¼Œ æ±‚æŸåœ°ä»Šå¤©çœŸæ­£ä¸‹é›¨çš„æ¦‚çŽ‡</p><ul><li>Aï¼šæŸåœ°ä¸‹é›¨</li><li>Bï¼šä¸‰ä¸ªæœ‹å‹éƒ½å‘Šè¯‰ä½ ä¸‹é›¨</li></ul><p><span class="math display">\[P(A) = \frac{1}{2}\]</span></p><p><span class="math display">\[P(B|A) = \frac{2}{3}^3\\\]</span></p><p><span class="math display">\[P(B) = \frac{2}{3}^3*\frac{1}{2}+\frac{1}{3}^3*\frac{1}{2}\]</span></p><h3 id="ä¸‰é—¨é—®é¢˜">3.3 ä¸‰é—¨é—®é¢˜</h3><p>æœ‰Aï¼ŒBï¼ŒCä¸‰æ‰‡é—¨ï¼Œå…¶ä¸­ä¸€æ‰‡èƒŒåŽæœ‰å¥–å“ï¼Œå½“çŽ©å®¶é€‰æ‹©ä¸€æ‰‡é—¨ä»¥åŽï¼Œä¸»æŒäººä¼šæ‰“å¼€å¦ä¸€æ‰‡åŽé¢æ˜¯ç©ºçš„é—¨ï¼Œè¯·é—®çŽ©å®¶æ˜¯å¦è¦æ”¹å˜è‡ªå·±çš„é€‰æ‹©ï¼Ÿ</p><p>æ­¤ç±»é—®é¢˜ç‰¹ç‚¹ä¸ºï¼š</p><ul><li>å…±å‡ºçŽ°3ä¸ªéšæœºå˜é‡ï¼Œéƒ½æ˜¯å¤šå€¼åˆ†å¸ƒï¼Œä½†æ˜¯è¿™ä¸‰è€…ä¹‹é—´æ˜¯äº’æ–¥çš„ï¼Œå¦‚æžœAä¸º1ï¼Œåˆ™Bï¼ŒCä¸ä¸º1</li><li>æ­¤æ—¶å…ˆéªŒå˜é‡ä¸ºâ€œæŸä¸€å˜é‡ä¸ºä¸€ç‰¹å®šå€¼â€ï¼Œè¯æ®å˜é‡ä¸ºâ€œå¦ä¸€ä¸ªå˜é‡è¢«æ­æ™“ä¸ä¸ºè¯¥å€¼â€ï¼Œæœ€åŽä¸€ä¸ªå˜é‡ä»…ç”¨äºŽè®¡ç®—å…¨æ¦‚çŽ‡ï¼Œæˆ–è€…ç”¨äºŽæ¯”è¾ƒé€‰æ‹©</li></ul><p>ä»¤ï¼š</p><ul><li>Aäº‹ä»¶ä¸ºé—¨åŽæœ‰å¥–çš„æ˜¯Aé—¨<span class="math inline">\(P(A) = P(H = A)\)</span></li><li>Däº‹ä»¶ä¸ºBé—¨è¢«æ‰“å¼€ä¸”ä¸ºç©º<span class="math inline">\(P(B) = P(H_D= B)\)</span></li></ul><p>åˆ™ï¼š <span class="math display">\[P(A) = \frac{1}{3}\]</span></p><p>$$</p><p><span class="math display">\[å½“Aé—¨åŽæœ‰è½¦ï¼ŒBï¼ŒCé—¨è¢«æ‰“å¼€çš„æ¦‚çŽ‡æ˜¯ä¸€æ ·çš„\]</span> P(D|A) =  $$ å½“Bé—¨åŽæœ‰è½¦ï¼Œä¸»æŒäººä¸ä¼šæ‰“å¼€Bé—¨ï¼Œå› æ­¤<span class="math inline">\(P(D|B) = 0\)</span></p><p>å½“Cé—¨åŽæœ‰è½¦ï¼Œä¸»æŒäººåªèƒ½æ‰“å¼€Bé—¨ï¼Œå› æ­¤<span class="math inline">\(P(D|C) = 1\)</span></p><p>å› æ­¤ï¼Œ<span class="math inline">\(P(D) = P(A)*P(D|A)+P(B)*P(D|B)+P(C)P(D|C) = \frac{1}{3}*\frac{1}{2}+0+\frac{1}{3}*1 = \frac{1}{2}\)</span></p><p>ç”±æ­¤å¯ä»¥è®¡ç®—å¾—åˆ°ï¼š <span class="math display">\[P(A|D) = \frac{1}{3}\\P(C|D) = \frac{2}{3}\]</span> å› æ­¤ï¼Œåº”è¯¥é€‰æ‹©Cé—¨</p><h4 id="èµ¦å…é—®é¢˜">3.3.1 èµ¦å…é—®é¢˜</h4><p>æœ‰Aï¼ŒBï¼ŒCä¸‰ä¸ªå›šçŠ¯ï¼Œå…¶ä¸­ä¸€ä¸ªäººå°†è¢«èµ¦å…ï¼Œå¦å¤–ä¸¤ä¸ªå°†è¢«æ€æ­»ï¼Œå¦‚æžœæœ‰å›šçŠ¯é—®çœ‹å®ˆï¼Œçœ‹å®ˆåªèƒ½å‘Šè¯‰ä»–æŸä¸€ä¸ªäººå°†è¢«å¤„æ­»ï¼Œè€Œä¸”çœ‹å®ˆä¸èƒ½å‘Šè¯‰é—®ä»–çš„äººæ˜¯å¦è¢«å¤„æ­»ã€‚Aé—®çœ‹å®ˆï¼Œçœ‹å®ˆå›žç­”Bè¦è¢«å¤„æ­»ï¼Œæ±‚è¿™ç§æƒ…å†µä¸‹ï¼ŒAå’ŒCè¢«èµ¦å…çš„æ¦‚çŽ‡</p><p>ä»¤ï¼š</p><ul><li>Aäº‹ä»¶ä¸ºè¢«èµ¦å…çš„æ˜¯A</li><li>Däº‹ä»¶ä¸ºçœ‹å®ˆå›žç­”Bè¢«å¤„æ­»</li></ul><p><span class="math display">\[P(A) = \frac{1}{3}\]</span></p><p><span class="math display">\[P(D|A) = \frac{1}{2}\\\]</span></p><p><span class="math display">\[P(D|B) = 0\]</span></p><p><span class="math display">\[P(D|C) = 1\]</span></p><p>åˆ™è®¡ç®—å¯å¾—ï¼š <span class="math display">\[P(A|D) = \frac{1}{3}\]</span></p><p><span class="math display">\[P(C|D) = \frac{2}{3}\]</span></p>]]></content>
    
    
    <categories>
      
      <category>Probability &amp; Statistics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Interview</tag>
      
      <tag>Bayesian Inference</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Evaluation for Regression</title>
    <link href="/2022/09/22/evaluation-for-regression/"/>
    <url>/2022/09/22/evaluation-for-regression/</url>
    
    <content type="html"><![CDATA[<h1 id="evaluation-for-regression-model">Evaluation for Regression Model</h1><h2 id="evalution-for-goodness-of-fitting">1. Evalution for goodness of fitting</h2><p>In most case, we can directly used the loss function's value on testing dataset as a metric to evaluate a regression model's performance</p><p>For common loss function for regression model, refer to <a href="http://zhengyuanyang.com/2022/09/22/loss-function/">here</a></p><p>here supplement several other metrics</p><p><strong>MSLE</strong></p><p>Mean Squared Log Error <span class="math display">\[MSLE = \frac{1}{n}\sum_i^n(log(1+y_i)-log(1+\hat{y)}^2\]</span></p><ul><li>Add one to avoid the appearance of log 0</li><li>MSLE is ideal when we priorly know there's a exponential relationship between Y and some X(e. g. Population). However, in many cases we would transorm data with exponential distribution in data preprocessing so that the exponential relationship would be eliminated. Thus, MSLE is not frequently used</li></ul><p><strong><span class="math inline">\(R^2\)</span></strong></p><p>Coefficient of Determination <span class="math display">\[R^2 = 1-\frac{\sum y-\hat{y}}{y-\bar{y}} = 1-\frac{RSS}{TSS}\]</span></p><ul><li><span class="math inline">\(R^2\)</span> represent how many variance of Y are interpreted by the model</li><li>If <span class="math inline">\(R^2 = 0\)</span>, TSS = RSS, which means the model equals to a model that simply predicted all samples as the average of Y, which indicates the model has a bad performance</li><li><span class="math inline">\(R^2\)</span> is not a true square number, the range of it is <span class="math inline">\((-\infty,1])\)</span></li></ul><h2 id="evaluation-for-linearity">2. Evaluation for Linearity</h2><p>Linear model can hardly capture non-linear mapping between X and Y. Thus, the linearity between X and Y need to be examined.</p><p><strong>Detection of non-Linearity</strong></p><p>For high-dimension data, we can draw a draw a <strong>Residual - Fitted</strong> Plot:</p><p><img src="/2022/09/22/evaluation-for-regression/1.png"></p><p>If the residuals randomly placed along a line, like case 1, than we can believe the data already have strong linearity.</p><p><strong>Solution for non-Linearity</strong></p><p>we should consider non-linear transformation for the features or adding non-linear terms of the features, so that the mapping relationship can be expressed by the hypothesis in a linear form</p><h2 id="evaluation-for-autocorrelation">3. Evaluation for Autocorrelation</h2><p>Autocorrelation refer to that there is a dependent mode between the randomized error of each sample . That is, the <span class="math inline">\(\epsilon\)</span> of different are correlated. This would lead to underestimate the real randomized error <span class="math inline">\(\epsilon\)</span>.</p><p>Usually, the Autocorrelation happen when there exists time-sequence factors.</p><p><strong>Detection of Autocorrelation</strong></p><p><em>1.Time-sequence Plot</em></p><p>A simple and direct way to recognized the time-sequence of <span class="math inline">\(\epsilon\)</span>. Draw a plot of <span class="math inline">\(\epsilon\)</span> sorted by time:</p><p><img src="/2022/09/22/evaluation-for-regression/2.png"></p><p>If the previous error <span class="math inline">\(e_{t-1}\)</span> would make the next error <span class="math inline">\(e_t\)</span> tend to be with opppsite sign, we call this a negative autocorrelation. Otherwise, we call it a positive autocorrelation.</p><p><em>2.DW Test</em></p><p>The DW test construct test statistics using the correction between <span class="math inline">\(e^{t-1}\)</span> and <span class="math inline">\(e^t\)</span>. Gather errors of all sample and calculate <span class="math display">\[\rho = corr(e^t,e^{t-1})\]</span> Construct <span class="math display">\[DW \approx 2(1-\rho)\]</span> according the Degree of Freedom n, we can look up in the table and find the upper bound and lower bound of the DW: <span class="math inline">\(d_U,d_L\)</span>, then we can examine which section the DW falls in to and make judgement on autocorrealtion:</p><p><img src="/2022/09/22/evaluation-for-regression/3.png"></p><p>The drawbacks of DW test is that it has two uncertain sections. Besides, it cannot detect higher derivative autocorrelation than 1.</p><p><em>3.LM Test</em></p><p>It regress on $e^t $ with all feature X and lagged error <span class="math inline">\(e = e_{t-1},e_{t-2},..e_{t-p}\)</span> with: <span class="math display">\[e_t = \alpha X + \rho e + \epsilon\]</span> Where <span class="math inline">\(\rho\)</span> is a vector, <span class="math inline">\(\rho_i\)</span> is the correlation between <span class="math inline">\(e_t\)</span> and <span class="math inline">\(e_{t-i}\)</span>. p is a hyperparameter for adjustment.</p><p>Obained the Judge coefficient <span class="math inline">\(R^2\)</span> of the model, when sample size n is big, <span class="math inline">\((n-p)R^2 \sim \chi^2(p)\)</span>, we can than to a <span class="math inline">\(\chi^2\)</span> test to examine whether there exist autocorrelation</p><p><strong>Solution for Autocorrelation</strong></p><p>The solution for autocorrelation:</p><ul><li>Consider time-sequence model</li><li>If there exists positive autocorrelation, consider addling lagged feature <span class="math inline">\(X_{t-1},X_{t-2},...\)</span> into the model</li><li>If there exist seasonal factor, adding that factor into the model as dummies variable</li><li>Generalized Difference Method: construct the model as:</li></ul><p><span class="math display">\[Y_t  = \beta_0 + \beta_1X_t + \rho_1u_1+\rho_2u_2+...\rho_pu_p+\epsilon\]</span></p><p>Where <span class="math inline">\(u_i\)</span> is the residual of the <span class="math inline">\(i^{th}\)</span> model. This method has similar ideal like boosting. In machine learning, we can split the sample set into different moments according to timestamp like hour or date and construct serial models.</p><h2 id="evaluation-of-multicollinearity">4. Evaluation of Multicollinearity</h2><p>Multicollinearity refer to the relationship that a variable's change would cause another variable's change</p><p>In regression, we do not want there to be multicollinearity among input variables.</p><p>For example suppose we have a ideal regression model that <span class="math display">\[y = 10x_1+b\]</span> Then we introduce a highly correlated variable <span class="math inline">\(x_2 = 2x_1\)</span>, in this case the modle can fit infinite possible combination of these two variables, for example, the model might end up with: <span class="math display">\[Y = -100x_1 +55x_2 +b = 10x_1+b\]</span> These will cause:</p><ul><li>coefficient might lose its interpretability. Positive coefficient might turn negative, insignificant variable might turn significant</li><li>The model might lose stability since the coefficients are enlarged. Small noises could cause big variance</li></ul><p><strong>Detection of Multicollinearity</strong></p><p>1.Variance Inflation Factor <span class="math display">\[VIF = \frac{1}{1-R^ 2}\]</span> As discussed above, <span class="math inline">\(R^2\)</span> represent the goodness of fitting. Thus we can use an input variable <span class="math inline">\(x_i\)</span> as the output variable, and fit a model with other input variable <span class="math inline">\(x_1,...x_{i-1},x_{i+ 1}...x_m\)</span> being inputs. If the <span class="math inline">\(R^2\)</span> turn out to be high, then it is possible that <span class="math inline">\(x_1\)</span> are highly correlated with other variables. In such case, the VIF would be high</p><p>In practice, if VIF &gt; 10, we can consider as there's a Multicollinearity problem. If VIF &gt; 100, we can consider as there's a serious Multicollinearity problem</p><p>2.Correlation Matrix</p><p>VIF demands large scale of calculation when the dimension of feature is high. A simpler way is to calculate the corrections matrixs using parameters like Pearson'r, Spearman'<span class="math inline">\(\rho\)</span> or Kendall's <span class="math inline">\(\tau\)</span></p><p><strong>Solution for Multicollinearity</strong></p><p>The solution for Multicollinearity includes:</p><ul><li><p>Filtering feature selection methods based on correlation</p></li><li><p>Wrapper feature engineering methods like stepwise regression</p></li><li><p>Embedded Feature Engineering methods like Lasso &amp; Ridge Regression</p></li></ul><h2 id="evaluation-for-homoskedasticity">5. Evaluation for Homoskedasticity</h2><p>Linear Regression Models require the variances of randomized to have same variance on different scale. That is, with the linearity assumption fulfilled, the variance of the model should be similar no matter how big the output variable is.</p><p><strong>Detection of Heteroskedasticity</strong></p><p>To detect heteroskedasticity, we can use <strong>Residual - Fitted</strong> Plot as well</p><p><img src="/2022/09/22/evaluation-for-regression/4.png"></p><p>In a RF plot, if the linearity assumption is satisfied, the point will place aside a horizontal line. If the model us biased, they would place around a leaned line or a curve. We call this line or curve the central line.</p><p>If the homoskedasticity is fulfilled, then the average distance from the point to the central line should be same across the axis of fitted values. If the errors has heteroskedasticity, then the points would be a shape like a spraying.</p><p><strong>Solution for Heteroskedasticity</strong></p><p>The solution for heteroskedasticity includes:</p><ul><li><a href="http://zhengyuanyang.com/2022/10/07/outlier/">Outlier detection</a>: heteroskedasticity is usually caused by outliers.</li><li>Distribution transformation on Y: heteroskedasticity can also be caused by the distribution of Y. Linear models require Y to be normally distributed. We can conduct distribution type transformation</li></ul><h2 id="evaluation-on-normality-of-epsilon">6. Evaluation on Normality of <span class="math inline">\(\epsilon\)</span></h2><p>The linear regression model requires the randomized error to be normally distributed. For normality test and normal transformation techniques, refer to <a href="http://zhengyuanyang.com/2022/10/22/distribution-type/">this article</a></p>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Model Evaluation</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Information Theory in ML</title>
    <link href="/2022/09/22/information-theory-in-ML/"/>
    <url>/2022/09/22/information-theory-in-ML/</url>
    
    <content type="html"><![CDATA[<h1 id="information-theory-basis">Information Theory Basis</h1><h2 id="information-and-entrophy">1. Information and Entrophy</h2><p><strong>self-info</strong></p><p>self-information is a measure related to the outcome of a probabilistic event. To quantify the information, we hope the measure would have following properties:</p><ul><li>A low-probability outcome contains more infomation than a high-probability event. For example, "I won't die" contains more information than "I will die". To some extent, we can regard self-info as the degree we would feel surprise about an certain outcome of an event</li><li>Information quantity must not be negative</li><li>The total imformation of several outcome should be the sum of ther individual information</li><li><span class="math inline">\(I(y=m_1,y=m_2) = I(y=m_1)+I(y=m_2)\)</span></li><li>I(y) must be continuous if P(y) is continuous</li></ul><p>It can be proved that the only expression that satisfies these properties is <span class="math inline">\(Klog(P(y))\)</span> where K is negative. Set K= 1, we define the self-information of an outcome of an event as: <span class="math display">\[I  = log(\frac{1}{P(y=c_m)}) = -log(P(y=c_m))\]</span></p><p><strong>Entrophy</strong></p><p>Entrophy is the expectation of self-info. It represent the mean information of an event related to an random variable y, the greater H is, the more uncertain event y is <span class="math display">\[H(Y) = E[I(y)] = -\sum_m^k p(y=c_m)log(p(y=c_m))\]</span></p><h2 id="entrophy-measure-for-two-variables">2. Entrophy measure for two variables</h2><h3 id="joint-entrophy">2.1 Joint Entrophy</h3><p>Joint entropy measure the uncertainty of a joint event (X, Y) <span class="math display">\[H(T,Y) =-\sum_t\sum_y p(t,y)log(p(t,y))\]</span></p><h3 id="conditional-entrophy">2.2 Conditional Entrophy</h3><p>Conditional Entrophy represent the Information recieved of one event when another event is for certain <span class="math display">\[H(Y|T) =-\sum_t\sum_y p(t,y)log(p(y|t)) = -\sum_t\sum_y p(y|t)p(t)log(p(y|t))\]</span> The higher H(Y|T) is, the less "extra information" about Y is needed when T is certain, which means the corralation between Y and T l is higher</p><p>The relationship between conditional entropy and joint entropy: <span class="math display">\[H(Yï½œT) = H(Y, T) - H(T)\]</span></p><h3 id="inofrmation-gain">2.3 Inofrmation Gain</h3><p>Information gain represent the amount of uncertainty reduction of a variable when another variable is certain <span class="math display">\[IG(Y|T) = H(Y) - H(Y| T)\]</span> It is usually applied as an impurity metrics in splitting algorithm like Decision Tree</p><h3 id="mutual-information">2.4 Mutual Information</h3><p>The nature of Mutual Information and Information Gain is the same, mutual information is the shared entropy of two variable</p><p><img src="/2022/09/22/information-theory-in-ML/1.png"></p><p>First, when we consider two event together, we can rewrite H(Y) as: <span class="math display">\[H(Y) = -\sum_i^m p(y=c_i)log(p(y=c_i) \\= -\sum_j^n p(x = c_j)\sum_i^mp(y=c_i|x_=c_j)log(p(y=c_i)) \\= \sum_x\sum_yp(x,y)log(p(y))\]</span></p><p><span class="math display">\[MI = H(x,y) - H(x|y) - H(y|x) = \sum_x\sum_yp(x,y)log\frac{p(x,y)}{p(x)p(y)}\]</span></p><p><span class="math display">\[IG = H(y)-H(y|x) = \sum_x\sum_yp(x,y)log(p(y)) - \sum_x\sum_yp(x,y)log(p(y|x)) = MI\]</span></p><p>MI is usually mentioned when calculating the correlation of two variable, IG is mentioned when calculating the impurity reduction of one variable when splitting another variable</p><h2 id="entrophy-measure-for-two-distribution">3. Entrophy measure for two distribution</h2><h3 id="kl-divergencerelative-entrophy">3.1 KL Divergence(Relative Entrophy)</h3><p>The KL divergence is the expectation(under true distribution) of the difference between information amount under predicted and true distribution <span class="math display">\[D_{KL}(p||q) = \sum_{i=1}^mp(y_i)\log(\frac{p(y_i)}{q(y_i)})\]</span> Where:</p><ul><li>q is the estimated distribution of y</li><li>p is the real distribution of y</li></ul><p>it can be used to evaluate an estimation of a distribution with the real distribution given</p><h3 id="cross-entrophy">3.2 Cross Entrophy</h3><p>The equation KL divergence can be written as: <span class="math display">\[D_{KL}(p||q) = \sum_{i=1}^mp(y_i)\log(\frac{p(y_i)}{q(y_i)}) = -\sum_i^mp(y_i)log(q(y_i)) - (-\sum_i^mp(y_i)log(p(y_i)))\]</span> Obviously, the second term of this equation is <span class="math inline">\(H_p(x)\)</span>, which is the entrophy of the real data. In a machine learning problem, since real entrophy is fixed for a dataset, we can only minimize the first term. we call this term Cross entropy: <span class="math display">\[CH(p,q) = D_ {KL}(p||q) + H_p(X) = -\sum_i^mp(y_i)log(q(y_i))\]</span></p>]]></content>
    
    
    <categories>
      
      <category>Probability &amp; Statistics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Information Theory</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Common Loss Function in Machine Learning</title>
    <link href="/2022/09/22/loss-function/"/>
    <url>/2022/09/22/loss-function/</url>
    
    <content type="html"><![CDATA[<h1 id="common-loss-function-in-machine-learning">Common Loss Function in Machine Learning</h1><h2 id="numerical-output">Numerical Output</h2><h3 id="msel2-lossrmse">1. MSE(L2 Loss)/RMSE</h3><p>Mean Squared Error <span class="math display">\[MSE = \frac{1}{n}\sum_i^n(y_i-\hat{y})^2\]</span></p><ul><li>MSE is differentiable any where, which makes it suitable for gradient descent optimizer</li><li>With gradient decrease, the MSE will decrease, which means MSE is effective with fixed learning rate</li><li>The squared operator gives enlarge the loss, thus MSE is sensitive ti outlier, if outlier is meant to be detected, suing MSE is fine. If the outlier is treat as part of the training data, MSE is not an ideal loss function (e. g. prediction model for sales promotion day)</li></ul><p><img src="/2022/09/22/loss-function/1.png"></p><p>RMSE is the square root of MSE <span class="math display">\[RMSE = \sqrt{MSE}\]</span></p><ul><li>RMSE is on the same scale with MSE, but it make the loss more interpretable in some case(e.g prediction on product price)</li></ul><h3 id="mae-l1-lossmape">2. MAE (L1 Loss)/MAPE</h3><p>Mean Absolute Error <span class="math display">\[MAE = \frac{1}{n}\sum_i^n|y_i-\hat{y}|\]</span></p><ul><li>MAE is not sensitive to outlier, it is less likely to cause gradient explosion</li><li>The gradient for any loss is the same, which means MAE does not converge well with fix learning rate</li><li>MAE is not differentiable at 0</li></ul><p><img src="/2022/09/22/loss-function/2.png"></p><p>MAPE is the mean percentage absolute error <span class="math display">\[MAPE = \frac{1}{n}\sum_i^n\frac{|y_i-\hat{y}|}{y_ i}\]</span></p><ul><li>It can more clearly deliver the degree of deviation rather than the scale of the error</li></ul><h3 id="smooth-l1huber-loss">3. Smooth L1(Huber Loss)</h3><p><span class="math display">\[L = \frac{1}{n}\sum_i^nz_ i\]</span></p><p><span class="math display">\[z_i = \left\{\begin{aligned}MSE \qquad&amp; |y -\hat{y}| &lt; \beta \\MAE \qquad &amp; elsewhere \\\end{aligned}\right.\]</span></p><ul><li><span class="math inline">\(\beta\)</span> is a defined threshold for error of outlier. If the error is within <span class="math inline">\(\beta\)</span>, apply MSE, otherwise, apply MAE. Huber Loss combines the advantages of L1 and L2 Loss</li><li>Huber loss is ideal for NN</li></ul><p><img src="/2022/09/22/loss-function/3.png"></p><h3 id="log-cosh-loss">4. Log-cosh Loss</h3><p><span class="math display">\[L = \sum_ i^ nlog(cosh(y_i-\hat{y_i}))\]</span></p><ul><li>Log-cosh has almost every virtue of Huber loss, the difference is, it is second-differentiable anywhere, such method is very useful when applying newton-method optimzer</li><li>However, when erro is very big, Log-cosh loss still would have gradient or hessian problem(gradient remains same when loss decrease). Just like MAE</li></ul><h2 id="categoricalprobability-output">Categorical/Probability Output</h2><h3 id="log-losscross-entropy-loss">1. Log Loss/Cross Entropy Loss</h3><p>Log Loss is basically the same concept as the cross entropy, the only difference is that it can be applied at a single sample by replaceing true probability p(x) with 1 if <span class="math inline">\(y_ {true} = m\)</span>. The average loss of all sample is the Log Loss or Cross Entropy Loss.</p><p>For Cross Entropy, refer to <a href="http://zhengyuanyang.com/2022/09/22/information-theory-in-ML/">here</a></p><p>When it come to a binary classification scenario, the Log Loss can be written as: <span class="math display">\[LogLoss = -\frac{1}{n}\sum_i^n [y_ilog(p(y_i))+(1-y_i)log(1-p(y_i))]\]</span></p><p>where <span class="math inline">\(y_i\)</span> is the true value of output and <span class="math inline">\(p(y_i)\)</span> is the probability predicted by the model.</p><ul><li>The gradient would decrease as Log Loss decrease, thus Log Loss can work with fixed learning rate</li><li>Sentive to outlier</li><li>GDBT usually apply Log Loss as loss function(classification)</li></ul><p>The following picture is the log loss of the prediction on a positive sample:</p><p><img src="/2022/09/22/loss-function/4.png"></p><h3 id="exponential-loss">2. Exponential Loss</h3><p><span class="math display">\[L = \frac{1}{n}\sum_i^ne^{-yf(x)}\]</span></p><ul><li>Theoretically, the optimal of Exponential Loss and Log Loss is the same(<span class="math inline">\(\frac{1}{2}log\ odds\)</span>), the advantage of exponential loss is that is is easier to calculate, thus can make optimzer update the weight with less cost</li><li>Sentive to outlier</li><li>AdaBoosting usually apply Exponential Loss as loss function(classification)</li></ul><h3 id="hinge-loss">3. Hinge Loss</h3><p><span class="math display">\[L = \frac{1}{n}\sum_i^n max(0,1-yf(x))\]</span></p><ul><li>If the model label the sample correct, the loss is 0</li><li>Less sensitive to outlier</li><li>SVM usually adopt Hinge Loss as loss function</li></ul><p><img src="/2022/09/22/loss-function/5.png"></p><h3 id="focal-loss">4. Focal Loss</h3><p>Focal Loss is a improved version of Cross Entrophy Loss <span class="math display">\[L_ f = -\frac{1}{n}\sum_i^n\sum_ j^m\alpha_ j(1-p(y ))^\gamma y log(p(y))\]</span></p><ul><li>Focal Loss add a focus factor <span class="math inline">\((1-p(y))\)</span>, so that those sample with high predicted probability, which are the ""easy samples", donate less loss. Compare to CE Loss, Focal Loss focus on those "hard samples"</li><li>Focal Loss also add a balance factor(optional), which is the percentage of a certain category of y among all samples. This make focal loss can deal with imbalanced data</li><li><span class="math inline">\(\gamma\)</span> is a influence parameter. When <span class="math inline">\(\gamma = 0\)</span>, the Focal Loss become CE Loss. In preactice, we usually set <span class="math inline">\(\gamma = 2\)</span></li></ul><h3 id="impurity">5.Impurity</h3><p>Impurity is a kind of loss functions usually applied in splitting in decision tree</p><h4 id="gini-impurity">5.1 Gini Impurity</h4><p><span class="math display">\[I_G = 1- \sum_{i}^m P(Y=C_i)^2\]</span></p><ul><li>Lower <span class="math inline">\(I_G\)</span> , better classification performance</li><li>For decision tree model, calculate <span class="math inline">\(I_G\)</span> for each split and use combined Gini Impurity(<span class="math inline">\(\sum I_G\)</span>) as loss of the spiltting</li></ul><h4 id="information-gain">5.2 Information Gain</h4><p>For details of Information Gain, refer to <a href="http://zhengyuanyang.com/2022/09/22/information-theory-in-ML/">here</a> <span class="math display">\[IG = H(Y) - H(Y|X)\]</span> where X is the feature the spliting based on (X&gt;c,X=1)</p><ul><li>IG is the degree that uncertainty reduce after the spilting, the greater IG is, the better a split is</li><li>We can calculate the Information Gain Rate <span class="math inline">\(IGR = \frac{IG}{H(Y)}\)</span> to present the degress of uncertainty reduction more directly</li></ul>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Loss Function</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Evaluation Method for Classification</title>
    <link href="/2022/09/21/Evaluation_Classification/"/>
    <url>/2022/09/21/Evaluation_Classification/</url>
    
    <content type="html"><![CDATA[<h1 id="evaluation-method-for-classification">Evaluation Method for Classification</h1><h2 id="confusion-matrix">1. Confusion Matrix</h2><p>The confusion matrix is a table that count different cases of the predicted outcome given by a classification model. For a binary classification model, it can be given as:</p><p><img src="/2022/09/21/Evaluation_Classification/confusion-matrix.png"></p><p>For a multiple classification case, the confusion matrix can be given as:</p><p><img src="/2022/09/21/Evaluation_Classification/2.png"></p><p>For such case, we can define TP, TN, FP, FN for each category by deeming all true â€œnot-birdâ€ samples predicted â€œnot-birdâ€ as TN, etc.</p><h2 id="accuracy-precision-recall-and-f1-score">2. Accuracy, Precision, Recall and F1 score</h2><p>With confusion matrix given, we can now define the following matrix:</p><p><strong>Accuracy</strong></p><p>Accuracy = samples predicted correctly / all predicted samples <span class="math display">\[accuracy = \frac{TP+TN}{TP+FP+FN+FP} \]</span> Accuracy is a very intuitive metrics. However, it sometimes cannot directly reflect the predicting performance of the model as it cannot deal with imbalanced data. For example, suppose we have a sample set of 100 sample with 99 positive and 1 negative, even if the model simply predicted all samples as positive without any training, it would still receive an accuracy of 99%.</p><p><strong>Recall and Precision</strong></p><p>Recall = correctly predicted positive samples / all actual positive samples <span class="math display">\[racall = \frac{TP}{TP + FN}\]</span> Recall represent the ability to find positive samples among all actual postive samples. It can deal with imbalanced data. It is sensitive to FN case, thus is suitable for the business case where FN would bring significant cause(e. g Explosion recognition, vehicle safety judgement). On the other side, recall does not consider FN, a model can simply improved recall by judging all samples as positive, which is not good in some cases.</p><p>Precision = correctly predicted positive samples / all predicted positive samples <span class="math display">\[precision = \frac{TP}{TP + FP}\]</span> Precision represent the probability that a model's judgment on positive case is correct. It can partly deal with imbalanced data. It is sensitive to FP case, thus is suitable for the business case where FP would bring significant cause(e. g Crime judgment, disease diagnosis).</p><p>Recall and Precision can both deal with imbalanced data. However, there's a trade-off between these two metrics. Thus, which metric to put emphasis on idepends on specific business application. Nevertheless, in most cases, since we can just flip P/N, or 1/0, precision is more like an accompanied constraint of recall to prevent model from foucsing too much on capture the minor category samples, as FN and FP are both bad in most business application.</p><p><strong>F1 Score</strong></p><p>The F-measure is a function that balance Precision and recall <span class="math display">\[F_\alpha = \frac{(1+\alpha^2)*P*R}{(\alpha^2*P)+R}\]</span> when <span class="math inline">\(\alpha\)</span> = 1, we call this metric F1 score: <span class="math display">\[F1 = \frac{2PR}{P+R}\]</span> F1 socre combine Recall and Precision to find a balance. It is suitable for many business case where we cannot decide a clear preference.</p><h2 id="p--r-curve-roc-curve-and-auc">3. P- R Curve, ROC Curve and AUC</h2><p><strong>P- R Curve</strong></p><p>P-R Curve is a curve to depict the relationship between Precision and Recall. It's application is similar to F1 score, but lessly used as F1 score is more concise to read( The higher the better)</p><p><img src="/2022/09/21/Evaluation_Classification/3.PNG"></p><p>Usually, we can regard model B as a better model if it can completely wrap the curve of A. If that; s not the case, we can mark the point on the curve where precision equals recall(Break Event Point, or BEP). The curve with a BEP closer towards up- right direction is better.</p><p><strong>ROC Curve</strong></p><p>We define:</p><ul><li>True positive rate (sensitivity): the ratio that actual positive samples predicted correctly</li><li>True negative rate (specificity): the ratio that actual negative samples predicted correctly</li><li>False positive rate (1-specificity): the ratio that actual negative samples predicted wrongly</li></ul><p><span class="math display">\[TPR = \frac{TP}{TP+FN} = Recall\\TNR = \frac{TN}{FP+TN} = 1-TNP\\FPR = \frac{FP}{FP+TN}\]</span></p><p>From a probabilistic aspect:</p><table><tbody><tr class="odd"><td>Precision</td><td style="text-align: center;"><span class="math inline">\(P(Y=1|\hat{Y}=1)\)</span></td></tr><tr class="even"><td>Recall (sensitivity)</td><td style="text-align: center;"><span class="math inline">\(P(\hat{Y}=1|Y=1)\)</span></td></tr><tr class="odd"><td>Specificity</td><td style="text-align: center;"><span class="math inline">\(P(\hat{Y}=0|Y=0)\)</span></td></tr></tbody></table><p>From this interpreation, we found that sensitivity and specificity are condition on Y, which means The influence of P(Y) are blocked whe calculating these two metrics. Therefore, these two metrics are not influenced by the imbalance of data.</p><p>The Reciever Operating Characteristics cureve(ROC curve) take both metrics into consideration by depict the relationship between sensitivity and 1-specificity:</p><p><img src="/2022/09/21/Evaluation_Classification/4.PNG"></p><p><strong>AUC</strong></p><p>Area Under Curve(AUC) is the area beneath the ROC curve.</p><p>Suppose our model completely randomly classifies the samples, the the probability it regard an actual postive sample or an actual negative sample as a positive sample is equal, in this case, AUC would be 0.5. If AUC &gt; 0.5, it means when the model predicts a sample, <span class="math inline">\(P(\hat{Y}=1|Y=1) &gt; P(\hat{Y}=1|Y=0)\)</span> , which means the prediction is effective. Thus, the higher the AUC is, the better the model performs.</p><p>Obviously, AUC is not influenced by imbalanced data, and it's delivery information concisely. Thus, it is one of the most frequently used metrics in classification.</p>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Model Evaluation</tag>
      
      <tag>Classification</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Causes and Solutions of Overfitting</title>
    <link href="/2022/09/19/overfitting/"/>
    <url>/2022/09/19/overfitting/</url>
    
    <content type="html"><![CDATA[<h1 id="overfitting-cause-and-solution">Overfitting: Cause and Solution</h1><h2 id="biasvariance-and-overfitting">1. Biasï¼ŒVariance and Overfitting</h2><p>Theoretically, we consider the expected risk of the model on real data consists of two parts:</p><p><strong>Bias</strong></p><p>The model's failure to imitate the real mapping, probability distribution or other relationship of the data. For example, if we try to fit a non-linear relationship with a linear model, there would be inevitable bias. Another example is that we leave some important factors omitted</p><p><strong>Variance</strong></p><p>The model's sensitivity to changes in data. High variance occurs when the model try to seize any details. It put too many weights on unimportant feature or noise in order to reduce error in training process.</p><p>Neither high bias nor high variance is good. However, when we take measure to solve bias, like applying complex model or increase feature, the variance of the model increase accordingly. In other worlds, there is a trade-off between bias and variance. In training process, our aim would be finding a model with bias and variance acceptable.</p><p><strong>Underfitting and Overfitting</strong></p><p>When the bias is high, we cannot describe the pattern of the data correctly, we call such a scene Underfitting</p><p>When the bias is low, but the variance is high, the model is trapped in the details or noises of the data, ot fit well on the given data but it has poor generality so that it would fail on other data</p><p><img src="/2022/09/19/overfitting/1.PNG"></p><p>The performance on training and testing dataset under these scenes</p><table><thead><tr class="header"><th></th><th>training SET Erro</th><th>Testing Set ERROR</th></tr></thead><tbody><tr class="odd"><td>Underfit</td><td>high</td><td>high</td></tr><tr class="even"><td>Overfit</td><td>low</td><td>high</td></tr><tr class="odd"><td>Optimum</td><td>low</td><td>low</td></tr></tbody></table><h2 id="causes-of-overfitting">2. Causes of Overfitting</h2><p>As specified above, the core reason that cause of overfitting is the imbalanced trade-off(High variance, low bias). Specifically, we induct the reasons into:</p><ul><li>Complexity of the model: The model is too complex for the pattern we want to discover in the data</li><li>Defects of data: the samples contains so much noises that the model cannot ignore them</li><li>Overtraining: the model is trained with too much epochs that force the model to learn noises in order to converge</li><li>Improper sampling/splitting: the training set fails to represent the distribution of the real data. Or, in some other case, the real distribution itself decides that the model is hard to imitate it.</li></ul><h2 id="solutions-for-overfitting">3. Solutions for Overfitting</h2><p>According to four reasons, we can also induct the solutions into:</p><h3 id="control-complexity">3.1 <strong>Control complexity</strong></h3><p><strong>Regularization</strong></p><p>In machine learning, regularization refer to constraints on the number of feature dimensions. Usually, it is realized through adding an regular term to the loss function to penalize putting weight on too many features. This includes:</p><ul><li>Lasso regression and Ridge regression</li><li>Soft margin for SVM</li><li>Regular term in XGBoost</li><li>...</li></ul><p><strong>Feature Engineering</strong></p><p>Reduce the number of features. FIlter those redundant feature through feature engineering methods like correlation analysis and dimensionality reduction. For details, please refer to <a href>ongoing</a></p><p><strong>Simplify Structure</strong></p><p>An important rule for machine learning is to solve the task with possible simplest model. A model with simpler structure can usually solve overfitting. Specific action includes:</p><ul><li>Dropout in NN</li><li>pruning in tree-based model</li><li>Hyperparameter like hidden size, max-leaf-node</li></ul><h3 id="data-augmentation"><strong>3.2 Data augmentation </strong></h3><p>The best way to eliminate the variance caused by data defects is simply increasing more data to the training set. Since sufficient data are sometimes unavailable in real project. We can apply data augmentation to generate more training data. Data augmentation is more common in deep learning feild.</p><h3 id="early-stopping"><strong>3.3 Early stopping</strong></h3><p>Stop the optimizer earlier to prevent overtraining. For example:</p><ul><li>raise error threshold for an optimzer</li><li>set max depth for an decision tree</li><li>set max iterations for an neural network</li></ul><h3 id="sampling-and-spliting"><strong>3.4 Sampling and spliting</strong></h3><p><strong>Cross Validation</strong></p><p>Cross validation means spliting the dataset into subsets. Use some of them to estimate the distribution and other of them to evaluate the estimation. Such procedure can effectively control the varaince caused by sample selection bias. For the details of cross validation, refer to<a href>ongoing</a></p><p><strong>Sampling </strong></p><p>From an theoretical perspective, sampling itself is actually a kind of non-parameter ML model. When you do sampling, yur actual target is to imitate the distribution of the real population through getting a sample. Thus, the sample itself would have bias if it cannot represent the true distribution of the population. Training a mode using these samples would obviously cause variance.</p><p>Thus, a way might help solving overfitting is improving your sampling method. For details of sampling methods in ML, refer to <a href>ongoing</a></p>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Model Evaluation</tag>
      
      <tag>Overfitting</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Learning Principle</title>
    <link href="/2022/09/12/Principle/"/>
    <url>/2022/09/12/Principle/</url>
    
    <content type="html"><![CDATA[<h1 id="learning-principle">Learning Principle</h1><p>In machine learning, learning principle refer to the standard for judging whether a model is good or not</p><h2 id="loss-function-risk-function-and-objective-function">1. Loss function, Risk function and Objective function</h2><p>Loss function is a function used to evaluate the fitness of a model</p><p>For supervised learning, loss function evaluate the difference between the predicted output and true output, noted as <span class="math inline">\(L(Y,f(x, \theta))\)</span>. Ususally, loss function is applied to a single sample or a part of the samples, it cannot evaluate the overall performance of the model. To obtain that, we define: <span class="math display">\[R_{exp}(\theta) = E_P[L(Y,f(x, \theta))] = \int_{X*Y}L(Y,f(x, \theta)P(X,Y)dxdy\]</span> Where <span class="math inline">\(R_{exp}\)</span> is called <strong>risk function</strong> or **expected loss*</p><p>To convert a ML problem into an optimization problem, a ideal practice is to adopt risk function as the objective function for the optimization program. However, this require us to know the true JPD P(X, Y), which is usually unknown in real problem(we can only know the estimated JPD through observational dataset), this is called an ill-formed problem</p><p><em>Note: sometimes, instead of directly use loss function, we would use a function of the loss function to construct objective function, for example, the boosting algorithm</em></p><p>For unsupervised learning, the loss function is a totally different thing, we usually directly talked about the objective function since we do not have a <span class="math inline">\(Y_{true}\)</span> to compare with. The specific form of the objective function varies from specific type of unsupervised learning</p><h2 id="empirical-risk-minimization">2. <strong>Empirical Risk Minimization</strong></h2><p>An obvious solution for ill-formed problem is to replace ture P(X,Y) with the observed <span class="math inline">\(\hat{P(X,Y)}\)</span> on training dataset.</p><p>Suppose the weight of all sample are equivalent, we define <span class="math display">\[R_{emp}(\theta) = \frac{1}{N}\sum_{n=1}^N L(y, f(x,\theta)\]</span> Where <span class="math inline">\(R_{emp}\)</span> is called empirical risk.</p><p>When we use empirical risk as our objective function, we call the learning principle of the machine learning "ERM"</p><p>For a probability model, under some condition, we can consider ERM as equivalent to a <strong>Maximum Likehood Estimation</strong>(MLE). Refer to another article about parameter estimation</p><h2 id="structural-risk-minimization">3. Structural Risk Minimization</h2><p>When sample size is big enough, empirical risk would be close enough to the real expected risk. However, in real problem we will not have infinite samples. We would probably obtain a subset of the sample with unmeasured varaible and noise. Such situation would often lead to overfitting. In such case, we need introduce regularization: <span class="math display">\[R_{srm}(\theta) = R_{emp} + \lambda J(\theta)\]</span> where <span class="math inline">\(J(\theta)\)</span> is a function represent the complexity of the model, and <span class="math inline">\(\lambda\)</span> is a penalized parameter used the control the degree of regularization</p><p>When we use structural risk as our objective function, we call the learning principle of the machine learning "SRM"</p><p>For a probability model, under some condition, we can consider SRM as equivalent to a <strong>Maximum-A-Posterior</strong>(MAP). Refer to another article about parameter estimation</p><h2 id="objective-function-for-unsupervised-learning">4. Objective function for Unsupervised Learning</h2><p>[ongoing]</p>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Learning Principle</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Basic knowledge about Machine Learning(Supervised Learning)</title>
    <link href="/2022/09/11/basic_knowledgefor_ML/"/>
    <url>/2022/09/11/basic_knowledgefor_ML/</url>
    
    <content type="html"><![CDATA[<h1 id="machine-learning">Machine Learning</h1><h2 id="about-machine-learning">1.About Machine Learning</h2><h3 id="what-is-machine-learning">1.1 What is Machine Learning</h3><p>The definition about machine learning can be expressed as:</p><p>Suppose we want a model to perform a task T, and we have a approach E to evaluate the goodness the model complete this task. If we improve E through updating an optimization algorithm O using an observational dataset D, we can call such process a machine learning process</p><h3 id="three-components-of-machine-learning">1.2 Three components of Machine Learning</h3><p><strong>Model</strong></p><p>A model is a learnner trying to solve the task we want to perform. In most cases, that task would fitting a real mapping between variables. Thus, a model can usually be noted as <span class="math inline">\(f(x,\theta)\)</span>, where <span class="math inline">\(\theta\)</span> is the parameter of the model, and the fitting task is to find the best <span class="math inline">\(\theta\)</span> according to the training dataset.</p><p>As me may not know the sepcific form of the real mapping, we need to give the algorithm a scope for leaning, we call such scope the Hypothesis Space, noted as F. For all potential fitted mapping f , <span class="math inline">\(f\in F\)</span></p><p><strong>Learning Principle</strong></p><p>To find the best <span class="math inline">\(\theta\)</span>, we need a principle to judge how good a <span class="math inline">\(\theta\)</span> is. This principle usually involve the definition and calculation of a Loss function</p><p><strong>Optimization Algorithm</strong></p><p>After confirming the training dataset, hypothesis space and learning principle, the task of finding the best parameters become a optimization problem. An optimization algorithm is a solver to solve such problem</p><h3 id="proprocess-of-the-data">1.3 Proprocess of the data</h3><h3 id="evaluation-of-the-model">1.4 Evaluation of the model</h3><h2 id="supervised-machine-learning">2. Supervised Machine Learning</h2><p>Supervised learning is a kind of machine learning where the output variable of the model is clearly labeled in the dataset. That is to say, we would have a real outcome <span class="math inline">\(Y_{true}\)</span> and a predicted outcome <span class="math inline">\(Y_{pred}\)</span></p><h3 id="joint-probability-distribution"><strong>2.1 Joint Probability Distribution</strong></h3><p>Joint probability is the probability that multiple conditions are satisfied same time, noted as <span class="math inline">\(P(X,Y)\)</span></p><p>the relationship among joint probability, conditional probability and edge probability are: <span class="math display">\[P(Y|X) = \frac{P(X,Y)}{P(X)}\\P(Y) = \sum_{i=1}^N P(X,Y)P(X)\]</span> For two independent variable: <span class="math display">\[P(X, Y) = P(X)P(Y)\\P(Y|X) = P(Y)\]</span></p><p>The fundamental hypothesis of supervised machine learning is the existence of the Joint Probability Distribution of input variable X and output variable Y</p><p>The task we want a supervised machine learning algorithm to perform is to imitate the real JPD <span class="math inline">\(P(X,Y)\)</span>, so that we can calculate <span class="math inline">\(P(Y| X)\)</span> when input X is given</p><h3 id="category-of-supervised-machine-learning">2.2 Category of Supervised Machine Learning</h3><p><strong>Probability model v.s. Non-probability model</strong></p><p>The Non-Probability model try to learn the mapping relationship f directly. Usually it confirm a hypothesis space according to prior knowledge(e.g a linear space ). For example, KNN, SVM, NN are all non-probability model</p><p>The probability model try to directly learn one or more of <span class="math inline">\(P(X,Y)\)</span> , <span class="math inline">\(P( X|Y )\)</span> and <span class="math inline">\(P(Y)\)</span></p><p>Usually, it would pre-decide the distribution form of P(Y|X) or P(Y), for example, the logistic regression suppose P(Y| X) follow a Bernoulli Distribution. Logistic Regression, Naive Bayes are probability model</p><p><strong>Parameter model v.s. Non-parameter model</strong></p><p>In statistics, a parameter estimation means an estimation with given hypothesis on the distribution of the whole population, while a non-parameter estimation does not have such hypothesis</p><p>For machine learning:</p><p>A parameter model means you have an explicit hypothesis on the mapping or the probability distribution, like liner regression, logistic regression, naive bayes(limited dimention of <span class="math inline">\(\theta\)</span>) or MLP. The advantage of such kind of models is, if the hypothesis is correct, the model can be fit with very small dataset. However, if the hypothesis is incorrect, no matter how large the dataset is, there would still be inevitable bias</p><p>A non-parameter model means you put no or limited hypothesis on the mapping or distribution, like KNN, tree-based model, SVM(non-linear). The cost of storage and calculation of non-parameter model would be bigger, but theoretically, a non-parameter can fit any complicated mapping as long as we have enough data. Usually a non-parameter model has a few hyperparameters and infinite parameters</p><p><strong>Discriminative model v.s. Generative model </strong></p><p>A discriminative model directly model on Y:</p><ul><li>All non-probability models are discriminative models</li><li>If a probability models try to directly learn <span class="math inline">\(P(Y|X)\)</span>, it is a discriminative model</li></ul><p>including most machine learning model like MLP, logistic regression, decision tree, KNN and SVM</p><p>A Generative model try to induce <span class="math inline">\(P( X| Y)\)</span> through learning P(X, Y) and P(Y), with <span class="math display">\[P(X,Y) = P(X| Y )P(Y)\]</span></p><p><span class="math display">\[P(Y|X) = \frac{P(X,Y)}{P(X)}\]</span> including naive bayesï¼ŒGMM</p><h2 id="unsupervised-machine-learning">3. Unsupervised Machine Learning</h2><p>Unsupervised learning is a kind of machine learning where the output variable of the model is not labeled in the dataset. Typically we can separate unsupervised machine learning algorithm into serval types according to the task we want it to perform</p><h3 id="feature-learning">3.1 Feature learning</h3><p>Mining useful expression or combination of features in unlabeled dataset. Usually applied in dimensionality reduction or visualization, including:</p><ul><li>PCA , T- SNE, SVD</li><li>Sparse Encoding, Auto-encoder ,Denoising Autoencoder</li></ul><h3 id="probabilistic-density-estimation">3.2 Probabilistic Density Estimation</h3><p>Induce the probability density function of a variable through observational data, can be classified as:</p><ul><li>Parametric Density Estimation: have prior hypothesis on the distribution form of the variable,including MLE, MAP etc.</li><li>Non-parametric Density Estimation: do not have a prior hypothesi, including histogram, Kernel Density Estimation(KDE) etc.</li></ul><h3 id="clustering">3.3 Clustering</h3><p>Segment unlabeled dataset into different groups. Including K-Means, DBscan, hierarchical clustering etc.</p><h3 id="other-unsupervised-learning">3.4 Other Unsupervised Learning</h3><p>There are lots of emerging unsupervised learning algorithm like pred-Net, GAN etc. These algorithm would be elaborated in single section in other articles</p>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Basic Knowledge</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hypothesis Testing</title>
    <link href="/2022/03/25/Hypothesis-Testing/"/>
    <url>/2022/03/25/Hypothesis-Testing/</url>
    
    <content type="html"><![CDATA[<h1 id="hypothesis-testing">Hypothesis Testing</h1><h2 id="definition-and-terms">1. Definition and Terms</h2><p>Hypothesis testing is a kind of statistical inference method.</p><table><thead><tr class="header"><th style="text-align: center;">Term</th><th style="text-align: center;">Meaning</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">Hypothesis</td><td style="text-align: center;">A claim to test</td></tr><tr class="even"><td style="text-align: center;">Null Hypothesis (<span class="math inline">\(H_0\)</span>)</td><td style="text-align: center;">Currently accepted value for a parameter(e.g diff = 0)</td></tr><tr class="odd"><td style="text-align: center;">Alternative Hypothesis(<span class="math inline">\(H_a\)</span>)</td><td style="text-align: center;">The claims to be tested. <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_a\)</span> are mathematically opposites</td></tr><tr class="even"><td style="text-align: center;">Test Outcomes</td><td style="text-align: center;">Reject <span class="math inline">\(H_0\)</span> or fail to reject <span class="math inline">\(H_0\)</span></td></tr><tr class="odd"><td style="text-align: center;">Test Statistics</td><td style="text-align: center;">Statistics calculated from the data samples used to decide whether to reject <span class="math inline">\(H_0\)</span></td></tr><tr class="even"><td style="text-align: center;">Big/Small Sample</td><td style="text-align: center;">sample size -&gt; inf / sample size is fixed, usually set threshold to 30</td></tr><tr class="odd"><td style="text-align: center;">Central Limit Theorem</td><td style="text-align: center;">A theorem that indicates no matter what distribution the total population is, when sample size n is big enough, the average of a statistics of a sample <span class="math inline">\(\bar{X}\)</span> follows a normal distribution N(<span class="math inline">\(\mu\)</span>, <span class="math inline">\(\frac{\sigma^2}{n}\)</span>). This theorem allows implementation of T- test on average of continuous test statistics, like average salary of a department</td></tr><tr class="even"><td style="text-align: center;">Degree of Freedom</td><td style="text-align: center;">The number of samples(n) -1</td></tr><tr class="odd"><td style="text-align: center;">Effect Size</td><td style="text-align: center;">The degree the test statistics differ from the accepted value</td></tr><tr class="even"><td style="text-align: center;">Significance Level(1-<span class="math inline">\(\alpha\)</span>)</td><td style="text-align: center;">A decided threshold of <span class="math inline">\(\alpha\)</span>. <span class="math inline">\(\alpha\)</span> is the probability of rejecting <span class="math inline">\(H_ 0\)</span> when <span class="math inline">\(H_ 0\)</span> is ture(Type I Error)</td></tr><tr class="odd"><td style="text-align: center;">Confidence Level</td><td style="text-align: center;">How confident we are to reject <span class="math inline">\(H_0\)</span> (1-<span class="math inline">\(\alpha\)</span>)</td></tr><tr class="even"><td style="text-align: center;">p value</td><td style="text-align: center;">The probability that the observed statistics significance are caused by random factor</td></tr><tr class="odd"><td style="text-align: center;">statistical power(<span class="math inline">\(1-\beta\)</span>)</td><td style="text-align: center;"><span class="math inline">\(\beta\)</span> is the the probability of accepting <span class="math inline">\(H_ 0\)</span> when <span class="math inline">\(H_ 0\)</span> is False(Type II Error). Typically we need the power of a test to be greater than 80%</td></tr><tr class="even"><td style="text-align: center;">Confidence Interval</td><td style="text-align: center;">With <span class="math inline">\(\alpha\)</span> as significance level, <span class="math inline">\(\theta\)</span> as test statistics, if <span class="math inline">\(P\{ \theta_n &lt; \theta &lt; \theta_m \} \ge 1-\alpha\)</span>, then we call <span class="math inline">\((\theta_n , \theta_m)\)</span> the confidence interval of <span class="math inline">\(\theta\)</span> uhder the significance level <span class="math inline">\(1-\alpha\)</span></td></tr><tr class="odd"><td style="text-align: center;">One-tail Test/Two-tail Test</td><td style="text-align: center;">In one-tail test, the <span class="math inline">\(H_a\)</span> has direction, so <span class="math inline">\(H_a\)</span> would be like <span class="math inline">\(\mu &gt; x\)</span>, and we only focus on one side of the rejection area in this case. While in two tail test, <span class="math inline">\(H_a\)</span> would be like <span class="math inline">\(\mu \ne x\)</span></td></tr><tr class="even"><td style="text-align: center;">Rejection Area</td><td style="text-align: center;">Let the the area of PDF on <span class="math inline">\((-inf,z_1],[z_2,inf)] = \alpha\)</span>, then this area is called rejection area, <span class="math inline">\(b_0,b_1\)</span> are called rejection boundaries, which are the z-score when the area one the left/right side is <span class="math inline">\(\frac{\alpha}{2}\)</span>. When the test statistics fall outside the rejection boundaries, we can reject <span class="math inline">\(H_0\)</span> under the Level of Significance</td></tr><tr class="odd"><td style="text-align: center;">MDE</td><td style="text-align: center;">The minimum detectable effect size of a experiment when <span class="math inline">\(1-\alpha\)</span> and <span class="math inline">\(\beta\)</span> is given. If detected effect size <span class="math inline">\(d &lt; mde\)</span>, it might be caused by random factor, and we cannot reject <span class="math inline">\(H_ 0\)</span></td></tr><tr class="even"><td style="text-align: center;">PSB</td><td style="text-align: center;">Practical Significance Boundary</td></tr></tbody></table><p><img src="/2022/03/25/Hypothesis-Testing/img1.png"></p><p><strong>Power and Error</strong></p><p><img src="/2022/03/25/Hypothesis-Testing/img3.PNG"></p><h2 id="basic-procedure-of-hypothesis-testing">2. Basic Procedure of Hypothesis Testing</h2><h3 id="propose-hypothesis">2.1 Propose Hypothesis</h3><p>Clarify the null hypothesis and alternative hypothesis to test on</p><h3 id="test-type">2.2 Test Type</h3><p><img src="/2022/03/25/Hypothesis-Testing/5.png"></p><h3 id="construct-test-statistics">2.3 Construct Test Statistics</h3><p>For differential test, we usually want to test the difference between a parameter. In most case, we want to test the statistics based on a normal distribution. To do so, we would aggregate the measure though an additive way so that the parameter follows a normal distribution no matter what type of distribution the original measure follows. Thus, the parameter can should be concluded into 2 types: mean and ratio.</p><p>Since the parameter follows the normal distribution, we can construct the test statistics through <strong>Cohen's d</strong>: <span class="math display">\[d = \frac{(\theta_1-\hat{\theta_1})-(\theta_2-\hat{\theta_2})}{\sigma_{SE,pooled}}\]</span> where <span class="math inline">\(\sigma_{SE}\)</span> measures the variance of a parameters <span class="math inline">\(V[\theta]\)</span>.</p><p>For a mean test, <span class="math inline">\(\theta\)</span> is a mean <span class="math inline">\(\bar{ X }\)</span> <span class="math display">\[V[\bar{X}] = V[\frac{(X_1+X_2+...X_n)}{n}] = \frac{1}{n^2}\sum_i^nV[X_i]=\frac{1}{n}V[X_i] = \frac{\sigma^2_X}{n}\]</span> For a ratio test, <span class="math inline">\(\theta\)</span> is a ratio R <span class="math display">\[V[R] = V[\frac{B_1+B_2+...+B_n}{n}] = \frac{1}{n^2}\sum_i^nV[B_i]=\frac{1}{n}p(1-p)\]</span> The calculation of pooled standard error would be discussed in the following sections</p><p>For ratio test, there's also another way to construct the test statistics called <strong>Cohen's h</strong>: <span class="math display">\[h = 2(arcsin \sqrt{p1} - arcsin\sqrt{p2})\]</span> For the correlation test between categorical variable, we can use <strong>Cramer's V</strong> to construct the test statistics <span class="math display">\[V = \sqrt{\frac{\chi^2/n}{min(c- 1,r-1)}}\]</span></p><h3 id="decide-testing-parameters">2.4 Decide Testing Parameters</h3><p><strong>Significance Level</strong></p><p>Decided by the preset <span class="math inline">\(\alpha\)</span> in the testing. <span class="math inline">\(1-\alpha\)</span> is the significance level, represent the strictness degree on judging significance.</p><p><strong>Statistical Power </strong></p><p>Decided by the preset <span class="math inline">\(\beta\)</span> in the testing. Statistical Power represents the probability of rejecting <span class="math inline">\(H_0\)</span> if it is indeed false, in other word, the probability of avoiding type II error. For example, in an one-tail differential Z test, let <span class="math inline">\(\beta&#39;\)</span> denote the real-time statistical power: <span class="math display">\[\beta&#39; = P(d \le Z_{1-\alpha/2}|H_0 \ False) = P(\frac{\theta_1 - \theta_2-\Delta}{\sigma_E} \le Z_{1-\alpha/2} - \frac{\Delta}{\sigma_E})\]</span> where <span class="math inline">\(\Delta = \theta_1 - \theta_2\)</span> is the real differential that exists. Let <span class="math inline">\(Z = \frac{\Delta}{\sigma_E}\)</span> <span class="math display">\[1 - \beta&#39; = 1-\Phi(Z_{1-\alpha/2}-Z) = \Phi(Z- Z_{1-\alpha/2})\]</span> For a two-tail Z test: <span class="math display">\[1 - \beta&#39; =  \Phi(Z- Z_{1-\alpha/2}) + \Phi(-Z-Z_{1-\alpha/2})\]</span></p><p><strong>Practical Significance Boundary</strong></p><p>The preset <span class="math inline">\(\delta\)</span> decided based on business goal. It is the minimum level of difference on metrics that we cares about. The PSB serve as an initial MDE used to decided minimum sample size.</p><p><strong>Vairance of Population</strong>: The estimation on <span class="math inline">\(\sigma^2\)</span> from the historical data of the population</p><p><strong>Estimate the sample size</strong></p><p>From the definition of the statistical power we can find that the minimum sample size required is associated with the expected statistical power. Given a fixed sensitivity(MDE), the higer power we want, the more sample we need. We can deduce the formula of minimum sample size as follows:</p><p>Mean Test: <span class="math display">\[n&#39; = \frac{(\sigma_1^2+\sigma_2^2)(z_{\alpha/2}+z_{\beta})^2}{\delta^2}\]</span> Ratio Test: <span class="math display">\[n&#39;= \frac{Z_{\alpha/2}\sqrt{\frac{p_1+p_0}{2}(1-\frac{p_1+p_0}{2})}+Z_\beta\sqrt{p_1(1-p_1)+p_0(1-p_0)}}{p_1-p_0}\]</span></p><ul><li>where <span class="math inline">\(p_0\)</span> is the baseline of the ratio</li><li><span class="math inline">\(p_1\)</span> is the expected level of the ratio, <span class="math inline">\(p_1 = p_0 + \delta\)</span></li></ul><h3 id="results-analysis">2.5 Results Analysis</h3><p>After the testing duration is reached, we can decide whether there is a statistical significance. Examine the p value of the observed results. If <span class="math inline">\(p &lt; \alpha\)</span> reject the Null hypothesis.</p><p>Also, check the sensitivity(the real-time mde). If the mde is greater than the preser <span class="math inline">\(\delta\)</span>, it is likely that the testing is underpower and needs more samples.</p><p>TO calculate real-time MDE <span class="math display">\[MDE = (t_{\frac{1-\alpha}{2}} + t_ {1-\beta})\sqrt{\frac{s_1^2}{n_ 1} + \frac{s_2^2}{n_ 2}}\]</span></p><p>According to the definition of the statistical power, the sensitivity of the testing is associated with the preset statistical power.</p><p><img src="/2022/03/25/Hypothesis-Testing/8.png"></p><p>In the this figure</p><ul><li>the orange area is the preset <span class="math inline">\(\beta\)</span></li><li>the green area represent the true type II error <span class="math inline">\(\beta&#39;\)</span></li><li><span class="math inline">\(\mu_0\)</span> is the mean of the test statements under <span class="math inline">\(H_0\)</span>, which is 0</li><li><span class="math inline">\(\mu^*\)</span> is the mean where the statistical power is exactly <span class="math inline">\(1-\beta\)</span>. <span class="math inline">\(\mu^*\)</span> decides the MDE of the experiment</li><li><span class="math inline">\(\mu_1\)</span> is the true value of the statistics estimated from the sample</li></ul><p>From the figure we can find out that if the true difference is bigger than MDE, than the ture statistical power is greater then we demands, and the experiment is overpowered. On the opposite, if the true difference is smaller than the MDE, than we cannot detect the difference with enough power, and the experiment is underpowered</p><p>When the sample size remains the same, higer power, which means lower type II error, demands the right-forward shift of mean of the parameter and leads to greater mde(lower sensitivity). If we want to improve sensity while maintaining the power, we would need more samples or find a way to lower the variance of the metrics</p><h2 id="zt-test">3. Z/T-test</h2><p><strong>Z Test</strong>:</p><p>A Z-test examine a statistics assuming it follow a standard normal distribution(distribution). Thus the construction of z statistics is <span class="math inline">\(Z = \frac{X-\mu}{\sigma}\)</span></p><p><strong>T-test</strong></p><p>A T-test construct a statistics like: <span class="math inline">\(t = \frac{X}{\sqrt{Y/n}}\)</span> where <span class="math inline">\(X\sim N(0,1)\)</span> and <span class="math inline">\(Y \sim \chi^2(n)\)</span> . In a mean test <span class="math inline">\(\sqrt{Y/n}\)</span> could be the standard error. The advantage of T test is, while it have similar testing capability as Z test when n is greater than 30, it does not require the population variance <span class="math inline">\(\sigma\)</span> to be given. Meanwhile, it has stronger testing capability when n is smaller than 30</p><h3 id="one-sample-test">3.1 One Sample Test</h3><p>Objective: to test whether the accepted mean or ratio of a population is correct through a sample. In this case, we can assume <span class="math inline">\(\mu_0\)</span> and <span class="math inline">\(\pi_0\)</span> is given</p><h4 id="sigma-givent-or-z">3.1.1 <span class="math inline">\(\sigma\)</span> Given(T or Z)</h4><p>In most application, the standard deviation of the whole population is unknown. But suppose we have the <span class="math inline">\(\sigma\)</span></p><p><strong>Big Sample</strong></p><p>For big sample, we conduct z-test and give hypothesis as:</p><p><span class="math inline">\(H_0: \mu = \mu_ 0\)</span> or <span class="math inline">\(\pi = \pi_0\)</span> for ratio test</p><p><span class="math inline">\(H_1: \mu \ne \mu_ 0\)</span> or <span class="math inline">\(\pi \ne \pi_0\)</span> for ratio test</p><p>where <span class="math inline">\(\mu_0\)</span> is the accepted value of the parameter and construct z-score as: <span class="math display">\[z = \frac{\bar{x}-\mu_0}{\sigma/\sqrt{n}}\]</span> for ratio test, construct z as: <span class="math display">\[z = \frac{p-\pi_0}{\sqrt{\frac{\pi_0(1-\pi_0)}{n}}}\]</span> <strong>Small Sample</strong></p><p>When the sample size is small, we can assume the sample ~ t distribution. The construction of the test statistics and reject condition are the same, the only difference is that the test statistics is now following t distribution</p><h4 id="sigma-unknownt">3.1.2 <span class="math inline">\(\sigma\)</span> Unknown(T)</h4><p>When <span class="math inline">\(\sigma\)</span> is unknown, the basic strategy is to replace population std with sample std, and apply t-test</p><p>We can conduct t-test and give hypothesis as:</p><p><span class="math inline">\(H_0: \mu = \mu_ 0\)</span> or <span class="math inline">\(\pi = \pi_0\)</span> for ratio test</p><p><span class="math inline">\(H_1: \mu \ne \mu_ 0\)</span> or <span class="math inline">\(\pi \ne \pi_0\)</span> for ratio test <span class="math display">\[t = \frac{\bar{x}-\mu_0}{s/\sqrt{n}}\]</span> for ratio test, construct t as: <span class="math display">\[t = \frac{p-\pi_0}{\sqrt{\frac{\pi_0(1-\pi_0)}{n}}}\]</span></p><h3 id="two-sample-test">3.2 Two Sample Test</h3><p>Objective: to test whether a condition would effect a metric through following one group before and after experiment or comparing two groups</p><h4 id="match-test">3.2.1 Match Test</h4><p>Usually applied when testing treatment on a same group of people in different time(e. g medical treatment). In this context, we can assum the sample size and standard deviation remain as same: <span class="math inline">\(n_ 1 = n_ 2, \sigma_1 = \sigma_2\)</span></p><h5 id="sigma-givenz">3.2.1.1 <span class="math inline">\(\sigma\)</span> Given(Z)</h5><p><span class="math inline">\(H_0: \mu_1 = \mu_ 0\)</span> or <span class="math inline">\(\pi_1 = \pi_0\)</span> for ratio test</p><p><span class="math inline">\(H_1: \mu_1 \ne \mu_ 0\)</span> or <span class="math inline">\(\pi_1 \ne \pi_0\)</span> for ratio test <span class="math display">\[z = \frac{(\bar{x_1}-\bar{x_0}) - (\mu_1-\mu_0)}{\sigma\sqrt{\frac{2}{n}}} = \frac{\bar{d}}{\sigma\sqrt{\frac{2}{n}}}\]</span> for ratio test, construct z as: <span class="math display">\[z = \frac{(p_1-p_0) - (\pi_1 - \pi_0)}{\sqrt{p(1-p)(\frac{2}{n})}}\]</span></p><p><span class="math display">\[p = \frac{p_0+p_1}{2}\]</span></p><h5 id="sigma-unkownt">3.2.1.2 <span class="math inline">\(\sigma\)</span> Unkown(T)</h5><p><span class="math inline">\(H_0: \mu_1 = \mu_ 0\)</span> or <span class="math inline">\(\pi_1 = \pi_0\)</span> for ratio test</p><p><span class="math inline">\(H_1: \mu_1 \ne \mu_ 0\)</span> or <span class="math inline">\(\pi_1 \ne \pi_0\)</span> for ratio test <span class="math display">\[t = \frac{\sqrt{n}((\bar{x_1}-\bar{x_0}) - (\mu_1-\mu_0))}{s_d} = \frac{\sqrt{n}\bar{d}}{s_d}\]</span> where <span class="math inline">\(s_d\)</span> is the standard deviation of d</p><p>for ratio test, construct z as: <span class="math display">\[t = \frac{(p_1-p_0) - (\pi_1 - \pi_0)}{\sqrt{p(1-p)(\frac{2}{n})}}\]</span></p><p><span class="math display">\[p = \frac{p_0+p_1}{2}\]</span></p><h4 id="independent-test">3.2.2 Independent Test</h4><p>Usually applied when evaluation the effect of a treatment by comparing a experiment group and control group, which is A/B Testing</p><h5 id="sigma-givenz-1">3.2.2.1 <span class="math inline">\(\sigma\)</span> Given(Z)</h5><p><span class="math inline">\(H_0: \mu_1 = \mu_ 0\)</span> or <span class="math inline">\(\pi_1 = \pi_0\)</span> for ratio test</p><p><span class="math inline">\(H_1: \mu_1 \ne \mu_ 0\)</span> or <span class="math inline">\(\pi_1 \ne \pi_0\)</span> for ratio test</p><p>if <span class="math inline">\(\sigma_1 = \sigma_2\)</span> <span class="math display">\[z = \frac{((\bar{x_1}-\bar{x_2}) - (\mu_1-\mu_2))}{\sigma \sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}\]</span></p><p>if <span class="math inline">\(\sigma_1 \ne \sigma_2\)</span> <span class="math display">\[z  = \frac{(\bar{x_1}-\bar{x_2}) - (\mu_1-\mu_2)}{\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}}\]</span> for ratio test: <span class="math display">\[z = \frac{(p_1-p_2) - (\pi_1 - \pi_2)}{\sqrt{p(1-p)(\frac{1}{n_1}+\frac{1}{n_2})}}\]</span></p><p><span class="math display">\[p = \frac{p1*n1+p_2*n_2}{n_1+n_2}\]</span></p><h5 id="sigma-uknownt">3.2.2.1 <span class="math inline">\(\sigma\)</span> Uknown(T)</h5><p><span class="math inline">\(H_0: \mu_1 = \mu_ 0\)</span> or <span class="math inline">\(\pi_1 = \pi_0\)</span> for ratio test</p><p><span class="math inline">\(H_1: \mu_1 \ne \mu_ 0\)</span> or <span class="math inline">\(\pi_1 \ne \pi_0\)</span> for ratio test</p><p>if <span class="math inline">\(\sigma_1 = \sigma_2\)</span> <span class="math display">\[t = \frac{((\bar{x_1}-\bar{x_2}) - (\mu_1-\mu_2))}{s_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}\]</span></p><p><span class="math display">\[s_p = \sqrt{\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}}\]</span></p><p>if <span class="math inline">\(\sigma_1 \ne \sigma_2\)</span> <span class="math display">\[t = \frac{((\bar{x_1}-\bar{x_2}) - (\mu_1-\mu_2))}{\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}}\]</span> for ratio test: <span class="math display">\[t = \frac{(p_1-p_2) - (\pi_1 - \pi_2)}{\sqrt{p(1-p)(\frac{1}{n_1}+\frac{1}{n_2})}}\]</span></p><p><span class="math display">\[p = \frac{p1*n1+p_2*n_2}{n_1+n_2}\]</span></p><h2 id="f-test">4. F-test</h2><p>An F-test construct the test statistics like <span class="math inline">\(\frac{U_1/d_1}{U_2/d_2}\)</span>, where <span class="math inline">\(U1 \sim \chi^2(d_1)\)</span> and <span class="math inline">\(U_2\sim \chi^2(d_2)\)</span>. In testing for Equality of Variances, the <span class="math inline">\(\frac{U}{d}\)</span> can be the standard error</p><h3 id="equality-of-variances">4.1 Equality of Variances</h3><p>Through F-test, we can examine the equality of the variances of two normally distributed varaible</p><p>Let <span class="math inline">\(X_1,X_2\)</span> be two independent variables, where: <span class="math display">\[X_1~N(\mu_1,\sigma_1^2),  X_2~N(\mu_2,\sigma_2^2)\]</span> Get a sample from each variable: <span class="math inline">\(x_1, x_2\)</span>, the sample sizes are <span class="math inline">\(n_1,n_2\)</span></p><p>Let <span class="math inline">\(\bar{x}_1,\bar{x}_2\)</span> be the mean of the samples, <span class="math inline">\(s_1,s_2\)</span> be the standard error of the samples</p><p>Set the null hypothesis and alternative hypothesis of Experiment: <span class="math display">\[H_ 0: \sigma_1^2 = \sigma_2^2\\H_ 1: \sigma_1^2 \neq \sigma_2^2\]</span> If it is a one-tail experiment: <span class="math display">\[H_ 0: \sigma_1^2 &lt; \sigma_2^2\\H_ 1: \sigma_1^2 \ge \sigma_2^2\]</span></p><p>Construct F statistics: <span class="math display">\[F(n_1-1,n_2-1) = \frac{s_1^2/\sigma_1^2}{s_2^2/\sigma_2^2}=\frac{s_ 1^2}{s_2^2}\]</span> Note: As a convention, we normally select the greater s as <span class="math inline">\(s_ 2\)</span> to let f score &lt;1</p><p>Look up the F score table, if <span class="math inline">\(F &gt; F_{\alpha}\)</span>, reject <span class="math inline">\(H_0\)</span></p><p>If it is a one-tail experiment, then reject <span class="math inline">\(H_0\)</span> when <span class="math inline">\(F &lt; F_{1-\alpha}\)</span></p><h3 id="single-factor-anova">4.2 Single Factor ANOVA</h3><p>We can use f- test to examine the impact of a factor to an indicator by judging if the indicator is same when the factor is set to different value</p><p>Let the factor be Y, indicator be x</p><p>Suppose we got the following observations:</p><table><thead><tr class="header"><th>Y = Y1</th><th>Y=y2</th><th>y=y3</th><th>y=y4</th></tr></thead><tbody><tr class="odd"><td>x=1</td><td>x=2</td><td>...</td><td>...</td></tr><tr class="even"><td>x=3</td><td>x=3</td><td>...</td><td>...</td></tr><tr class="odd"><td>x=2</td><td>x=4</td><td>...</td><td>...</td></tr><tr class="even"><td>x=6</td><td>x=6</td><td>...</td><td>...</td></tr></tbody></table><p>Let k = number of groups(number of different values of Y)</p><p>Let <span class="math inline">\(n_i\)</span> = the number of samples in <span class="math inline">\(i_{th}\)</span> group</p><p>Let n = <span class="math inline">\(max(n_ k)\)</span></p><p>Construct <span class="math display">\[F = \frac{SSA/df1}{SSE/df2}\]</span> where:</p><ul><li><p>df1 = k - 1</p></li><li><p>df2 = n- k</p></li><li><p>SSA is Sum of Square Between Groups:</p><p><span class="math display">\[SSA = \sum_{i=1}^kn_i(\bar{x_i}-\bar{x})\]</span> Where:</p><ul><li><span class="math inline">\(\bar{x_i}\)</span> is the average of the <span class="math inline">\(i_{th}\)</span> group</li><li><span class="math inline">\(\bar{x}\)</span> is the average of all <span class="math inline">\(\bar{x_i}\)</span></li></ul></li><li><p>SSE is the Sum of square error <span class="math display">\[SSE = \sum_{i=1}^k(n_i-1)s_i^2\]</span> Where:</p><ul><li><span class="math inline">\(s_1^2\)</span> is the variance(square of standard error) of the <span class="math inline">\(i_{th}\)</span> group</li></ul></li></ul><p>Look up the F score table, if <span class="math inline">\(F &gt; F_{\alpha}\)</span>, reject <span class="math inline">\(H_0\)</span>(the factor do has an impact)</p><h3 id="exam-on-the-significance-of-the-linear-regression">4.3 Exam on the significance of the Linear Regression</h3><p>We can use f-test to examine on whether a liner model(linear hypothesis) fit a problem well</p><p>Suppose we got the following linear hypothesis function: <span class="math display">\[y = \beta_1x_1 + \beta_2x_ 2 + \beta_ 0\]</span> Define SSR as: <span class="math display">\[SSR = ||\hat{y}-\bar{y}1_n||^2\]</span> Where:</p><ul><li><span class="math inline">\(\hat{y}\)</span> is the prediction of y</li><li><span class="math inline">\(\bar{ y }\)</span> is the average of true y</li><li>1n is a vector with all one</li></ul><p>Define SSE as: <span class="math display">\[SSR = ||y- \hat{y}||^2\]</span> Construct F statistics as: <span class="math display">\[F = \frac{SSR/p}{SSE/(n-p-1)}\]</span> where:</p><ul><li><p>n is number of samples</p></li><li><p>p is number of variables(x)</p></li></ul><p>Look up the F score table, if <span class="math inline">\(F &gt; F_{\alpha}\)</span>, reject <span class="math inline">\(H_0\)</span>. In such case, the linear model is significant to the change of the x and y, thus the linear hypothesis is acceptable. Otherwise, consider a non-linear model</p><h2 id="chi2-test">5. <span class="math inline">\(\chi^2\)</span> Test</h2><p>A <span class="math inline">\(\chi^2\)</span> Test construct the test statistics as a function of a <span class="math inline">\(\chi^2\)</span> variable. The degree of freedom are usually involved in the construction of such a statistics</p><h4 id="chi-squared-test-for-independence">5.1 Chi-squared Test for Independence</h4><p>chi-squared test is a <strong>supervised</strong> hypothesis testing method to calculate the probability that 2 categorical variables are correlated</p><p>Suppose there are categorical variables X and Y, X has r possible values, with probability <span class="math inline">\((p_{x,1},...p_{x,r})\)</span> and Y has c possible values, with probability <span class="math inline">\((p_{y,1},...p_{y,c})\)</span>.</p><p>Under the null hypothesis, since X and Y are independent, the probability of observing <span class="math inline">\(X=c_{x,i}, Y = c_{y,j}\)</span> would be <span class="math inline">\(p_{i,j} = p_{x,i}p_{y,j}\)</span></p><p>In such case, let <span class="math inline">\(t_{i,j}\)</span> be the observed times that <span class="math inline">\(X=c_{x,i}, Y = c_{y,j}\)</span>, t would follow a binomial distribution <span class="math inline">\(Bin(t;n,p_{ij})\)</span></p><p>According to properties of binomial distribution, when n is big enough, <span class="math inline">\(Bin(t;n,p_{i,j})\)</span> is approximately <span class="math inline">\(N(np_{i,j},np_{i,j}(1-p_{i,j}))\)</span></p><p>According to the definition of <span class="math inline">\(\chi^2\)</span> distribution, let <span class="math display">\[\chi^2=\sum_i^r\sum_j^c \frac{(t_{i,j}-E[t_{i,j})^2]}{E[t_{i,j}]}\]</span> <span class="math inline">\(\chi^2\)</span> would follow a <span class="math inline">\(\chi^2\)</span> distribution, with the degree of freedom being <span class="math inline">\((r-1)(c-1)\)</span></p><p>We can calculate the <span class="math inline">\(\chi^2\)</span> and obtain its according p value through p value table for <span class="math inline">\(\chi^2\)</span> distribution. If p &lt; 0.05, we can reject the null hypothesis that the two variables is independent</p><p>Note that in a <span class="math inline">\(\chi^2\)</span> testm the probability <span class="math inline">\((p_{x,1},...p_{x,r})\)</span> and <span class="math inline">\((p_{y,1},...p_{y,c})\)</span> is not a hypothesis to test, it is a believed fact. In real application, it needs to be estimated from observations. When number of observations is big enough, the error of estimation can be ignored.</p><p>A example is given below:</p><ol type="1"><li><p>According to the observations, make the frequency table</p></li><li><p>calculate the row total and the column total</p></li><li><p>calculate the expectations for each cell by <span class="math inline">\(\frac{R_i*C_j}{total}\)</span> (<span class="math inline">\(\frac{125*310}{600} = 65\)</span>,etc.)</p></li><li><p>the <span class="math inline">\(\chi^2\)</span> would be <span class="math display">\[\chi_{i,j}^2 = \frac{(O_{i,j} - E_{i,j})^2}{E_{i,j}}\\\chi^2 = \sum_{i,j}^{r,c}\chi_{i,j}^2\]</span></p><table><thead><tr class="header"><th>movie type</th><th>High POPULARITY</th><th>low POPULARITY</th><th>Row total</th></tr></thead><tbody><tr class="odd"><td>type1</td><td>50(65)</td><td>75(60)</td><td>125</td></tr><tr class="even"><td>type2</td><td>125(155)</td><td>175(145)</td><td>300</td></tr><tr class="odd"><td>type3</td><td>...</td><td>...</td><td>...</td></tr><tr class="even"><td>type4</td><td>...</td><td>...</td><td>...</td></tr><tr class="odd"><td>column total</td><td>310</td><td>290</td><td>600</td></tr></tbody></table></li><li><p>calculate the degree of freedom, <span class="math inline">\(k=(r-1)(c-1)\)</span></p></li><li><p>check the significance table of chi distribution to find the threshold of <span class="math inline">\(\chi^2\)</span> given k and <span class="math inline">\(\alpha\)</span></p></li><li><p>compare the <span class="math inline">\(\chi^2\)</span> with the rejection area, if <span class="math inline">\(\chi^2\)</span> is greater than the threshold(which means p value is smaller than <span class="math inline">\(\alpha\)</span>), then reject the null hypothesis</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> SelectKBest, chi2<br>X, y = data_0,target_0<br>X_new = SelectKBest(chi2, k=<span class="hljs-number">2</span>).fit_transform(X, y)<br></code></pre></td></tr></table></figure><h3 id="chi-squared-test-for-goodness-of-fit">5.2 Chi-squared Test for Goodness of fit</h3><p>The process is basically the same.</p><table><thead><tr class="header"><th>Category</th><th>Predicted times</th><th>Observed time</th></tr></thead><tbody><tr class="odd"><td>C1</td><td>...</td><td></td></tr><tr class="even"><td>C2</td><td></td><td></td></tr><tr class="odd"><td>C3</td><td></td><td></td></tr></tbody></table><p>Construct the <span class="math inline">\(\chi^2\)</span> as: <span class="math display">\[\chi^2 = \sum_i^k\frac{O_i-P_i}{P_i}\]</span> the <span class="math inline">\(\chi^2\)</span> follows a <span class="math inline">\(\chi^2(k-1)\)</span> when number of observations is big enough</p>]]></content>
    
    
    <categories>
      
      <category>A/B Testing &amp; Case Interview</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Hypothesis Testing</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Feature Selection: Statistical Method</title>
    <link href="/2022/02/09/feature-selection-stats-method/"/>
    <url>/2022/02/09/feature-selection-stats-method/</url>
    
    <content type="html"><![CDATA[<h1 id="feature-selection">Feature Selection</h1><h2 id="filter">1. Filter</h2><p>Evaluate features on divergence and correlation. set one or more thresholds and select the feature.</p><p><strong>Pro</strong>: fast, scalable, independent of the model</p><p><strong>Con</strong>: ignore the dependence of features</p><h3 id="varianceskewness">1.1 Variance/Skewness</h3><p>For most models, variables with high variance or skewness would be weighted more and deemed as more important. Thus, we can</p><ol type="1"><li>calculate the variance(not STD) of each feature</li><li>set a threshold, select all features whose variance bigger than the threshold</li></ol><p>Calculation of Skewness: <span class="math display">\[SK = \frac{n\sum(x_i-\bar{x})^3}{(n-1)(n-2)\sigma^3}\]</span> An implementation of feature selection based on variance in Python</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> VarianceThreshold<br><span class="hljs-comment">#threshold æ˜¯æ–¹å·®çš„é˜ˆå€¼</span><br><span class="hljs-comment">#è¿”å›žé€‰æ‹©åŽçš„ç‰¹å¾</span><br>data_1 = VarianceThreshold(threshold=<span class="hljs-number">0.25</span>).fit_transform(data_0)<br></code></pre></td></tr></table></figure><h3 id="correlation">1.2 Correlation</h3><ol type="1"><li>calculate the correlation value between each feature and the target</li><li>select the features with top K biggest correlation value</li></ol><h4 id="pearson-r">1.2.1 Pearson R</h4><p>Pearson R calculates correlation based on covariance. <span class="math display">\[p_{X,Y} = \frac{cov(X,Y)}{\sigma_X \sigma_Y} = \frac{E[(X - \mu_X)(Y-\mu_Y)]}{\sigma_X \sigma_Y} = \frac{E[XY]-E[X]E[Y]}{\sqrt{(E[X^2]-E[X])^2} \sqrt{(E[Y^2]-E[Y])^2}}\]</span> For a sample with n samples: <span class="math display">\[r = \frac{\sum_i^n(X_i-\bar{X})(Y_i-\bar{Y})}{\sqrt{\sum_i^n(X_i-\bar{X})^2} \sqrt{\sum_i^n(Y_i-\bar{Y})^2}} = \frac{\sum XY - \frac{\sum X \sum Y}{n}}{\sqrt{\sum X^2 - \frac{(\sum X)^2 }{n}} \sqrt{\sum Y^2 - \frac{(\sum Y)^2 }{n}}}\]</span> The Pearson R has following properties:</p><ul><li>The range of Pearson R is [-1,1], positive numbers indicate positive correlation</li><li>The Pearson R represents the linear correlation between two variables, linear transformation of X or Y does not change Pearson R</li><li>X and Y must be numerical variables and follow normal distribution</li><li>The observations of X and Y are in pairs</li></ul><h4 id="spearman">1.2.2 Spearman</h4><p>Suppose we have samples of X and Y with n observations. Sort the observations X and Y to obtain two new set <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>, where <span class="math inline">\(a_i,b_i\)</span> is the rank of <span class="math inline">\(X_i,Y_i\)</span> in X,Y</p><p>define Spearman correlation as: <span class="math display">\[\rho = \frac{6\sum_i^n(a_i-b_i)^2}{n(n^2-1)}\]</span> The Spearman correlation has following properties:</p><ul><li>The range of Spearman correlations is [-1,1], positive numbers indicate positive correlation</li><li>The Spearman correlation represents rank correlation (simply based on size relationship)</li><li>X and Y does not need to follow certain distribution. Aithough the sample must be the same, they do not need to be in pairs<br></li><li>The statistical power of Spearman is relatively lower</li></ul><p><img src="/2022/02/09/feature-selection-stats-method/1.png"></p><h4 id="kendall">1.2.3 Kendall</h4><p>Suppose we combine variables X and Y into a new element <span class="math inline">\((X,Y)\)</span>. If two elements <span class="math inline">\((X_i, Y_i)\)</span> and <span class="math inline">\(X_j,Y_j\)</span> satisfy either of these two case:</p><ul><li><span class="math inline">\(X_i &gt; X_j\)</span> and <span class="math inline">\(Y_i &gt;Y_j\)</span></li><li><span class="math inline">\(X_i &lt; X_j\)</span> and <span class="math inline">\(Y_i &lt;Y_j\)</span></li></ul><p>Then we call these two elements have consistency</p><p>if <span class="math inline">\(X_i = X_j\)</span> and <span class="math inline">\(Y_i = Y_j\)</span>, we regard these two elements as having neither consistency nor inconsistency. Otherwise, we call these two elements have inconsistency</p><p>define Kendall correlation as: <span class="math display">\[\tau = \frac{C-D}{\sqrt{N3-N1}\sqrt{N_3-N_2}{}}\]</span> where:</p><ul><li><p>C is number of paris of elements(Two element <span class="math inline">\((X _1,Y_1),(X_2,Y_ 2)\)</span> is one pair) that have consistency</p></li><li><p>D is number of paris of elements that have inconsistency</p></li><li><p><span class="math inline">\(N1 = \sum_i^s \frac{ 1}{2}U_i(U_i-1)\)</span>, where:</p><ul><li>s is the number of values in X that appears more than once</li><li><span class="math inline">\(U_i\)</span> is the number those values appears(For <span class="math inline">\(i^{th}\)</span> Values in s)</li><li>For example, for a X={1,2,2,3,3,3,4}, s=2, <span class="math inline">\(U_1 = 2, U_2 = 3\)</span></li></ul></li><li><p>N2 is calculated same way as N1 on Y</p></li><li><p><span class="math inline">\(N3 = \frac{1}{2}N(N- 1)\)</span>, where is the number of samples</p></li></ul><p>The Kendall correlations have similar conditions as Pearson R. The only difference is it represents rank correlation instead of linear correlation</p><ul><li>The range of Pearson R is [-1,1], positive numbers indicate positive correlation</li><li>X and Y must be numerical variables and follow normal distribution</li><li>The observations of X and Y are in pairs</li></ul><p><strong>An implementation of feature selection based on Pearson R in Python</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> SelectKBest<br><span class="hljs-keyword">from</span> scipy.stats <span class="hljs-keyword">import</span> pearsonr<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_all_pscore</span>(<span class="hljs-params">x,y</span>):</span><br>    k = np.zeros([<span class="hljs-number">4</span>,<span class="hljs-number">2</span>])<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,x.shape[<span class="hljs-number">1</span>]):<br>        temp = pearsonr(x[:,i],y[:,<span class="hljs-number">0</span>])<br>        k[i,:] = np.array(temp)<br>    <span class="hljs-keyword">return</span> [k.T[<span class="hljs-number">0</span>],k.T[<span class="hljs-number">1</span>]]<br><span class="hljs-comment"># ä¸‹é¢çš„å†™æ³•æœ‰é—®é¢˜ç†è®ºä¸Šåº”è¯¥ä¸Žä¸Šé¢çš„å‡½æ•°ç­‰ä»·ï¼Œå®žé™…ä¸Šåœ¨è°ƒç”¨np.arrayæ—¶ï¼Œä¼šæŠŠæœ€å†…å±‚çš„pearsonrç³»æ•°å€¼å˜æˆä¸€ä¸ªæ•°ç»„å¯¹è±¡ï¼Œå¯¼è‡´SelectKBestæ— æ³•</span><br><span class="hljs-comment"># éåŽ†ï¼Œéœ€è¦ç”¨astypeæŠŠç¬¬ä¸€åˆ—è½¬åŒ–ä¸ºfloatï¼Œä½†è¿™æ ·å¾ˆéš¾å°è£…è¿›lambdaå‡½æ•°é‡Œï¼Œä¸å¦‚ä¸ç”¨ï¼Œå†™è¿™ä¸ªçš„äººé“ntï¼Œå®³æˆ‘ç ”ç©¶ä¸€ä¸ªå¤šå°æ—¶</span><br><span class="hljs-comment"># get_all_pscore =  lambda X,Y:np.array(list(map(lambda x:pearsonr(x,Y),X.T))).T</span><br><br><span class="hljs-comment">#ç¬¬ä¸€ä¸ªå‚æ•°ä¸ºä¸€ä¸ªcallable()ï¼Œè¯¥å‡½æ•°ä»¥featureï¼Œtargetä¸ºè¾“å…¥ï¼Œè¾“å‡ºå¯ä»¥æ˜¯ä¸¤ç§ï¼š</span><br><span class="hljs-comment"># 1. ä¸€å¯¹æ•°ç»„pearsonrç³»æ•°-på€¼ï¼ˆå¯ä»¥æ˜¯tupleä¸­ä¸¤ä¸ªæ•°ç»„ï¼Œä¹Ÿå¯ä»¥æ˜¯ndarrayï¼Œæ€»ä¹‹ç¬¬ä¸€ä¸ªç»´åº¦é¡»ä¸º2</span><br><span class="hljs-comment"># 2. ä¸€ä¸ªå•ä¸€çš„æ•°ç»„ï¼ˆåªæœ‰ç›¸å…³ç³»æ•°ï¼‰</span><br><span class="hljs-comment"># ç¬¬äºŒä¸ªå‚æ•°kï¼Œä»£è¡¨é€‰æ‹©å‰kä¸ª</span><br>data_1 = SelectKBest(get_all_pscore(),k=<span class="hljs-number">2</span>).fit_transform(data_0,target_0)<br></code></pre></td></tr></table></figure><h3 id="hypothesis-testing">1.3 Hypothesis Testing</h3><h4 id="chi-squared-test">1.3.1 Chi-Squared Test</h4><p>chi-squared test is a <strong>supervised</strong> hypothesis testing method to calculate the probability that 2 variables are correlated</p><ol type="1"><li><p>According to the observations, make the frequency table</p></li><li><p>calculate the row total and the column total</p></li><li><p>calculate the expectations for each cell by <span class="math inline">\(\frac{R_i*C_j}{total}\)</span> (<span class="math inline">\(\frac{125*310}{600} = 65\)</span>,etc.)</p></li><li><p>the chi2 of each cell and the total chi2 are given by <span class="math display">\[\chi_{i,j}^2 = \frac{(O_{i,j} - E_{i,j})^2}{E_{i,j}}\\\chi^2 = \sum_{i,j}^{r,c}\chi_{i,j}^2\]</span></p></li><li><p>calculate the degree of freedom, <span class="math inline">\(k=(r-1)(c-1)\)</span></p><table><thead><tr class="header"><th>movie type</th><th>High POPULARITY</th><th>low POPULARITY</th><th>Row total</th></tr></thead><tbody><tr class="odd"><td>type1</td><td>50(65)</td><td>75(60)</td><td>125</td></tr><tr class="even"><td>type2</td><td>125(155)</td><td>175(145)</td><td>300</td></tr><tr class="odd"><td>type3</td><td>...</td><td>...</td><td>...</td></tr><tr class="even"><td>type4</td><td>...</td><td>...</td><td>...</td></tr><tr class="odd"><td>column total</td><td>310</td><td>290</td><td>600</td></tr></tbody></table></li><li><p>check the significance table of chi distribution to find the value of the random variable under given k and <span class="math inline">\(\alpha\)</span></p></li><li><p>compare the <span class="math inline">\(\chi^2\)</span>z with the rejection area, if <span class="math inline">\(\chi^2\)</span> &gt; the found value(which means p value is smaller than <span class="math inline">\(\alpha\)</span>), then reject the null hypothesis</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> SelectKBest, chi2<br>X, y = data_0,target_0<br>X_new = SelectKBest(chi2, k=<span class="hljs-number">2</span>).fit_transform(X, y)<br></code></pre></td></tr></table></figure><h3 id="mutual-information">1.4 Mutual Information</h3><p>For the theoretical part about Entrophy and Mutual Information, refer to <a href="http://zhengyuanyang.com/2022/09/22/information-theory-in-ML/">this article</a> <span class="math display">\[MI = H(x,y) - H(x|y) - H(y|x) = \sum_x\sum_yp(x,y)log\frac{p(x,y)}{p(x)p(y)}\\\]</span> Suppose we have an input variable X with n samples and m unique values {<span class="math inline">\(x_1 = c_ 1,x_2 =c_ 1,...x_n = c_m\)</span>} and an output variable Y with n samples and k unique values {<span class="math inline">\(y_1 = c_ 1,y_2 =c_ 1,...y_n = c_k\)</span>}</p><p>It's easy to calculate <span class="math inline">\(P(X=c_i),P(Y=c_j),P(X=c_i,Y=c_j)\)</span></p><p>Thus the MI can be calculated. The greater MI X and Y share, the greater dependency there exists, and X is thus a more important feature.</p><p>The MI mtheod have the following properties:</p><ul><li>MI method is sometime impractical with two continuous numerical variables, since there are too many unique values</li><li>MI needs some certain metrics to map the original values in to a range(usually [0,1]), so that MI score of different variables can be compared</li></ul><p>An implementation of feature selection based on Mutual Information in Python:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mutual_info_score<br>MI_matrix = np.zeros([data_and_target.shape[<span class="hljs-number">1</span>],data_and_target.shape[<span class="hljs-number">1</span>]])<br><span class="hljs-comment"># calculate the MI matrix between each two feature</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,data_and_target.shape[<span class="hljs-number">1</span>]):<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,data_and_target.shape[<span class="hljs-number">1</span>]):<br>        MI_matrix[i,j] = mutual_info_score(data_and_target[i+<span class="hljs-number">1</span>],data_and_target[j+<span class="hljs-number">1</span>])<br>df = pd.DataFrame(MI_matrix,columns=data_and_target.columns,index=data_and_target.columns)<br><span class="hljs-built_in">print</span>(df)<br></code></pre></td></tr></table></figure><h2 id="wrapper">2.Wrapper</h2><p>Through the evaluation of the model, add or drop some feature each trail to obtain a subset of all features, which is the selected feature.</p><p><strong>Pro</strong>: accurate, model-relevant</p><p><strong>Con</strong>: time-consuming</p><h3 id="recursive-feature-elimination">2.1 Recursive Feature Elimination</h3><ol type="1"><li>Train model with all m features</li><li>Select k best features and to take them out(or drop k worst feature from all feature)</li><li>Train the model with the rest feature and repeat step2, until we reach the max/min number of feature we want</li><li>The taken-out/ left-in feature is the final features space we want to preserve</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> RFE<br><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> RFECV<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> StratifiedKFold<br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier<br><span class="hljs-comment"># REF works for all models that have a weight on features</span><br><span class="hljs-comment"># step: the number(or precentage) of feature to eliminate in each iteration</span><br>estimator = RandomForestClassifier(n_estimators=<span class="hljs-number">100</span>)<br>selector = RFE(estimator= estimator, n_features_to_select= <span class="hljs-number">3</span>,step=<span class="hljs-number">1</span>)<br>data_transformed = selector.fit_transform(data_0,target_0)<br><br><span class="hljs-comment"># REFCV</span><br><span class="hljs-comment"># REF with cross validation</span><br>cv = StratifiedKFold(n_splits=<span class="hljs-number">5</span>)<br>selector = RFECV(estimator= estimator, min_features_to_select= <span class="hljs-number">3</span>, cv=cv, step=<span class="hljs-number">1</span>)<br>data_transformed = selector.fit_transform(data_0,target_0)<br></code></pre></td></tr></table></figure><h3 id="step-wise-regression">2.2 Step-wise Regression</h3><h2 id="embedded">3. Embedded</h2><p>Some models, like Lasso, Ridge, and Random Forest has method embedded in the model to evaluate features. Train these model first and than make selection of feature.</p><p><strong>Pro</strong>: fast, easy to apply</p><p><strong>Con</strong>: ignore the dependence of features</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> SelectFromModel<br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier<br><span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> LinearSVC<br><br>estimator = RandomForestClassifier(n_estimators=<span class="hljs-number">100</span>)<br><span class="hljs-comment"># threshold:</span><br><span class="hljs-comment"># threshold of the feature importance to drop</span><br><span class="hljs-comment"># if you apply l1 in your model(or use lasso), the threshold is 1e-5 by default</span><br><span class="hljs-comment"># otherwise, the threshold is mean by default, which means features with a importance less than mean importance will</span><br><span class="hljs-comment"># all by dropped</span><br>selecor = SelectFromModel(estimator,threshold=<span class="hljs-number">0.03</span>)<br>data_transformed = selecor.fit_transform(data_0,target_0)<br><br><br>estimator = LinearSVC(C=<span class="hljs-number">0.01</span>,penalty=<span class="hljs-string">&#x27;l1&#x27;</span>,dual=<span class="hljs-literal">False</span>).fit(data_0,target_0)<br><span class="hljs-comment"># prefit: whether the model given to the selector is already fit</span><br>selecor = SelectFromModel(estimator,threshold=<span class="hljs-number">0.03</span>,prefit=<span class="hljs-literal">True</span>)<br>data_transformed = selecor.transform(data_0)<br><span class="hljs-built_in">print</span>(data_transformed)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Feature Engineering</tag>
      
      <tag>Feature Selection</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL åŸºç¡€çŸ¥è¯†</title>
    <link href="/2022/02/09/MySQL-Basic/"/>
    <url>/2022/02/09/MySQL-Basic/</url>
    
    <content type="html"><![CDATA[<h1 id="mysqlåŸºç¡€çŸ¥è¯†">MySQLåŸºç¡€çŸ¥è¯†</h1><h2 id="æ•°æ®åº“ä¸‰å¤§èŒƒå¼">1. æ•°æ®åº“ä¸‰å¤§èŒƒå¼</h2><ol type="1"><li><p>æ•°æ®åº“è¡¨ä¸­ï¼Œæ‰€æœ‰å­—æ®µéƒ½æ˜¯ä¸å¯åˆ†è§£çš„åŽŸå­å€¼ï¼Œäº’ç›¸ä¸ä¾èµ–</p></li><li><p>æ‰€æœ‰éžä¸»é”®å­—æ®µéƒ½ä¾èµ–äºŽä¸»é”®</p><p>ï¼ˆå­¦å·ï¼Œå§“åï¼Œä¸“ä¸šåç§°ï¼‰å…¶ä¸­ä¸“ä¸šåç§°ä¸ä¾èµ–äºŽä¸»é”®ï¼Œæ‰€ä»¥ä¸æ»¡è¶³ç¬¬äºŒèŒƒå¼</p></li><li><p>æ‰€æœ‰éžä¸»é”®å±žæ€§éƒ½ç›´æŽ¥ä¾èµ–äºŽä¸»é”®</p><p>ï¼ˆå­¦å·ï¼Œå§“åï¼Œä¸“ä¸šidï¼Œä¸“ä¸šåç§°ï¼‰å…¶ä¸­åŒ…å«é—´æŽ¥ä¾èµ–å…³ç³» å­¦æ ¡-&gt;ä¸“ä¸šid-&gt;ä¸“ä¸šåç§°ï¼Œä¸æ»¡è¶³ç¬¬ä¸‰èŒƒå¼</p></li></ol><h2 id="mysqlçš„æž¶æž„">2. MySQLçš„æž¶æž„</h2><p>MySQLå¯ä»¥åˆ†ä¸ºåº”ç”¨å±‚,é€»è¾‘å±‚,æ•°æ®åº“å¼•æ“Žå±‚,ç‰©ç†å±‚ã€‚</p><p>åº”ç”¨å±‚ï¼šè´Ÿè´£å’Œå®¢æˆ·ç«¯ï¼Œå“åº”å®¢æˆ·ç«¯è¯·æ±‚ï¼Œå»ºç«‹è¿žæŽ¥ï¼Œè¿”å›žæ•°æ®</p><p>é€»è¾‘å±‚ï¼šåŒ…æ‹¬SQKæŽ¥å£ï¼Œè§£æžå™¨ï¼Œä¼˜åŒ–å™¨ï¼ŒCacheä¸Žbuffer</p><p>æ•°æ®åº“å¼•æ“Žå±‚ï¼šæœ‰å¸¸è§çš„MyISAM,InnoDBç­‰ç­‰</p><p>ç‰©ç†å±‚ï¼šè´Ÿè´£æ–‡ä»¶å­˜å‚¨ï¼Œæ—¥å¿—ç­‰ç­‰</p><h3 id="ä¸€æ¡sqlè¯­å¥æ‰§è¡Œçš„è¿‡ç¨‹">2.1 ä¸€æ¡SQLè¯­å¥æ‰§è¡Œçš„è¿‡ç¨‹</h3><ol type="1"><li>å®¢æˆ·ç«¯é¦–å…ˆé€šè¿‡è¿žæŽ¥å™¨è¿›è¡Œèº«ä»½è®¤è¯å’Œæƒé™ç›¸å…³</li><li>å¦‚æžœæ˜¯æ‰§è¡ŒæŸ¥è¯¢è¯­å¥çš„æ—¶å€™ï¼Œä¼šå…ˆæŸ¥è¯¢ç¼“å­˜ï¼Œä½†MySQL 8.0 ç‰ˆæœ¬åŽè¯¥æ­¥éª¤ç§»é™¤ã€‚</li><li>æ²¡æœ‰å‘½ä¸­ç¼“å­˜çš„è¯ï¼ŒSQL è¯­å¥å°±ä¼šç»è¿‡è§£æžå™¨ï¼Œåˆ†æžè¯­å¥ï¼ŒåŒ…æ‹¬è¯­æ³•æ£€æŸ¥ç­‰ç­‰</li><li>é€šè¿‡ä¼˜åŒ–å™¨ï¼Œå°†ç”¨æˆ·çš„SQLè¯­å¥æŒ‰ç…§ MySQL è®¤ä¸ºæœ€ä¼˜çš„æ–¹æ¡ˆåŽ»æ‰§è¡Œã€‚</li><li>æ‰§è¡Œè¯­å¥ï¼Œå¹¶ä»Žå­˜å‚¨å¼•æ“Žè¿”å›žæ•°æ®</li></ol><h3 id="buffer-ä¸Ž-cache-çš„å¯¹æ¯”">2.2 buffer ä¸Ž cache çš„å¯¹æ¯”</h3><ol type="1"><li>Cache(å¦‚Qcache)ä¸€èˆ¬ç”¨æ¥æŠŠå›ºå®šè¯­å¥å¯¹åº”çš„ç»“æžœé›†æ”¾åœ¨å†…å­˜ï¼Œç›®çš„æ˜¯ä¸ºäº†æé«˜è¯»å–é€Ÿåº¦</li><li>bufferï¼ˆå¦‚buffer poolï¼‰ä¸€èˆ¬ç”¨æ¥æŠŠé¡µé¢åŠ è½½åˆ°å†…å­˜ï¼Œæ¯æ¬¡å†™å…¥æ—¶ï¼Œå…ˆæ›´æ–°buffer poolä¸­çš„æ—¥å¿—ï¼ˆredo logï¼‰ï¼ŒæŠŠè¦ä¿®æ”¹çš„é¡µè®°ä¸ºè„é¡µã€‚åŽå°è¿›ç¨‹æ¯éš”ä¸€æ®µæ—¶é—´å°†buffer poolä¸­çš„æ—¥å¿—è¿›è¡Œåˆ·ç›˜ï¼Œä»Žè€Œæé«˜äº†ç£ç›˜IOæ•ˆçŽ‡ï¼Œé™ä½Žäº†å¤§é‡å†™å…¥å¸¦æ¥çš„å†²å‡»</li></ol><h2 id="mysqlçš„å¼•æ“Ž">3. MySQLçš„å¼•æ“Ž</h2><h3 id="mysqlæ”¯æŒçš„å¼•æ“Ž">3.1 MySQLæ”¯æŒçš„å¼•æ“Ž</h3><table><thead><tr class="header"><th>InnoDB</th><th>MyISAM</th></tr></thead><tbody><tr class="odd"><td>æ”¯æŒäº‹åŠ¡</td><td>ä¸æ”¯æŒ</td></tr><tr class="even"><td>æ”¯æŒå¤–é”®</td><td>ä¸æ”¯æŒ</td></tr><tr class="odd"><td>èšé›†ç´¢å¼•</td><td>éžèšé›†ç´¢å¼•</td></tr><tr class="even"><td>è¡Œçº§é”å’Œè¡¨çº§é”</td><td>è¡¨çº§é”</td></tr></tbody></table><p>Memory å­˜å‚¨å¼•æ“Žï¼š</p><p>Memoryå­˜å‚¨å¼•æ“Žå°†æ‰€æœ‰æ•°æ®éƒ½ä¿å­˜åœ¨å†…å­˜ï¼Œä¸éœ€è¦ç£ç›˜ IOã€‚æ”¯æŒå“ˆå¸Œç´¢å¼•ï¼Œå› æ­¤æŸ¥æ‰¾é€Ÿåº¦æžå¿«ã€‚Memory è¡¨ä½¿ç”¨è¡¨çº§é”ï¼Œå› æ­¤å¹¶å‘å†™å…¥çš„æ€§èƒ½è¾ƒä½Žã€‚</p><h3 id="innodbçš„ç´¢å¼•">3.2 InnoDBçš„ç´¢å¼•</h3><p>ç´¢å¼•æ˜¯ä¸€ç§æ•°æ®ç»“æž„ï¼Œç”¨äºŽå¸®åŠ©å­˜å‚¨å¼•æ“Žå¿«é€Ÿçš„æ‰¾åˆ°æ•°æ®ï¼Œç´¢å¼•å­˜å‚¨åœ¨å†…å­˜ä¸Š</p><h4 id="èšé›†ç´¢å¼•å’Œéžèšé›†ç´¢å¼•">3.2.1 èšé›†ç´¢å¼•å’Œéžèšé›†ç´¢å¼•</h4><p>èšé›†ç´¢å¼•ä¸­ï¼Œç´¢å¼•å’Œæ•°æ®ç»‘å®šåœ¨ä¸€èµ·ï¼Œé€šè¿‡æŸ¥æ‰¾ç´¢å¼•å¯ä»¥ç›´æŽ¥è¿”å›žæ•°æ®ã€‚ä¸»é”®éƒ½æ˜¯èšé›†ç´¢å¼•ã€‚éžèšé›†ç´¢å¼•ä¸­ï¼Œæ•°æ®å’Œç´¢å¼•åˆ†ç¦»ï¼Œé€šè¿‡ä¸€ä¸ªæˆ–å¤šä¸ªéžèšé›†ç´¢å¼•çš„æŸ¥è¯¢ï¼ŒæŸ¥åˆ°å¯¹åº”æŸä¸€å€¼çš„ä¸»é”®å€¼/åœ°å€ï¼Œç„¶åŽå†ä½¿ç”¨ä¸»é”®å€¼æ‰¾åˆ°æ•°æ®</p><p>æœ‰æ—¶éžèšé›†ç´¢å¼•æ— æ³•ç›´æŽ¥æ‰¾åˆ°ä¸»é”®å€¼ï¼Œåªèƒ½æŸ¥åˆ°æ»¡è¶³éžèšé›†ç´¢å¼•æŸä¸€ç»„å€¼çš„é”æ¬§èšé›†ç´¢å¼•ï¼Œæ­¤æ—¶ä¼šå›žåˆ°èšé›†ç´¢å¼•ä¸­æ ¹æ®ä¸»é”®å€¼ç»§ç»­æŸ¥æ‰¾æ•°æ®ï¼Œè¿™ä¸€è¿‡ç¨‹ç§°ä¸º<strong>å›žè¡¨æŸ¥è¯¢</strong></p><h4 id="è”åˆç´¢å¼•å’Œæœ€å·¦åŒ¹é…åŽŸåˆ™"><strong>3.2.2 è”åˆç´¢å¼•å’Œæœ€å·¦åŒ¹é…åŽŸåˆ™ï¼š</strong></h4><p>è”åˆç´¢å¼•æ˜¯æŒ‡å¯¹è¡¨ä¸Šçš„å¤šä¸ªåˆ—çš„å…³é”®è¯è¿›è¡Œç´¢å¼•ã€‚</p><p>å¯¹äºŽè”åˆç´¢å¼•çš„æŸ¥è¯¢ï¼Œå¦‚æžœç²¾ç¡®åŒ¹é…è”åˆç´¢å¼•çš„å·¦è¾¹è¿žç»­ä¸€åˆ—æˆ–è€…å¤šåˆ—ï¼Œåˆ™mysqlä¼šä¸€ç›´å‘å³åŒ¹é…ç›´åˆ°é‡åˆ°èŒƒå›´æŸ¥è¯¢ï¼ˆ&gt;,&lt;,between,likeï¼‰å°±åœæ­¢åŒ¹é…ã€‚whereè¯­å¥ä¸­ï¼Œæ‰€æœ‰å‘½ä¸­çš„ç´¢å¼•è¢«ç§°ä¸ºåŒ¹é…åˆ—ï¼Œæ²¡æœ‰å‘½ä¸­ä½†å‡ºçŽ°åœ¨ç´¢å¼•ä¸­çš„æˆä¸ºè¿‡æ»¤åˆ—ï¼Œæ‰€æœ‰ä¸åœ¨ç´¢å¼•ä¸­çš„æˆä¸ºéžåŒ¹é…åˆ—</p><p>ä¾‹å¦‚è”åˆç´¢å¼•ä¸ºï¼ˆuser, age, id), è€ŒèŒƒå›´æŸ¥è¯¢ä¸­çš„è°“è¯­ä¸ºâ€œwhere id = 1 and age &gt; 10 and user = wang and sex = 'M' â€,æ­¤æ—¶ï¼š</p><ol type="1"><li>åœ¨whereè¯­å¥è¯­å¥ä¸­æŸ¥æ‰¾è°“è¯­userï¼Œå‘½ä¸­ï¼Œuserä¸ºåŒ¹é…åˆ—</li><li>åœ¨whereè¯­å¥è¯­å¥ä¸­æŸ¥æ‰¾è°“è¯­ageï¼Œå‘½ä¸­ï¼Œä½†ageä¸ºèŒƒå›´æŸ¥è¯¢ï¼Œå› æ­¤ageåŽçš„åˆ—æ— æ³•å†å‘½ä¸­</li><li>idæœªå‘½ä¸­ï¼Œä½†å‡ºçŽ°åœ¨ç´¢å¼•ä¸­ï¼Œä¸ºè¿‡æ»¤åˆ—</li><li>sexä¸åœ¨ç´¢å¼•ä¸­ï¼Œä¸ºéžåŒ¹é…åˆ—</li></ol><p>å¯¹äºŽuserå’Œsexï¼ŒSQLå°†åœ¨å†…å­˜ä¸­çš„ç´¢å¼•ï¼ˆb+æ ‘ï¼‰è¿›è¡ŒæŸ¥è¯¢ï¼ˆé€šè¿‡explainå¯æŸ¥çœ‹æŸ¥è¯¢æ–¹å¼ä¸ºREFï¼‰</p><p>å¯¹äºŽidï¼ŒSQLå°†åœ¨ç¬¦åˆuserï¼Œageæ¡ä»¶çš„å­æ ‘ä¸ŠéåŽ†ï¼Œè¿™æ ·çš„å¤æ‚åº¦å¹¶ä¸é™ä½Žï¼Œä½†ç”±äºŽæ˜¯åœ¨å†…å­˜ä¸Šæ‰§è¡Œï¼Œé€Ÿåº¦ä»ç„¶æ¯”å›žè¡¨åŽå¿«ï¼ˆé€šè¿‡explainå¯æŸ¥çœ‹æŸ¥è¯¢æ–¹å¼ä¸ºINDEXï¼‰</p><p>å¯¹äºŽsexï¼ŒSQLå°†å…ˆå›žè¡¨ï¼Œè¿”å›žæ‰€æœ‰æ»¡è¶³userï¼Œageï¼Œidæ¡ä»¶çš„æ•°æ®ç»“æžœï¼Œç„¶åŽå†éåŽ†èŽ·å¾—æ»¡è¶³sexæ¡ä»¶çš„æ•°æ®ç»“æžœï¼ˆé€šè¿‡explainå¯æŸ¥çœ‹æŸ¥è¯¢æ–¹å¼ä¸ºALLï¼‰</p><p>Mysqlä¼šå¯¹ç¬¬ä¸€ä¸ªç´¢å¼•å­—æ®µæ•°æ®è¿›è¡ŒæŽ’åºï¼Œåœ¨ç¬¬ä¸€ä¸ªå­—æ®µåŸºç¡€ä¸Šï¼Œå†å¯¹ç¬¬äºŒä¸ªå­—æ®µæŽ’åºã€‚</p><h3 id="ç´¢å¼•çš„æ•°æ®ç»“æž„">3.3 ç´¢å¼•çš„æ•°æ®ç»“æž„</h3><p>InnoDBé‡‡ç”¨çš„æ˜¯B+Treeç´¢å¼•</p><p>B-Treeï¼šä¸€ç§è‡ªå¹³è¡¡å¤šæ’æ ‘ã€‚æ¯ä¸ªèŠ‚ç‚¹éƒ½å­˜å‚¨keyå’Œvalueã€‚å› ä¸ºæ¯ä¸ªèŠ‚ç‚¹éƒ½æœ‰æ•°æ®ï¼Œæ‰€ä»¥æŸ¥è¯¢æ•ˆçŽ‡è¾ƒé«˜</p><p>B+Treeï¼šä¹Ÿæ˜¯è‡ªå¹³è¡¡å¤šå‰æ ‘ï¼Œä½†ä¸­é—´èŠ‚ç‚¹ä¸å­˜æ”¾æ•°æ®åªå­˜æ”¾keyã€‚åªåœ¨å¶èŠ‚ç‚¹å­˜æ”¾æ•°æ®ï¼Œç»“æž„çŸ®èƒ–ï¼Œå‡ºåº¦æ›´å¤§ï¼Œå¯ä»¥åœ¨ç›¸åŒçš„ç£ç›˜ç©ºé—´ä¸‹å®¹çº³æ›´å¤šæ•°æ®ã€‚ä¸”åœ¨å¶èŠ‚ç‚¹ä¹‹é—´é“¾æŒ‡é’ˆï¼Œæ‰€ä»¥è¿›è¡ŒèŒƒå›´æŸ¥è¯¢æ—¶åªéœ€è¦éåŽ†å¶èŠ‚ç‚¹å³å¯ã€‚</p><p>Hashç´¢å¼•ï¼šå“ˆå¸Œç´¢å¼•å¯¹äºŽæ¯ä¸€è¡Œæ•°æ®è®¡ç®—ä¸€ä¸ªå“ˆå¸Œç ï¼Œå¹¶å°†æ‰€æœ‰çš„å“ˆå¸Œç å­˜å‚¨åœ¨ç´¢å¼•ä¸­ï¼ŒåŒæ—¶åœ¨å“ˆå¸Œè¡¨ä¸­ä¿å­˜æŒ‡å‘æ¯ä¸ªæ•°æ®è¡Œçš„æŒ‡é’ˆã€‚åªæœ‰ Memory å¼•æ“Žæ˜¾å¼æ”¯æŒå“ˆå¸Œç´¢å¼•ã€‚</p><p><strong>ä¸ºä½•ä¸ä½¿ç”¨çº¢é»‘æ ‘ï¼š</strong></p><p>çº¢é»‘æ ‘æ˜¯äºŒå‰æŸ¥æ‰¾æ ‘ï¼Œå‡ºåº¦ä¸º2ï¼Œå› æ­¤çº¢é»‘æ ‘å­˜å‚¨ä¸€å¼ è¡¨ï¼Œé«˜åº¦ä¼šæ¯”B Treeå¤§å¾ˆå¤šï¼ŒIOæ¬¡æ•°å¤šï¼Œæ£€ç´¢æ—¶é—´é•¿</p><h2 id="mysqlçš„äº‹åŠ¡">4. MySQLçš„äº‹åŠ¡</h2><h3 id="acid">4.1 ACID</h3><p>äº‹åŠ¡æ»¡è¶³å¦‚ä¸‹å‡ ä¸ªç‰¹æ€§ï¼š</p><ul><li><p>åŽŸå­æ€§ï¼ˆAtomicityï¼‰: ä¸€ä¸ªäº‹åŠ¡ä¸­çš„æ‰€æœ‰æ“ä½œè¦ä¹ˆå…¨éƒ¨å®Œæˆï¼Œè¦ä¹ˆå…¨éƒ¨ä¸å®Œæˆã€‚</p></li><li><p>ä¸€è‡´æ€§ï¼ˆConsistencyï¼‰: äº‹åŠ¡æ‰§è¡Œå‰åŽæ•°æ®åº“çš„çŠ¶æ€ä¿å­˜ä¸€è‡´ã€‚</p></li><li><p>éš”ç¦»æ€§ï¼ˆIsolationï¼‰ å¤šä¸ªå¹¶å‘äº‹åŠ¡å¯¹æ•°æ®åº“è¿›è¡Œæ“ä½œï¼Œäº‹åŠ¡é—´äº’ä¸å¹²æ‰°ã€‚</p></li><li><p>æŒä¹…æ€§ï¼ˆDurabilityï¼‰ äº‹åŠ¡æ‰§è¡Œå®Œæ¯•ï¼Œå¯¹æ•°æ®çš„ä¿®æ”¹æ˜¯æ°¸ä¹…çš„ï¼Œå³ä½¿ç³»ç»Ÿæ•…éšœä¹Ÿä¸ä¼šä¸¢å¤±</p></li></ul><h3 id="äº‹åŠ¡çš„å¹¶å‘é—®é¢˜å’Œéš”ç¦»ç­‰çº§">4.2 äº‹åŠ¡çš„å¹¶å‘é—®é¢˜å’Œéš”ç¦»ç­‰çº§</h3><p>å¹¶å‘é—®é¢˜ï¼š</p><ul><li>ä¸¢å¤±ä¿®æ”¹</li><li>è„è¯»ï¼šå½“å‰äº‹åŠ¡å¯ä»¥æŸ¥çœ‹åˆ°åˆ«çš„äº‹åŠ¡æœªæäº¤çš„æ•°æ®ã€‚</li><li>ä¸å¯é‡è¯»ï¼šåœ¨åŒä¸€äº‹åŠ¡ä¸­ï¼Œä½¿ç”¨ç›¸åŒçš„æŸ¥è¯¢è¯­å¥ï¼ŒåŒä¸€æ•°æ®èµ„æºèŽ«åæ”¹å˜äº†ã€‚</li><li>å¹»è¯»ï¼šåœ¨åŒä¸€äº‹åŠ¡ä¸­ï¼Œä½¿ç”¨ç›¸åŒçš„æŸ¥è¯¢è¯­å¥ï¼ŒèŽ«åå¤šå‡ºäº†ä¸€äº›ä¹‹å‰ä¸å­˜åœ¨çš„æ•°æ®ï¼Œæˆ–èŽ«åå°‘äº†ä¸€äº›åŽŸå…ˆå­˜åœ¨çš„æ•°æ®ï¼Œä¾‹å¦‚ç¬¬äºŒæ¬¡è¯»å–å‰ï¼Œè¡¨æ ¼è¢«æ’å…¥äº†æ–°è¡Œã€‚</li></ul><p>éš”ç¦»ç­‰çº§</p><ul><li><p>è¯»æœªæäº¤ï¼š ä¸€ä¸ªäº‹åŠ¡è¿˜æ²¡æäº¤ï¼Œå®ƒåšçš„å˜æ›´å°±èƒ½è¢«åˆ«çš„äº‹åŠ¡çœ‹åˆ°ã€‚</p></li><li><p>è¯»å·²æäº¤ï¼š ä¸€ä¸ªäº‹åŠ¡æäº¤åŽï¼Œå®ƒåšçš„å˜æ›´æ‰èƒ½è¢«åˆ«çš„äº‹åŠ¡çœ‹åˆ°ã€‚</p></li><li><p>å¯é‡å¤è¯»ï¼š ä¸€ä¸ªäº‹åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­çœ‹åˆ°çš„æ•°æ®æ€»æ˜¯å’Œäº‹åŠ¡å¯åŠ¨æ—¶çœ‹åˆ°çš„æ•°æ®æ˜¯ä¸€è‡´çš„ã€‚åœ¨è¿™ä¸ªçº§åˆ«ä¸‹äº‹åŠ¡æœªæäº¤ï¼Œåšå‡ºçš„å˜æ›´å…¶å®ƒäº‹åŠ¡ä¹Ÿçœ‹ä¸åˆ°ã€‚</p></li><li><p>ä¸²è¡ŒåŒ–ï¼š å¯¹äºŽåŒä¸€è¡Œè®°å½•è¿›è¡Œè¯»å†™ä¼šåˆ†åˆ«åŠ è¯»å†™é”ï¼Œå½“å‘ç”Ÿè¯»å†™é”å†²çªï¼ŒåŽé¢æ‰§è¡Œçš„äº‹åŠ¡éœ€ç­‰å‰é¢æ‰§è¡Œçš„äº‹åŠ¡å®Œæˆæ‰èƒ½ç»§ç»­æ‰§è¡Œã€‚</p></li></ul><p>å¹¶å‘é—®é¢˜çš„è§£å†³ï¼š</p><p><img src="/2022/02/09/MySQL-Basic/1.png"></p><h2 id="mysqlçš„é”innodb">5. MySQLçš„é”ï¼ˆInnoDBï¼‰</h2><h3 id="é”çš„æ€§è´¨">5.1 é”çš„æ€§è´¨</h3><h4 id="å…±äº«æ€§">5.1.1 å…±äº«æ€§</h4><p>å…±äº«é”ï¼šå…¶ä»–äº‹åŠ¡å¯ä»¥è¯»ä½†ä¸èƒ½å†™ï¼Œåˆç§°ä¸ºè¯»é”</p><p>æŽ’ä»–é”ï¼šå…¶ä»–äº‹åŠ¡ä¸èƒ½è¯»å†™ï¼Œåˆç§°ä¸ºå†™é”</p><h4 id="ç²’åº¦">5.1.2 ç²’åº¦</h4><p><strong>è¡¨çº§é”:</strong> å¯¹å½“å‰æ“ä½œçš„æ•´å¼ è¡¨åŠ é”,å®žçŽ°ç®€å•ï¼ŒåŠ é”å¿«ï¼Œä½†å¹¶å‘èƒ½åŠ›ä½Žã€‚</p><p><strong>è¡Œé”:</strong> é”ä½æŸä¸€è¡Œï¼Œå¦‚æžœè¡¨å­˜åœ¨ç´¢å¼•ï¼Œé‚£ä¹ˆè®°å½•é”æ˜¯é”åœ¨ç´¢å¼•ä¸Šçš„ï¼Œå¦‚æžœè¡¨æ²¡æœ‰ç´¢å¼•ï¼Œé‚£ä¹ˆ InnoDB ä¼šåˆ›å»ºä¸€ä¸ªéšè—çš„èšç°‡ç´¢å¼•åŠ é”ã€‚è¡Œçº§é”èƒ½å¤§å¤§å‡å°‘æ•°æ®åº“æ“ä½œçš„å†²çªã€‚å…¶åŠ é”ç²’åº¦æœ€å°ï¼Œå¹¶å‘åº¦é«˜ï¼Œä½†åŠ é”æ…¢ï¼Œä¼šå‡ºçŽ°æ­»é”ã€‚</p><p><strong>Gap é”</strong>ï¼šé”ä½ä¸€ä¸ªé—´éš™ä»¥é˜²æ­¢æ’å…¥ï¼Œä½†ä¸åŒ…æ‹¬é—´éš™çš„ä¸¤ç«¯ã€‚å‡è®¾ç´¢å¼•åˆ—æœ‰2, 4, 8 ä¸‰ä¸ªå€¼ï¼Œå¦‚æžœå¯¹ 4 åŠ è¡Œé”ï¼Œé‚£ä¹ˆä¹Ÿä¼šåŒæ—¶å¯¹(2,4)å’Œ(4,8)è¿™ä¸¤ä¸ªé—´éš™åŠ é”ã€‚å…¶ä»–äº‹åŠ¡æ— æ³•æ’å…¥å€¼æ‰€å¯¹åº”çš„ç´¢å¼•å€¼åœ¨è¿™ä¸¤ä¸ªé—´éš™ä¹‹é—´çš„è®°å½•</p><p><strong>next-key-lockï¼š</strong>next-key lock å®žé™…ä¸Šå°±æ˜¯ è¡Œé”+è¿™æ¡è®°å½•å‰é¢çš„ gap lock çš„ç»„åˆã€‚å‡è®¾æœ‰ç´¢å¼•å€¼10,11,13å’Œ 20,é‚£ä¹ˆå¯èƒ½çš„ next-key lock åŒ…æ‹¬:</p><p>(è´Ÿæ— ç©·,10],(10,11],(11,13],(13,20],(20,æ­£æ— ç©·)</p><p>åœ¨ RR éš”ç¦»çº§åˆ«ä¸‹ï¼ŒInnoDB ä½¿ç”¨ next-key lock ä¸»è¦æ˜¯é˜²æ­¢å¹»è¯»é—®é¢˜äº§ç”Ÿã€‚</p><h4 id="æ„å‘é”">5.1.3 æ„å‘é”</h4><p>æ„å‘é”å¿…é¡»æ˜¯è¡¨çº§é”ï¼Œå¯ä»¥æœ‰å…±äº«æ€§å’ŒæŽ’ä»–æ€§ã€‚æ„å‘é”çš„ä½œç”¨åœ¨äºŽä¿æŠ¤ä¸åŒçº§åˆ«çš„é”å…±äº«æ€§ä¸å†²çªï¼Œæˆ–è€…è¯´æé«˜æ£€æµ‹è¿™ä¸€å†²çªçš„æ•ˆçŽ‡ã€‚</p><p>å‡è®¾äº‹åŠ¡Aæ­£åœ¨updateè¡¨tçš„æŸä¸€è¡Œrï¼Œå¹¶ç»™è¿™ä¸€è¡Œæ·»åŠ äº†æŽ’ä»–é”ï¼ŒåŒæ—¶ï¼Œäº‹åŠ¡Bæƒ³è¦ç»™è¡¨tä¸Šä¸€ä¸ªè¡¨çº§å…±äº«é”ï¼Œä¸ºäº†é˜²æ­¢å…±äº«æ€§å†²çªï¼Œäº‹åŠ¡Bå¿…é¡»æ£€æŸ¥è¡¨tçš„æ¯ä¸€è¡Œï¼Œæ£€æŸ¥æ˜¯å¦æœ‰Aä¸Šçš„é”è¿™æ ·çš„æŽ’ä»–é”ï¼Œç„¶åŽæ‰èƒ½ä¸Šé”</p><p>å› æ­¤ï¼ŒAç»™è¡¨tä¸­çš„è¡Œrä¸ŠæŽ’ä»–é”æ—¶ï¼ŒåŒæ—¶è¿˜ä¼šç»™è¡¨tä¸Šä¸€ä¸ªè¡¨çº§çš„æŽ’ä»–æ„å‘é”ï¼Œæ­¤æ—¶Bæ‰€ä¸Šçš„è¡¨çº§å…±äº«é”å°†ä¼šè¢«é˜»å¡ž</p><p>æ³¨æ„ï¼Œæ„å‘é”åªä¼šé˜»å¡žè¡¨çº§é”ï¼Œä¸Šä¾‹ä¸­ï¼Œå¦‚æžœæœ‰å¦ä¸€äº‹åŠ¡Cè¯•å›¾ç»™å¦ä¸€è¡Œr2åŠ å…±äº«é”ï¼Œåˆ™Aæ‰€åŠ çš„æŽ’ä»–æ„å‘é”ä¸ä¼šå¯¹å…¶è¿›è¡Œé˜»å¡ž</p><h4 id="æ­»é”">5.1.4 æ­»é”</h4><p>ä¸¤ä¸ªäº‹ç‰©åŒæ—¶ä¸Šé”è¿›å…¥äº’ç›¸ç­‰å¾…çš„æ­»å¾ªçŽ¯ã€‚</p><p>å¦‚ä½•è§£å†³æ­»é”ï¼š</p><ol type="1"><li>åˆç†è®¾è®¡ç´¢å¼•ï¼Œå°½å¯èƒ½é€šè¿‡ç´¢å¼•å®šä½è¡Œï¼Œé˜²æ­¢è¿‡å¤šçš„è¡¨å’Œè¡Œè¢«é”ä½ï¼Œå‡å°‘ç«žäº‰</li><li>è°ƒæ•´SQLè¯­å¥é¡ºåºï¼Œupdateï¼Œdeleteç­‰é•¿æ—¶é—´æŒæœ‰é”çš„è¯­å¥æ”¾åœ¨åŽé¢</li><li>æŠŠå¤§äº‹ç‰©åˆ†è§£æˆå°äº‹åŠ¡æ‰§è¡Œ</li><li>å¿…è¦æ—¶ï¼Œå¯ä»¥ä½¿ç”¨<code>KILL</code>æ€æ­»ä¸€äº›è¿›ç¨‹ï¼Œé‡Šæ”¾å…¶æŒæœ‰çš„é”</li></ol><p>è¯¦ç»†åˆ†æžæ–¹æ³•å¯å‚è€ƒ<a href="https://z.itpub.net/article/detail/7B944ED17C0084CF672A47D6E938B750">è¿™ç¯‡æ–‡ç« </a></p><h4 id="ä¹è§‚æ€§">5.1.5 ä¹è§‚æ€§</h4><p>ä¹è§‚é”ï¼šå¯¹äºŽæ•°æ®å†²çªä¿æŒä¸€ç§ä¹è§‚æ€åº¦ï¼Œæ“ä½œæ•°æ®æ—¶ä¸ä¼šå¯¹æ“ä½œçš„æ•°æ®è¿›è¡ŒåŠ é”ï¼Œåªæœ‰åˆ°æ•°æ®æäº¤çš„æ—¶å€™æ‰é€šè¿‡ä¸€ç§æœºåˆ¶æ¥éªŒè¯æ•°æ®æ˜¯å¦å­˜åœ¨å†²çªã€‚</p><p>æ‚²è§‚é”ï¼šå¯¹äºŽæ•°æ®å†²çªä¿æŒä¸€ç§æ‚²è§‚æ€åº¦ï¼Œåœ¨ä¿®æ”¹æ•°æ®ä¹‹å‰æŠŠæ•°æ®é”ä½ï¼Œç„¶åŽå†å¯¹æ•°æ®è¿›è¡Œè¯»å†™ï¼Œåœ¨å®ƒé‡Šæ”¾é”ä¹‹å‰ä»»ä½•äººéƒ½ä¸èƒ½å¯¹å…¶æ•°æ®è¿›è¡Œæ“ä½œï¼Œç›´åˆ°å‰é¢ä¸€ä¸ªäººæŠŠé”é‡Šæ”¾åŽä¸‹ä¸€ä¸ªäººæ•°æ®åŠ é”æ‰å¯å¯¹æ•°æ®è¿›è¡ŒåŠ é”ï¼Œç„¶åŽæ‰å¯ä»¥å¯¹æ•°æ®è¿›è¡Œæ“ä½œï¼Œä¸€èˆ¬æ•°æ®åº“çš„é”éƒ½æ˜¯æ‚²è§‚é”</p><h3 id="ä¸Šé”æ–¹å¼">5.2 ä¸Šé”æ–¹å¼</h3><h4 id="è¡¨é”">5.2.1 è¡¨é”</h4><p>éšå¼ä¸Šé”ï¼šä½¿ç”¨ä¸€äº›å…³é”®è¯æ—¶ï¼Œè‡ªåŠ¨æ·»åŠ è‡ªåŠ¨é‡Šæ”¾çš„ä¸Šé”ã€‚å¦‚selectè¯­å¥ä¼šç»™è¡¨ä¸Šå…±äº«é”ï¼Œinsertï¼Œupdateï¼Œdeleteä¼šç»™è¡¨ä¸ŠæŽ’ä»–é”</p><p>æ˜¾ç¤ºä¸Šé”ï¼š</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs SQL">LOCK <span class="hljs-keyword">TABLE</span> t1 READ  <span class="hljs-comment">-- ç»™t1è¡¨ä¸Šå…±äº«é”</span><br>LOCK <span class="hljs-keyword">TABLE</span> t1 WRITE  <span class="hljs-comment">-- ç»™t1è¡¨ä¸ŠæŽ’ä»–é”</span><br>UNLOCK <span class="hljs-keyword">TABLE</span> t1 <span class="hljs-comment">-- è§£é”t1</span><br>UNLOCK TABLES <span class="hljs-comment">-- è§£é”æ‰€æœ‰è¡¨</span><br></code></pre></td></tr></table></figure><h4 id="è¡Œé”">5.2.2 è¡Œé”</h4><p>éšå¼ä¸Šé”ï¼šä½¿ç”¨ä¸€äº›å…³é”®è¯æ—¶ï¼Œè‡ªåŠ¨æ·»åŠ è‡ªåŠ¨é‡Šæ”¾çš„ä¸Šé”ã€‚insertï¼Œupdateï¼Œdeleteä¼šç»™é€‰ä¸­çš„è¡Œä¸ŠæŽ’ä»–é”ã€‚æ³¨æ„selectä¸ä¼šç»™è¡ŒåŠ é”</p><p>æ˜¾ç¤ºä¸Šé”ï¼š</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> t1 <span class="hljs-keyword">IN</span> SHARE MODE <span class="hljs-comment">-- ç»™é€‰ä¸­çš„è¡ŒåŠ å…±äº«é”</span><br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> t1 <span class="hljs-keyword">FOR</span> UPDATE <span class="hljs-comment">-- ç»™é€‰ä¸­çš„è¡ŒåŠ æŽ’ä»–é”</span><br><span class="hljs-keyword">COMMIT</span><br><span class="hljs-keyword">ROLLBACK</span> <span class="hljs-comment">-- äº‹åŠ¡å®Œæˆæˆ–å›žæ»šæ—¶ï¼Œä¼šè§£é™¤äº‹ç‰©ä¸­æ‰€åŠ çš„è¡Œé”</span><br>KILL <span class="hljs-comment">-- æ€æ­»æŸä¸€è¿›ç¨‹ï¼Œä¼šè§£é™¤è¿™ä¸€è¿›ç¨‹æ‰€åŠ çš„è¡Œé”</span><br></code></pre></td></tr></table></figure><h2 id="mysqlçš„æ—¥å¿—">6. MySQLçš„æ—¥å¿—</h2><h3 id="logç§ç±»">6.1 logç§ç±»</h3><p>redo log: å­˜å‚¨å¼•æ“Žçº§åˆ«çš„logï¼ˆInnoDBæœ‰ï¼ŒMyISAMæ²¡æœ‰ï¼‰ï¼Œè¯¥logå…³æ³¨äºŽäº‹åŠ¡çš„æ¢å¤ã€‚åœ¨é‡å¯mysqlæœåŠ¡çš„æ—¶å€™ï¼Œæ ¹æ®redo logè¿›è¡Œé‡åšï¼Œä»Žè€Œä½¿äº‹åŠ¡æœ‰æŒä¹…æ€§ã€‚</p><p>undo logï¼šæ˜¯å­˜å‚¨å¼•æ“Žçº§åˆ«çš„logï¼ˆInnoDBæœ‰ï¼ŒMyISAMæ²¡æœ‰ï¼‰ä¿è¯æ•°æ®çš„åŽŸå­æ€§ï¼Œè¯¥logä¿å­˜äº†äº‹åŠ¡å‘ç”Ÿä¹‹å‰çš„æ•°æ®çš„ä¸€ä¸ªç‰ˆæœ¬ï¼Œå¯ä»¥ç”¨äºŽå›žæ»šï¼Œæ˜¯MVCCçš„é‡è¦å®žçŽ°æ–¹æ³•ä¹‹ä¸€ã€‚</p><p>å¦‚æžœéœ€è¦æ‰§è¡Œäº‹åŠ¡ï¼Œä½¿ç”¨redo logï¼Œæ‰§è¡Œå¤±è´¥åˆ™ä½¿ç”¨undo logï¼Œè¿™æ ·çš„ç»„åˆä¿è¯äº†äº‹åŠ¡çš„ä¸€è‡´æ€§</p><p>bin logï¼šæ•°æ®åº“çº§åˆ«çš„logï¼Œå…³æ³¨æ¢å¤æ•°æ®åº“çš„æ•°æ®ã€‚æœ‰å…³bin logå’Œredo logçš„åŒºåˆ«</p><ol type="1"><li>redo logæ˜¯InnoDBå¼•æ“Žç‰¹æœ‰çš„ï¼Œåªè®°å½•è¯¥å¼•æ“Žä¸­è¡¨çš„ä¿®æ”¹è®°å½•ã€‚binlogæ˜¯MySQLçš„Serverå±‚å®žçŽ°çš„ï¼Œä¼šè®°å½•æ‰€æœ‰å¼•æ“Žå¯¹æ•°æ®åº“çš„ä¿®æ”¹ï¼Œå…·æœ‰å´©æºƒä¿®å¤èƒ½åŠ›ã€‚InnoDBé€šè¿‡redo logä¿è¯å³ä½¿æ•°æ®åº“å‘ç”Ÿå¼‚å¸¸é‡å¯ï¼Œä¹‹å‰æäº¤çš„è®°å½•éƒ½ä¸ä¼šä¸¢å¤±ï¼Œè¿™ä¸ªèƒ½åŠ›ç§°ä¸ºcrash-safe</li><li>redo logæ˜¯ç‰©ç†æ—¥å¿—ï¼Œè®°å½•çš„æ˜¯åœ¨å…·ä½“æŸä¸ªæ•°æ®é¡µä¸Šåšäº†ä»€ä¹ˆä¿®æ”¹ï¼›binlogæ˜¯é€»è¾‘æ—¥å¿—ï¼Œè®°å½•çš„æ˜¯è¿™ä¸ªè¯­å¥çš„åŽŸå§‹é€»è¾‘ï¼Œä¾‹å¦‚è¯­å¥çš„å¢žåˆ æ”¹ï¼Œå¹¶ä¸è®°å½•æ•°æ®é¡µå…·ä½“å‘ç”Ÿäº†ä»€ä¹ˆæ”¹å˜ï¼Œå› æ­¤å•ç‹¬çš„bin logä¸å…·å¤‡å´©æºƒä¿®å¤èƒ½åŠ›ã€‚</li><li>redo logæ˜¯å¾ªçŽ¯å†™çš„ï¼Œç©ºé—´å›ºå®šä¼šç”¨å®Œï¼›binlogæ˜¯å¯ä»¥è¿½åŠ å†™å…¥çš„ï¼Œbinlogæ–‡ä»¶å†™åˆ°ä¸€å®šå¤§å°åŽä¼šåˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªï¼Œå¹¶ä¸ä¼šè¦†ç›–ä»¥å‰çš„æ—¥å¿—ã€‚</li></ol><h3 id="walæŠ€æœ¯">6.2 WALæŠ€æœ¯</h3><p>WALçš„å…¨ç§°æ˜¯Write-Ahead Loggingï¼Œå®ƒçš„å…³é”®ç‚¹å°±æ˜¯å…ˆå†™æ—¥å¿—ï¼Œå†å†™ç£ç›˜ã€‚äº‹åŠ¡åœ¨æäº¤å†™å…¥ç£ç›˜å‰ï¼Œä¼šå…ˆå†™åˆ°redo logé‡Œé¢åŽ»ã€‚å¦‚æžœç›´æŽ¥å†™å…¥ç£ç›˜æ¶‰åŠç£ç›˜çš„éšæœºI/Oè®¿é—®ï¼Œæ¶‰åŠç£ç›˜éšæœºI/Oè®¿é—®æ˜¯éžå¸¸æ¶ˆè€—æ—¶é—´çš„ä¸€ä¸ªè¿‡ç¨‹ï¼Œç›¸æ¯”ä¹‹ä¸‹å…ˆå†™å…¥redo logï¼ŒåŽé¢å†æ‰¾åˆé€‚çš„æ—¶æœºæ‰¹é‡åˆ·ç›˜èƒ½æå‡æ€§èƒ½ã€‚</p><h3 id="ä¸¤é˜¶æ®µæäº¤">6.3 ä¸¤é˜¶æ®µæäº¤</h3><p>ä¸ºäº†ä¿è¯binlogå’Œredo logä¸¤ä»½æ—¥å¿—çš„é€»è¾‘ä¸€è‡´ï¼Œæœ€ç»ˆä¿è¯æ¢å¤åˆ°ä¸»å¤‡æ•°æ®åº“çš„æ•°æ®æ˜¯ä¸€è‡´çš„ï¼Œé‡‡ç”¨ä¸¤é˜¶æ®µæäº¤çš„æœºåˆ¶ã€‚</p><ol type="1"><li>æ‰§è¡Œå™¨è°ƒç”¨å­˜å‚¨å¼•æ“ŽæŽ¥å£ï¼Œå­˜å‚¨å¼•æ“Žå°†ä¿®æ”¹æ›´æ–°åˆ°å†…å­˜ä¸­åŽï¼Œå°†ä¿®æ”¹æ“ä½œè®°å½•redo logä¸­ï¼Œæ­¤æ—¶redo logå¤„äºŽprepareçŠ¶æ€ã€‚</li><li>å­˜å‚¨å¼•æ“Žå‘ŠçŸ¥æ‰§è¡Œå™¨æ‰§è¡Œå®Œæ¯•ï¼Œæ‰§è¡Œå™¨ç”Ÿæˆè¿™ä¸ªæ“ä½œå¯¹åº”çš„binlogï¼Œå¹¶æŠŠbinlogå†™å…¥ç£ç›˜ã€‚</li><li>æ‰§è¡Œå™¨è°ƒç”¨å¼•æ“Žçš„æäº¤äº‹åŠ¡æŽ¥å£ï¼Œå¼•æ“ŽæŠŠåˆšåˆšå†™å…¥çš„redo logæ”¹æˆæäº¤commitçŠ¶æ€ï¼Œæ›´æ–°å®Œæˆ</li></ol><h3 id="mysql-ä¸»ä»Žæœºåˆ¶">6.4 MySQL ä¸»ä»Žæœºåˆ¶</h3><h4 id="ä¸»ä»Žé…ç½®">6.4.1ä¸»ä»Žé…ç½®</h4><p>ä¸€ä¸ªæœåŠ¡å™¨å……å½“ä¸»æœåŠ¡å™¨ï¼ˆmasterï¼‰ï¼Œå…¶ä½™çš„æœåŠ¡å™¨å……å½“ä»ŽæœåŠ¡å™¨ï¼ˆslaveï¼‰ã€‚ä»ŽæœåŠ¡å™¨ä¸»è¦ç”¨æ¥è¯»ï¼Œä¸»æœåŠ¡å™¨ä¸»è¦ç”¨å†™ï¼Œä»ŽæœåŠ¡å™¨å®šæœŸä¸Žä¸»æœåŠ¡å™¨è¿›è¡ŒåŒæ­¥ï¼Œå¤åˆ¶å…¶æ•°æ®ã€‚å› ä¸ºå¤åˆ¶æ˜¯å¼‚æ­¥è¿›è¡Œçš„ï¼Œæ‰€ä»¥ä»ŽæœåŠ¡å™¨ä¸éœ€è¦ä¸€ç›´è¿žæŽ¥ç€ä¸»æœåŠ¡å™¨</p><p>ä¸»ä»Žæœºåˆ¶çš„ä¼˜ç‚¹ï¼š</p><ol type="1"><li>æ•°æ®å­˜åœ¨å¤šä¸ªé•œåƒï¼Œå¯ä»¥é˜²æ­¢å•ä¸€ä¸»æœºå´©æºƒå’Œæ•°æ®ä¸¢å¤±ï¼Œå¦‚æžœä¸»æœºå®•æœºå¯ä»¥åˆ‡æ¢åˆ°ä»ŽæœåŠ¡å™¨ä¸Šï¼ˆç”±äºŽå¼‚æ­¥åŒæ­¥ï¼Œå¯èƒ½æ•°æ®ä¸€è‡´æ€§å­˜åœ¨é—®é¢˜ï¼‰</li><li>ä»ŽæœåŠ¡å™¨å¯ä»¥åˆ†æ‹…ä¸»æœåŠ¡å™¨çš„è¯»çš„åŽ‹åŠ›</li></ol><p>æ³¨æ„ï¼Œéƒ¨åˆ†æ•°æ®å®žæ—¶æ€§å¼ºï¼Œç»å¸¸ä¼šè¢«æ›´æ–°ï¼Œè¿™ç±»æ•°æ®ä¸é€‚åˆæ”¾åœ¨ä»ŽæœåŠ¡å™¨ä¸Šï¼Œå®¹æ˜“å¼•å‘é”™è¯¯</p><h4 id="ä¸»ä»Žå¤åˆ¶">6.4.2 ä¸»ä»Žå¤åˆ¶</h4><p>MySQLä¸»ä»Žå¤åˆ¶æµç¨‹ï¼š</p><ol type="1"><li>åœ¨äº‹åŠ¡å®Œæˆä¹‹å‰ï¼Œä¸»åº“åœ¨binlogä¸Šè®°å½•è¿™äº›æ”¹å˜ï¼Œå®Œæˆbinlogå†™å…¥è¿‡ç¨‹åŽï¼Œä¸»åº“é€šçŸ¥å­˜å‚¨å¼•æ“Žæäº¤äº‹ç‰©</li><li>ä»Žåº“å°†ä¸»åº“çš„binlogå¤åˆ¶åˆ°å¯¹åº”çš„ä¸­ç»§æ—¥å¿—ï¼Œå³å¼€è¾Ÿä¸€ä¸ªI/Oå·¥ä½œçº¿ç¨‹ï¼ŒI/Oçº¿ç¨‹åœ¨ä¸»åº“ä¸Šæ‰“å¼€ä¸€ä¸ªæ™®é€šçš„è¿žæŽ¥ï¼Œç„¶åŽå¼€å§‹binlog dump processï¼Œå°†è¿™äº›äº‹ä»¶å†™å…¥ä¸­ç»§æ—¥å¿—ã€‚ä»Žä¸»åº“çš„binlogä¸­è¯»å–äº‹ä»¶ï¼Œå¦‚æžœå·²ç»è¯»åˆ°æœ€æ–°äº†ï¼Œçº¿ç¨‹è¿›å…¥ç¡çœ å¹¶ç­‰å¾…maä¸»åº“äº§ç”Ÿæ–°çš„äº‹ä»¶ã€‚</li></ol><h2 id="å¤šç‰ˆæœ¬å¹¶å‘æŽ§åˆ¶mvcc">7. å¤šç‰ˆæœ¬å¹¶å‘æŽ§åˆ¶(MVCC)</h2><p><strong>å¤šç‰ˆæœ¬å¹¶å‘æŽ§åˆ¶ï¼ˆMVCCï¼‰</strong> æ˜¯é€šè¿‡ä¿å­˜æ•°æ®åœ¨æŸä¸ªæ—¶é—´ç‚¹çš„å¿«ç…§æ¥å®žçŽ°å¹¶å‘æŽ§åˆ¶çš„ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œä¸ç®¡äº‹åŠ¡æ‰§è¡Œå¤šé•¿æ—¶é—´ï¼Œäº‹åŠ¡å†…éƒ¨çœ‹åˆ°çš„æ•°æ®æ˜¯ä¸å—å…¶å®ƒäº‹åŠ¡å½±å“çš„ï¼Œæ ¹æ®äº‹åŠ¡å¼€å§‹çš„æ—¶é—´ä¸åŒï¼Œæ¯ä¸ªäº‹åŠ¡å¯¹åŒä¸€å¼ è¡¨ï¼ŒåŒä¸€æ—¶åˆ»çœ‹åˆ°çš„æ•°æ®å¯èƒ½æ˜¯ä¸ä¸€æ ·çš„ã€‚</p><p>å¯ä»¥è®¤ä¸ºMVCC æ˜¯è¡Œçº§é”çš„ä¸€ä¸ªå˜ç§ï¼Œä½†æ˜¯å®ƒåœ¨å¾ˆå¤šæƒ…å†µä¸‹é¿å…äº†åŠ é”æ“ä½œï¼Œå› æ­¤å¯ä»¥å®žçŽ°è¯»å†™å¹¶å‘ï¼Œå¹¶é™ä½Žæ­»é”æ¦‚çŽ‡ï¼ŒIOå¼€é”€æ›´ä½Žã€‚</p><p>MVCCåªåœ¨ å¯é‡å¤è¯»ï¼ˆREPEATABLE READï¼‰ å’Œè¯»å·²æäº¤ï¼ˆREAD COMMITTEDï¼‰ ä¸¤ä¸ªéš”ç¦»çº§åˆ«ä¸‹å·¥ä½œã€‚å…¶ä»–ä¸¤ä¸ªéš”ç¦»çº§åˆ«éƒ½å’Œ MVCC ä¸å…¼å®¹</p><p>é€šè¿‡MVCCï¼Œä¸æ˜¾å¼åŠ é”çš„ä¸€èˆ¬selectè¯­å¥ä½¿ç”¨çš„éƒ½æ˜¯å¿«ç…§è¯»ï¼Œå³è¯»å–æ•°æ®åœ¨äº‹åŠ¡è¯­å¥æ‰§è¡Œå‰æˆ–æ‰§è¡ŒåŽçš„åŽ†å²ç‰ˆæœ¬ï¼Œè€Œéžå½“å‰æ•°æ®ï¼Œä¹Ÿå³æ˜¯è¯´å…¶ä»–å¹¶å‘çš„äº‹ç‰©æ— æ³•å½±å“åˆ°è¯¥å¿«ç…§ã€‚è€Œæ˜¾å¼åŠ é”çš„selectè¯­å¥æ‰§è¡Œçš„æ˜¯å½“å‰è¯»ï¼ŒèŽ·å¾—ç›®æ ‡ä½ç½®æœ€æ–°çš„æ•°æ®</p>]]></content>
    
    
    <categories>
      
      <category>Database</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
      <tag>Interview Knowledge</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Basic Statistics for Data Science</title>
    <link href="/2022/02/09/statistics-for-ds/"/>
    <url>/2022/02/09/statistics-for-ds/</url>
    
    <content type="html"><![CDATA[<h1 id="statistics-for-data-science">Statistics for Data Science</h1><h2 id="basic-concepts-for-statistics">1. Basic Concepts for Statistics</h2><p><strong>Statistics</strong>: Statistics gather, describe and analyze sample data in a numerical way to understand the whole population</p><p><strong>Target Population</strong>: A particular group of interest, the distribution of the target population is called</p><p><strong>Sample Population</strong>: A group which the sample is taken from. In most cases it equals to the target population</p><p><strong>Sample</strong>: A subset of the sample population from which data are collected, Doing statistics is a process trying to learn information of the target population through samples. Ideally, sample should be representative to sample population, the sample population should be the same or representative to target population.</p><p><img src="/2022/02/09/statistics-for-ds/1.PNG" alt style="zoom:80%;"></p><p><strong>Variable</strong>: A dimension of a sample representing a specific measure. A sample can contain multiple variables</p><p><strong>Data </strong>: the actual counts, measurements or observation about the variables that markdown with samples</p><p><strong>Data Point and Sample Size</strong>: Data point is a single record of data in the sample. Sample size is the number of data point in the sample</p><p><strong>Parameter</strong>: A numerical description of a population characteristic. Note that a parameter of target population and sample is not the same. We cannot construct statistics with unknown parameters of the whole population</p><p><strong>Sample Statistics</strong>: A function constructed from the sample. A statistics should containing no <strong>unknown</strong> parameters. Common sample statistics includes:</p><table><thead><tr class="header"><th>Sample Statistics</th><th>Format</th></tr></thead><tbody><tr class="odd"><td>mean</td><td><span class="math inline">\(\bar{X} = \frac{1}{n}\sum_i^nX_i\)</span></td></tr><tr class="even"><td>biased variance</td><td><span class="math inline">\(S_0^2 = \frac{1}{n}\sum_i^n(X_i - \bar{X})^2\)</span></td></tr><tr class="odd"><td>unbiased variance</td><td><span class="math inline">\(S^2 = \frac{1}{n-1}\sum_i^n(X_i - \bar{X})\)</span></td></tr><tr class="even"><td>standard deviation</td><td><span class="math inline">\(S = \sqrt{S^ 2}\)</span></td></tr><tr class="odd"><td>moment</td><td><span class="math inline">\(A_k = \frac{1}{n}\sum_i^nX_i^k\)</span></td></tr><tr class="even"><td>central moment</td><td><span class="math inline">\(B_ k = \frac{1}{n}\sum_i^n(X_i - \bar{X})^k\)</span></td></tr></tbody></table><h2 id="data-classification">2. Data Classification</h2><h3 id="categorical-numeric">2.1 Categorical &amp; Numeric</h3><p><strong>Categorical</strong>: consist of labels or description of traits. It's meaning less to apply quantitative calculation on it</p><p><strong>Numeric</strong>: consist of counts and measurement, it have meanings when you apply quantitative calculations</p><h3 id="discrete-continuous">2.2 Discrete &amp; Continuous</h3><p><strong>Discrete</strong>: numeric data that can take only particular values(counts, rate stars)</p><p><strong>Continuous</strong>: numeric data that can take any values in an interval</p><p><img src="/2022/02/09/statistics-for-ds/3.PNG"></p><h3 id="noir">2.3 NOIR</h3><p><strong>Nominal level data</strong>: description of categorical data that order do not matters</p><p><strong>Ordinal level data</strong>: categorical data that have a meaningful order(still not meaningful to add or divide)</p><p><strong>Interval level data</strong>: numeric data that can be arranged in a meaningful order, and the different between data entries are meaningful(timestamp, shoe size, temperature degree)</p><p><strong>Ratio level data</strong>: Interval data where zero indicates absence of something(like body height, 0 inch body high do not have a actual meaning, it means the data are not collected, where 0 degree do have an actual meaning, so it is not a ratio data.) As ratio data cannot participate calculation if data is not included, it must be non-zero in a calculation, thus it can divide other numeric data, that is why it is called ratio data</p><p><img src="/2022/02/09/statistics-for-ds/2.PNG"></p><h2 id="two-important-theorem">3. Two Important Theorem</h2><p>There are two important probability theorem for statistics:</p><h3 id="law-of-large-number">3.1 Law of Large Number</h3><p><strong>Chebyshev's inequality</strong></p><p>For a random variable X, if E[X] and V[X] both exist: <span class="math display">\[P(|X-X[x ]| \ge \epsilon ) \le \frac{D[X]}{\epsilon^2}\]</span> This inequality implies taht the probability of an observation fall far from the expectation is small. The greater <span class="math inline">\(\epsilon\)</span> is, the smaller this probability is.</p><p><strong>Chebyshev's Law of Large Number</strong></p><p>Let a sequence <span class="math inline">\(X_n \to a\)</span>: <span class="math display">\[\lim_{n\to \infty} P(|X_n - a| &lt; \epsilon) = 1 \qquad \forall \epsilon\]</span> This law implies that a statistics on a sample would approaches the same statistics on the population as the sample size is big. In other word, the sample can represent the population when n is big.</p><h3 id="central-limit-theorem">3.2 Central Limit Theorem</h3><p>If a random phenomenon is caused by numerous factors that have same distribution but are independent to each other, then the limit of thu sum of these factors, which is the phenomenon, follows a normal distribution.</p><p>The CLT can be expressed in the following format:</p><p><strong>Lindebergâ€“LÃ©vy CLT</strong></p><p>Let <span class="math inline">\(X_1, X_2,..X_n\)</span> be a series of independent random variables following same distribution, <span class="math inline">\(E[X_i] = \mu, V[X_ i] = \sigma^2\)</span>, then <span class="math display">\[\lim_{n\to \infty}P(\frac{ \sum_i^n X_ i-n\mu}{\sqrt{n}\sigma } \le X) = \Phi_0(X)\]</span> where <span class="math inline">\(\Phi_0\)</span> is a standard normal distribution</p><p>This theorem implies that when n is big enough, let <span class="math inline">\(Y = \sum_i^nX_i\)</span>, we can regarding Y as following a normal distribution <span class="math inline">\(N(n\mu, n\sigma)\)</span></p><p>Such a conclusion has very important meaning to hypothesis testing. It indicates that, if a statistics is constructed through through adding up sample point, lilke mean, then this statistics should follow a normal distribution no matter what distribution each sample follows. In hypothesis test, if we want to test on the mean of a measure of the population, we can regard that measure of each sample point as a random variable, these variables are independent and same-distributed, so no matter what distribution that measure follows, the mean of it on the total should follow a normal distribution. According to law of large number, as long as n is big enough, the mean on the sample should also follow normal distribution. Thus CLT make hypothesis testing on mean statistics possible.</p><p>Let <span class="math inline">\(\mu, \sigma^2\)</span> be the mean and variance of the population, <span class="math inline">\(\bar{X},S^2\)</span> be the mean and variance of the sample. According to Law of Large Number and CLT: <span class="math display">\[E[\bar{ X}] = \mu\]</span></p><p><span class="math display">\[V[\bar{X}] = \frac{1}{n}\sigma^2\]</span></p><p><span class="math display">\[E[S^2] = \sigma^2\]</span></p><h2 id="topic-in-applied-statistics">4. Topic in Applied Statistics</h2><p>Some topics in statistics are widely applied in domains like machine learning and A/B Test</p><h3 id="sampling">1.Sampling</h3><h3 id="probability-density-estimation">2. Probability Density Estimation</h3><h3 id="statistical-learning-and-machine-learning">3. Statistical Learning and Machine Learning</h3><h3 id="experiment-and-hypothesis-testing">4. Experiment and Hypothesis Testing</h3><h3 id="observational-study-and-causal-inference">5. Observational Study and Causal Inference</h3>]]></content>
    
    
    <categories>
      
      <category>Probability &amp; Statistics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Basic Knowledge</tag>
      
      <tag>Statistics</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MongoDB Guildbook</title>
    <link href="/2022/02/06/MongoDB-Guildline/"/>
    <url>/2022/02/06/MongoDB-Guildline/</url>
    
    <content type="html"><![CDATA[<h1 id="mongodb">MongoDB</h1><h2 id="about-mongodb">About MongoDB</h2><p>MongoDB is a open- source NoSQL database stroing data in json like documents with schema.</p><p>mongoDB do not have concepts like join.</p><p>mongoDB provides APIs for most programing language</p><h2 id="three-ways-to-access-mongodb">Three ways to access MongoDB</h2><ol type="1"><li>Community server</li><li>VS extending</li><li>MongoDB Altas</li></ol><h2 id="concepts-in-mondodb">Concepts in MondoDB:</h2><p><strong>Document:</strong> a set of K-V pairs. Every document has a unique value via key "_id". Documents have dynamic schema, documents in same collection can have different schema. They. Can hold data of any types allowed by mongodb.</p><p><strong>Collection:</strong> a group of mongodb documents, similar to "tables in other database. Unlike tables, collections does nothave any schema definition, and it cannnot be join. Usually, documents with in a collection belonging to a particular subject.</p><p><strong>Database:</strong> A database is a container of collections of data</p><p><strong>Comparison between RDBMS and MongoDB</strong></p><table><thead><tr class="header"><th style="text-align: left;">RDBMS</th><th style="text-align: left;"></th><th></th><th></th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">Tables</td><td style="text-align: left;">stand for entity</td><td>Collections</td><td>A set of documents representing one object</td></tr><tr class="even"><td style="text-align: left;">rows</td><td style="text-align: left;">stand for an actual record</td><td>Documents</td><td>a json objects</td></tr><tr class="odd"><td style="text-align: left;">columns</td><td style="text-align: left;">stand for attributes</td><td>Fields</td><td>The first level of the schema</td></tr></tbody></table><h2 id="start-with-mongodb">Start with MongoDB</h2><ol type="1"><li><p>Build a sever(for Mac)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">mongod --config /opt/homebrew/etc/mongod.conf<br></code></pre></td></tr></table></figure><p>This create a temp mongo server. If you close the session by ctrl+c, he connecttion would be terminated</p><p>Or you can use the command</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">brew services start mongodb/brew/mongodb-community<br></code></pre></td></tr></table></figure><p>This create a back-support mongoDB server, you can still access to it after you close the terminal, to stop the back-support:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">brew services stop mongodb/brew/mongodb-community<br></code></pre></td></tr></table></figure></li><li><p>Start a connection</p><ol type="1"><li>After start the server, you can type <code>mongo</code> in bash to start a connection. Use <code>exit</code> to stop the connection</li><li>you can use mongodb compass to start a connection, this is a mongondb management UI</li><li>use Datagrip/Dataspell to build a connection</li></ol><p>Notes:</p><ul><li>The port for local host is always 27017</li><li>There's no default username and password</li></ul></li></ol><h2 id="data-types-in-mongodb">Data types in MongoDB</h2><p>Allowed data dytes in mongoDB include:</p><ul><li><p>BSON</p><p>â€‹ A mongoDB data type, it's binary encoded json that can processed faster, it support some types(data, timestamp,object id) that are not supported by json</p></li><li><p>JSON</p></li><li><p>Integer</p></li><li><p>Boolean</p></li><li><p>Double</p></li><li><p>Arrays</p></li><li><p>Objects</p><p>â€‹ Used to store embedded documents. If a documents A contains a K-V pair {"file":B}, where B is another document, the type of B in A's schema is Object</p></li><li><p>Null</p></li><li><p>Date</p></li><li><p>Timestemp</p></li><li><p>Object ID</p><p>â€‹ ObjectIds are small, likely unique, fast to generate, and ordered. It's a usually used as a PK of a document. ObjectId values are 12 bytes in length, consisting of a 4-bytes timestamp value representiong the ObjectId's creation, a 5-bytes random value, a 3-byte incrementing value</p></li><li><p>Code</p><p>â€‹ Like javascript code</p></li></ul><h2 id="create-and-drop-database">Create and Drop Database</h2><p>you can create databse by:</p><figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs fortran"><span class="hljs-keyword">use</span> &lt;database-<span class="hljs-keyword">name</span>&gt;<br></code></pre></td></tr></table></figure><p>It would select the DB, if not exists, it create the DB</p><p>Notes: The created databse will not be visible untill you insert any data into it</p><p>To drop the database:</p><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gcode">db.dropDatabase<span class="hljs-comment">()</span><br></code></pre></td></tr></table></figure><p>where <code>db</code> refer to the currently used database.</p><p>Before you drop the DB, makesure you select the DB first.</p><p>Some other commands related to create and drop</p><figure class="highlight nsis"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nsis"><span class="hljs-literal">show</span> databases -- list <span class="hljs-literal">all</span> visible DB<br>db -- <span class="hljs-literal">show</span> the <span class="hljs-literal">current</span> DB<br></code></pre></td></tr></table></figure><h2 id="create-and-drop-colletions">Create and drop colletions</h2><p>to create a collection in Database:</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">db.create<span class="hljs-constructor">Collection(<span class="hljs-string">&quot;name&quot;</span>,<span class="hljs-params">options</span>)</span><br></code></pre></td></tr></table></figure><p>to drop a collection:</p><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stata"><span class="hljs-keyword">db</span>.collection_name.<span class="hljs-keyword">drop</span>()<br></code></pre></td></tr></table></figure><p>to show collections in current DB</p><figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dart"><span class="hljs-keyword">show</span> collections<br></code></pre></td></tr></table></figure><h2 id="insert-documents">Insert documents</h2><p>to create one documents:</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">db.<span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">C1</span>.</span></span>insert<span class="hljs-constructor">One(&#123;<span class="hljs-string">&quot;name&quot;</span>:<span class="hljs-string">&quot;A&quot;</span>&#125;)</span>;<br></code></pre></td></tr></table></figure><p>to create many documents:</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">db.<span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">C1</span>.</span></span>insert<span class="hljs-constructor">Many([&#123;<span class="hljs-string">&quot;name&quot;</span>:<span class="hljs-string">&quot;B&quot;</span>&#125;,&#123;<span class="hljs-string">&quot;name&quot;</span>:<span class="hljs-string">&quot;C&quot;</span>&#125;])</span><br></code></pre></td></tr></table></figure><p>Note: the input of insertMany() should be a list[]</p><h2 id="update-documents">Update documents</h2><p>To update a documents</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs stylus">db<span class="hljs-selector-class">.C1</span><span class="hljs-selector-class">.updateOne</span>(&#123;<span class="hljs-string">&quot;name&quot;</span>:<span class="hljs-string">&quot;B&quot;</span>&#125;,&#123;<br>        <span class="hljs-variable">$set</span>:&#123;<br>            <span class="hljs-string">&quot;mobile&quot;</span>:<span class="hljs-string">&quot;123456&quot;</span><br>        &#125;<br>    &#125;<br>)<br></code></pre></td></tr></table></figure><p>Where:</p><ul><li>the first parameter eplicts the documents to update</li><li>the second parameter explicts the operation to conduct</li></ul><p>Notes:This command only applies to the first document that meet the search condition(the first pararmeter)</p><p>to update many documents:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs stylus">db<span class="hljs-selector-class">.C1</span><span class="hljs-selector-class">.updateMany</span>(&#123;<span class="hljs-string">&quot;mobile&quot;</span>:<span class="hljs-string">&quot;123456&quot;</span>&#125;,&#123;<br>        <span class="hljs-variable">$set</span>:&#123;<br>            <span class="hljs-string">&quot;mobile&quot;</span>:<span class="hljs-string">&quot;654321&quot;</span><br>        &#125;<br>    &#125;<br>)<br></code></pre></td></tr></table></figure><h2 id="read-data">Read data</h2><p>To read(and modify) data:</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs applescript"><span class="hljs-comment">-- find all documents in the collection</span><br>db.C1.find()<br><br><span class="hljs-comment">--find particular documents </span><br>db.C1.find(&#123;<span class="hljs-string">&quot;name&quot;</span>:<span class="hljs-string">&quot;A&quot;</span>,<span class="hljs-string">&quot;mobile&quot;</span>:<span class="hljs-string">&quot;654321&quot;</span>&#125;) <br><br><span class="hljs-comment">-- find the first documents that fits the condition</span><br>db.C1.findOne(&#123;<span class="hljs-string">&quot;mobile&quot;</span>:<span class="hljs-string">&quot;654321&quot;</span>&#125;)<br><br><span class="hljs-comment">-- find and delete the first documenttaht fits the condition</span><br>db.C1.findOneAndDelete(&#123;<span class="hljs-string">&quot;name&quot;</span>:<span class="hljs-string">&quot;D&quot;</span>&#125;)<br><br><span class="hljs-comment">-- find and replace the first documenttaht fits the condition</span><br><span class="hljs-comment">-- the second parameter gives a whole documents(like the format in insert)</span><br>db.C1.findOneAndReplace(&#123;<span class="hljs-string">&quot;name&quot;</span>:<span class="hljs-string">&quot;A&quot;</span>&#125;,&#123;<span class="hljs-string">&quot;name&quot;</span>:<span class="hljs-string">&quot;E&quot;</span>,<span class="hljs-string">&quot;mobile&quot;</span>:<span class="hljs-string">&quot;23456&quot;</span>&#125;)<br><br><span class="hljs-comment">-- find and update</span><br><span class="hljs-comment">-- the second parameter gives a the operation to apply on the  documents(like the format in update)</span><br>db.C1.findOneAndUpdate(&#123;<span class="hljs-string">&quot;name&quot;</span>:<span class="hljs-string">&quot;E&quot;</span>&#125;,&#123;<br>$<span class="hljs-keyword">set</span>:&#123;<br><span class="hljs-string">&quot;mobile&quot;</span>:<span class="hljs-string">&quot;12345&quot;</span><br>&#125;<br>&#125;<br>   )<br>   <br><span class="hljs-comment">-- find and Modify</span><br><span class="hljs-comment">-- pass a json that tell the command to conduct multiple operaions</span><br>db.C1.findAndModify(<br>    &#123;<br>    <span class="hljs-string">&quot;query&quot;</span>: &#123;<span class="hljs-string">&quot;name&quot;</span>:<span class="hljs-string">&quot;E&quot;</span>&#125;,<br>    <span class="hljs-string">&quot;update&quot;</span>:&#123;$<span class="hljs-keyword">set</span>:&#123;<span class="hljs-string">&quot;name&quot;</span>:<span class="hljs-string">&quot;A&quot;</span>&#125;&#125;,<br>    &#125;<br>)<br><br></code></pre></td></tr></table></figure><h2 id="delete-documents">Delete documents</h2><p>to delete documents from a collection:</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">-- delete the first documetn fits the condition<br>db.<span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">C1</span>.</span></span>delete<span class="hljs-constructor">One(&#123;<span class="hljs-string">&quot;mobile&quot;</span>:<span class="hljs-string">&quot;12345&quot;</span>&#125;)</span><br>-- delete all documents fit the condition<br>db.<span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">C1</span>.</span></span>delete<span class="hljs-constructor">Many(&#123;<span class="hljs-string">&quot;mobile&quot;</span>:<span class="hljs-string">&quot;12345&quot;</span>&#125;)</span><br></code></pre></td></tr></table></figure><h2 id="query">Query</h2><p>The first parameter is called query condition, by passing a json map, you tell the command constraints of fields.</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">db.<span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">C1</span>.</span></span>find(&#123;<span class="hljs-string">&quot;mobile&quot;</span>:<span class="hljs-string">&quot;12345&quot;</span>,<span class="hljs-string">&quot;name&quot;</span>:<span class="hljs-string">&quot;T&quot;</span>&#125;)<br></code></pre></td></tr></table></figure><p>you can also use the $and operand:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs routeros">db.C1.<span class="hljs-builtin-name">find</span>(<br>&#123;<br><span class="hljs-variable">$and</span>:[<br>&#123;<span class="hljs-string">&quot;mobile&quot;</span>:<span class="hljs-string">&quot;12345&quot;</span>&#125;,&#123;<span class="hljs-string">&quot;name&quot;</span>:<span class="hljs-string">&quot;T&quot;</span>&#125;<br>]<br>&#125;<br>)<br></code></pre></td></tr></table></figure><p>Other operand in this formats:</p><ul><li>or</li><li>nor</li></ul><p>to query documents with quantify condition:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">db.C1.<span class="hljs-builtin-name">find</span>(&#123;<span class="hljs-string">&quot;mobile&quot;</span>:&#123;<span class="hljs-variable">$gte</span>:<span class="hljs-string">&quot;20000&quot;</span>&#125;&#125;)<br></code></pre></td></tr></table></figure><p>Other operand in this formats:</p><ul><li>lte: less than ot equal</li><li>gt: greater than</li><li>lt: less than</li><li>eq: equal</li><li>neq: not equal</li></ul><h2 id="select-specific-fields">Select specific fields</h2><p>to select specific fields:</p><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stata"><span class="hljs-keyword">var</span> pipline = [<br>    &#123;<span class="hljs-variable">$sort</span>:&#123;<span class="hljs-string">&quot;name&quot;</span>:1&#125;&#125;<br>]<br><span class="hljs-keyword">db</span>.C1.aggregate(pipline)<br></code></pre></td></tr></table></figure><p>Notes:</p><ul><li>the first parameter explicts the query condition</li><li>the second parameter explicts the fields you want or do not want(Projection)</li><li><strong>You can not mix inclusion and exclusion</strong> in the second parameter like {"name":0,"mobile":1}</li><li>**The only field that can be mixed is "_id"** of documents. {"name":1,"_id":0}</li></ul><h2 id="projection">Projection</h2><p>Projection is a mechanism allowing you to select specific fieds, like slice of an array.</p><h2 id="aggregation">Aggregation</h2><p>To perform aggregation on collections:</p><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs stata"><span class="hljs-keyword">var</span> pipline = [<br>    &#123;<span class="hljs-variable">$sort</span>:&#123;<span class="hljs-string">&quot;name&quot;</span>:1&#125;&#125;,<br>    &#123;<span class="hljs-variable">$limit</span>:4&#125;<br>]<br><span class="hljs-keyword">db</span>.C1.aggregate(pipline)<br></code></pre></td></tr></table></figure><p>where pip line is list of operations,</p><ul><li>$count</li><li>$group</li><li>$limit</li><li>$lookup</li><li>$match</li><li>$merge</li><li>$sort</li><li>project</li><li>unwind</li><li>unset</li></ul><h2 id="limit-and-skip">Limit and skip</h2><p>Limit the results returned by:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">db<span class="hljs-selector-class">.C1</span><span class="hljs-selector-class">.find</span>()<span class="hljs-selector-class">.limit</span>(<span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure><p>showing the first there results</p><p>Skip the first 2 results and show the rest:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">db<span class="hljs-selector-class">.C1</span><span class="hljs-selector-class">.find</span>()<span class="hljs-selector-class">.skip</span>(<span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure><h2 id="sort">Sort</h2><p>to sort results:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">db<span class="hljs-selector-class">.C1</span><span class="hljs-selector-class">.find</span>()<span class="hljs-selector-class">.sort</span>(&#123;<span class="hljs-string">&quot;name&quot;</span>:-<span class="hljs-number">1</span>&#125;)<br></code></pre></td></tr></table></figure><p>where the json map in sort() specify the sorting depending on which fields. 1 for ascending and -1 for descending. If you pass multiple fields, it sort the next fields in the groups of previous fields.</p><h2 id="create-and-drop-index">Create and Drop index</h2><p>Create indexes:</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">db.<span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">C1</span>.</span></span>create<span class="hljs-constructor">Index(&#123;<span class="hljs-string">&quot;name&quot;</span>:1&#125;)</span><br>db.<span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">C1</span>.</span></span>create<span class="hljs-constructor">Indexes([&#123;<span class="hljs-string">&quot;name&quot;</span>:1&#125;,&#123;<span class="hljs-string">&quot;mobile&quot;</span>:1&#125;])</span><br></code></pre></td></tr></table></figure><p>Drop index:</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">db.<span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">C1</span>.</span></span>drop<span class="hljs-constructor">Index(&#123;<span class="hljs-string">&quot;mobile&quot;</span>:1&#125;)</span><br><br>-- drop all indexes except _id<br>db.<span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">C1</span>.</span></span>drop<span class="hljs-constructor">Indexes()</span><br></code></pre></td></tr></table></figure><p>Group by:</p><p>Group by operand:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs stylus">db<span class="hljs-selector-class">.C1</span><span class="hljs-selector-class">.aggregate</span>(<br>    &#123;<br>        <span class="hljs-variable">$group</span>:&#123;<br>            _id:<span class="hljs-string">&quot;$name&quot;</span>,<br>            <span class="hljs-string">&quot;count&quot;</span>:&#123;<span class="hljs-variable">$sum</span>:<span class="hljs-number">1</span>&#125;<br>        &#125;<br>    &#125;<br>)<br></code></pre></td></tr></table></figure><p>Where:</p><ul><li>_id is an essential arguments, it explain group by which field</li><li>put a $ before the field to group by, it's necessary</li><li>if you want to group by multiple levels, use _id:["$name","$mobile"]</li><li>the "count" is an alias defined by user</li><li>{$sum:1} = count(*)</li><li>{$sum:"$field"} = sum(field)</li><li>other operans includes: $avg, $min, $max</li><li>$push: push all values of the given field in the group into one array</li><li>$addToSet: same as $push, but return a unique set</li><li>$first, $last: return the first/last value</li><li>if _id:null, then return all documents in one group</li></ul><h2 id="back-up-restore">Back up &amp; Restore</h2><p>to back up all databases</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">-- dump the current database<br>mongodump<br></code></pre></td></tr></table></figure><p>To restore all databases</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">mongorestore<br></code></pre></td></tr></table></figure><h2 id="transaction">Transaction</h2><p>For transation realted content in MongoDB, please refer to <a href="https://zhuanlan.zhihu.com/p/71679945">this link</a>.</p>]]></content>
    
    
    <categories>
      
      <category>Database</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NoSQL</tag>
      
      <tag>MongoDB</tag>
      
      <tag>Guidebook</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
