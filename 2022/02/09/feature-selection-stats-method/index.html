

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Zhengyuan Yang">
  <meta name="keywords" content="">
  
    <meta name="description" content="Evaluate features on divergence and correlation. set one or more thresholds and select the feature.">
<meta property="og:type" content="article">
<meta property="og:title" content="Feature Selection: Statistical Method">
<meta property="og:url" content="http://example.com/2022/02/09/feature-selection-stats-method/index.html">
<meta property="og:site_name" content="Data Shore">
<meta property="og:description" content="Evaluate features on divergence and correlation. set one or more thresholds and select the feature.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2022/02/09/feature-selection-stats-method/1.png">
<meta property="article:published_time" content="2022-02-10T06:04:00.000Z">
<meta property="article:modified_time" content="2023-04-25T20:44:29.872Z">
<meta property="article:author" content="Zhengyuan Yang">
<meta property="article:tag" content="Feature Engineering">
<meta property="article:tag" content="Feature Selection">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/2022/02/09/feature-selection-stats-method/1.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>Feature Selection: Statistical Method - Data Shore</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.3","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"left","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.0.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Data Shore</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                Categories
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                Tags
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                Archives
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/banner.gif') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Feature Selection: Statistical Method"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-02-09 22:04" pubdate>
          February 9, 2022 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          9.9k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          83 mins
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> views
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="padding-left: 2rem; margin-right: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;Table of Contents</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Feature Selection: Statistical Method</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="feature-selection">Feature Selection</h1>
<h2 id="filter">1. Filter</h2>
<p>Evaluate features on divergence and correlation. set one or more thresholds and select the feature.</p>
<p><strong>Pro</strong>: fast, scalable, independent of the model</p>
<p><strong>Con</strong>: ignore the dependence of features</p>
<h3 id="varianceskewness">1.1 Variance/Skewness</h3>
<p>For most models, variables with high variance or skewness would be weighted more and deemed as more important. Thus, we can</p>
<ol type="1">
<li>calculate the variance(not STD) of each feature</li>
<li>set a threshold, select all features whose variance bigger than the threshold</li>
</ol>
<p>Calculation of Skewness: <span class="math display">\[
SK = \frac{n\sum(x_i-\bar{x})^3}{(n-1)(n-2)\sigma^3}
\]</span> An implementation of feature selection based on variance in Python</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> VarianceThreshold<br><span class="hljs-comment">#threshold 是方差的阈值</span><br><span class="hljs-comment">#返回选择后的特征</span><br>data_1 = VarianceThreshold(threshold=<span class="hljs-number">0.25</span>).fit_transform(data_0)<br></code></pre></td></tr></table></figure>
<h3 id="correlation">1.2 Correlation</h3>
<ol type="1">
<li>calculate the correlation value between each feature and the target</li>
<li>select the features with top K biggest correlation value</li>
</ol>
<h4 id="pearson-r">1.2.1 Pearson R</h4>
<p>Pearson R calculates correlation based on covariance. <span class="math display">\[
p_{X,Y} = \frac{cov(X,Y)}{\sigma_X \sigma_Y} = \frac{E[(X - \mu_X)(Y-\mu_Y)]}{\sigma_X \sigma_Y} = \frac{E[XY]-E[X]E[Y]}{\sqrt{(E[X^2]-E[X])^2} \sqrt{(E[Y^2]-E[Y])^2}}
\]</span> For a sample with n samples: <span class="math display">\[
r = \frac{\sum_i^n(X_i-\bar{X})(Y_i-\bar{Y})}{\sqrt{\sum_i^n(X_i-\bar{X})^2} \sqrt{\sum_i^n(Y_i-\bar{Y})^2}} = \frac{\sum XY - \frac{\sum X \sum Y}{n}}{\sqrt{\sum X^2 - \frac{(\sum X)^2 }{n}} \sqrt{\sum Y^2 - \frac{(\sum Y)^2 }{n}}}
\]</span> The Pearson R has following properties:</p>
<ul>
<li>The range of Pearson R is [-1,1], positive numbers indicate positive correlation</li>
<li>The Pearson R represents the linear correlation between two variables, linear transformation of X or Y does not change Pearson R</li>
<li>X and Y must be numerical variables and follow normal distribution</li>
<li>The observations of X and Y are in pairs</li>
</ul>
<h4 id="spearman">1.2.2 Spearman</h4>
<p>Suppose we have samples of X and Y with n observations. Sort the observations X and Y to obtain two new set <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>, where <span class="math inline">\(a_i,b_i\)</span> is the rank of <span class="math inline">\(X_i,Y_i\)</span> in X,Y</p>
<p>define Spearman correlation as: <span class="math display">\[
\rho = \frac{6\sum_i^n(a_i-b_i)^2}{n(n^2-1)}
\]</span> The Spearman correlation has following properties:</p>
<ul>
<li>The range of Spearman correlations is [-1,1], positive numbers indicate positive correlation</li>
<li>The Spearman correlation represents rank correlation (simply based on size relationship)</li>
<li>X and Y does not need to follow certain distribution. Aithough the sample must be the same, they do not need to be in pairs<br>
</li>
<li>The statistical power of Spearman is relatively lower</li>
</ul>
<p><img src="/2022/02/09/feature-selection-stats-method/1.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="kendall">1.2.3 Kendall</h4>
<p>Suppose we combine variables X and Y into a new element <span class="math inline">\((X,Y)\)</span>. If two elements <span class="math inline">\((X_i, Y_i)\)</span> and <span class="math inline">\(X_j,Y_j\)</span> satisfy either of these two case:</p>
<ul>
<li><span class="math inline">\(X_i &gt; X_j\)</span> and <span class="math inline">\(Y_i &gt;Y_j\)</span></li>
<li><span class="math inline">\(X_i &lt; X_j\)</span> and <span class="math inline">\(Y_i &lt;Y_j\)</span></li>
</ul>
<p>Then we call these two elements have consistency</p>
<p>if <span class="math inline">\(X_i = X_j\)</span> and <span class="math inline">\(Y_i = Y_j\)</span>, we regard these two elements as having neither consistency nor inconsistency. Otherwise, we call these two elements have inconsistency</p>
<p>define Kendall correlation as: <span class="math display">\[
\tau = \frac{C-D}{\sqrt{N3-N1}\sqrt{N_3-N_2}{}}
\]</span> where:</p>
<ul>
<li><p>C is number of paris of elements(Two element <span class="math inline">\((X _1,Y_1),(X_2,Y_ 2)\)</span> is one pair) that have consistency</p></li>
<li><p>D is number of paris of elements that have inconsistency</p></li>
<li><p><span class="math inline">\(N1 = \sum_i^s \frac{ 1}{2}U_i(U_i-1)\)</span>, where:</p>
<ul>
<li>s is the number of values in X that appears more than once</li>
<li><span class="math inline">\(U_i\)</span> is the number those values appears(For <span class="math inline">\(i^{th}\)</span> Values in s)</li>
<li>For example, for a X={1,2,2,3,3,3,4}, s=2, <span class="math inline">\(U_1 = 2, U_2 = 3\)</span></li>
</ul></li>
<li><p>N2 is calculated same way as N1 on Y</p></li>
<li><p><span class="math inline">\(N3 = \frac{1}{2}N(N- 1)\)</span>, where is the number of samples</p></li>
</ul>
<p>The Kendall correlations have similar conditions as Pearson R. The only difference is it represents rank correlation instead of linear correlation</p>
<ul>
<li>The range of Pearson R is [-1,1], positive numbers indicate positive correlation</li>
<li>X and Y must be numerical variables and follow normal distribution</li>
<li>The observations of X and Y are in pairs</li>
</ul>
<p><strong>An implementation of feature selection based on Pearson R in Python</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> SelectKBest<br><span class="hljs-keyword">from</span> scipy.stats <span class="hljs-keyword">import</span> pearsonr<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_all_pscore</span>(<span class="hljs-params">x,y</span>):</span><br>    k = np.zeros([<span class="hljs-number">4</span>,<span class="hljs-number">2</span>])<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,x.shape[<span class="hljs-number">1</span>]):<br>        temp = pearsonr(x[:,i],y[:,<span class="hljs-number">0</span>])<br>        k[i,:] = np.array(temp)<br>    <span class="hljs-keyword">return</span> [k.T[<span class="hljs-number">0</span>],k.T[<span class="hljs-number">1</span>]]<br><span class="hljs-comment"># 下面的写法有问题理论上应该与上面的函数等价，实际上在调用np.array时，会把最内层的pearsonr系数值变成一个数组对象，导致SelectKBest无法</span><br><span class="hljs-comment"># 遍历，需要用astype把第一列转化为float，但这样很难封装进lambda函数里，不如不用，写这个的人铁nt，害我研究一个多小时</span><br><span class="hljs-comment"># get_all_pscore =  lambda X,Y:np.array(list(map(lambda x:pearsonr(x,Y),X.T))).T</span><br><br><span class="hljs-comment">#第一个参数为一个callable()，该函数以feature，target为输入，输出可以是两种：</span><br><span class="hljs-comment"># 1. 一对数组pearsonr系数-p值（可以是tuple中两个数组，也可以是ndarray，总之第一个维度须为2</span><br><span class="hljs-comment"># 2. 一个单一的数组（只有相关系数）</span><br><span class="hljs-comment"># 第二个参数k，代表选择前k个</span><br>data_1 = SelectKBest(get_all_pscore(),k=<span class="hljs-number">2</span>).fit_transform(data_0,target_0)<br></code></pre></td></tr></table></figure>
<h3 id="hypothesis-testing">1.3 Hypothesis Testing</h3>
<p>We can conduct hypothesis testing on correlation to examine whether the correlation of two variables are significant, and we can drop those features with high correlation with others.</p>
<p>For example, we can conduct <span class="math inline">\(\chi^2\)</span> test to test the correlation of discrete variables. We can conduct Fisher's Z test on the correlation coefficient to determine whether the correlation are significant.</p>
<p>For details of these tests, refer to<a target="_blank" rel="noopener" href="http://zhengyuanyang.com/2022/03/25/Hypothesis-Testing/">this article</a></p>
<h3 id="mutual-information">1.4 Mutual Information</h3>
<p>For the theoretical part about Entrophy and Mutual Information, refer to <a target="_blank" rel="noopener" href="http://zhengyuanyang.com/2022/09/22/information-theory-in-ML/">this article</a> <span class="math display">\[
MI = H(x,y) - H(x|y) - H(y|x) = \sum_x\sum_yp(x,y)log\frac{p(x,y)}{p(x)p(y)}\\
\]</span> Suppose we have an input variable X with n samples and m unique values {<span class="math inline">\(x_1 = c_ 1,x_2 =c_ 1,...x_n = c_m\)</span>} and an output variable Y with n samples and k unique values {<span class="math inline">\(y_1 = c_ 1,y_2 =c_ 1,...y_n = c_k\)</span>}</p>
<p>It's easy to calculate <span class="math inline">\(P(X=c_i),P(Y=c_j),P(X=c_i,Y=c_j)\)</span></p>
<p>Thus the MI can be calculated. The greater MI X and Y share, the greater dependency there exists, and X is thus a more important feature.</p>
<p>The MI mtheod have the following properties:</p>
<ul>
<li>MI method is sometime impractical with two continuous numerical variables, since there are too many unique values</li>
<li>MI needs some certain metrics to map the original values in to a range(usually [0,1]), so that MI score of different variables can be compared</li>
</ul>
<p>An implementation of feature selection based on Mutual Information in Python:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mutual_info_score<br>MI_matrix = np.zeros([data_and_target.shape[<span class="hljs-number">1</span>],data_and_target.shape[<span class="hljs-number">1</span>]])<br><span class="hljs-comment"># calculate the MI matrix between each two feature</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,data_and_target.shape[<span class="hljs-number">1</span>]):<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,data_and_target.shape[<span class="hljs-number">1</span>]):<br>        MI_matrix[i,j] = mutual_info_score(data_and_target[i+<span class="hljs-number">1</span>],data_and_target[j+<span class="hljs-number">1</span>])<br>df = pd.DataFrame(MI_matrix,columns=data_and_target.columns,index=data_and_target.columns)<br><span class="hljs-built_in">print</span>(df)<br></code></pre></td></tr></table></figure>
<h2 id="wrapper">2.Wrapper</h2>
<p>Through the evaluation of the model, add or drop some feature each trail to obtain a subset of all features, which is the selected feature.</p>
<p><strong>Pro</strong>: accurate, model-relevant</p>
<p><strong>Con</strong>: time-consuming</p>
<h3 id="recursive-feature-elimination">2.1 Recursive Feature Elimination</h3>
<ol type="1">
<li>Train model with all m features</li>
<li>Select k best features and to take them out(or drop k worst feature from all feature)</li>
<li>Train the model with the rest feature and repeat step2, until we reach the max/min number of feature we want</li>
<li>The taken-out/ left-in feature is the final features space we want to preserve</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> RFE<br><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> RFECV<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> StratifiedKFold<br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier<br><span class="hljs-comment"># REF works for all models that have a weight on features</span><br><span class="hljs-comment"># step: the number(or precentage) of feature to eliminate in each iteration</span><br>estimator = RandomForestClassifier(n_estimators=<span class="hljs-number">100</span>)<br>selector = RFE(estimator= estimator, n_features_to_select= <span class="hljs-number">3</span>,step=<span class="hljs-number">1</span>)<br>data_transformed = selector.fit_transform(data_0,target_0)<br><br><span class="hljs-comment"># REFCV</span><br><span class="hljs-comment"># REF with cross validation</span><br>cv = StratifiedKFold(n_splits=<span class="hljs-number">5</span>)<br>selector = RFECV(estimator= estimator, min_features_to_select= <span class="hljs-number">3</span>, cv=cv, step=<span class="hljs-number">1</span>)<br>data_transformed = selector.fit_transform(data_0,target_0)<br></code></pre></td></tr></table></figure>
<h3 id="step-wise-regression">2.2 Step-wise Regression</h3>
<p>Stepwise regression is a variable selection method used in multiple linear regression to identify the most significant predictors or independent variables in a dataset. It is an iterative process that involves adding or removing variables based on their statistical significance, with the goal of improving the overall model's performance. Stepwise regression can help to mitigate multicollinearity, reduce overfitting, and simplify a model for easier interpretation.</p>
<p>There are three primary types of stepwise regression: forward selection, backward elimination, and bidirectional elimination (also known as stepwise selection).</p>
<ol type="1">
<li>Forward selection:
<ul>
<li>Start with an empty model (i.e., no independent variables)</li>
<li>Add the most significant variable based on a predetermined significance level threshold (e.g., p-value &lt; 0.05)</li>
<li>Continue adding variables one at a time, each time selecting the variable that provides the most significant improvement to the model</li>
<li>Stop when no further variables meet the significance level for inclusion</li>
</ul></li>
<li>Backward elimination:
<ul>
<li>Start with a full model (i.e., all independent variables included)</li>
<li>Remove the least significant variable based on a predetermined significance level threshold (e.g., p-value &gt; 0.1)</li>
<li>Continue removing variables one at a time, each time selecting the variable that has the least significant impact on the model</li>
<li>Stop when all remaining variables meet the significance level for retention</li>
</ul></li>
<li>Bidirectional elimination (stepwise selection):
<ul>
<li>Start with either an empty model or a full model</li>
<li>At each step, consider both adding and removing variables based on predetermined significance levels for inclusion and retention</li>
<li>Continue adding or removing variables iteratively until no more variables meet the criteria for inclusion or exclusion</li>
</ul></li>
</ol>
<p>Stepwise regression has some limitations and assumptions. The procedure assumes a linear relationship between the independent and dependent variables and requires that the data meet the assumptions of linear regression (e.g., normally distributed errors, homoscedasticity, and absence of multicollinearity). Additionally, stepwise regression can be sensitive to the initial set of variables, and the final model may depend on the order in which variables are considered.</p>
<p>Despite these limitations, stepwise regression can be a valuable tool for identifying the most important predictors in a dataset and building a parsimonious model with improved interpretability.</p>
<h2 id="embedded">3. Embedded</h2>
<p>Some models, like Lasso, Ridge, and Random Forest has method embedded in the model to evaluate features. Train these model first and than make selection of feature.</p>
<p><strong>Pro</strong>: fast, easy to apply</p>
<p><strong>Con</strong>: ignore the dependence of features</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> SelectFromModel<br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier<br><span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> LinearSVC<br><br>estimator = RandomForestClassifier(n_estimators=<span class="hljs-number">100</span>)<br><span class="hljs-comment"># threshold:</span><br><span class="hljs-comment"># threshold of the feature importance to drop</span><br><span class="hljs-comment"># if you apply l1 in your model(or use lasso), the threshold is 1e-5 by default</span><br><span class="hljs-comment"># otherwise, the threshold is mean by default, which means features with a importance less than mean importance will</span><br><span class="hljs-comment"># all by dropped</span><br>selecor = SelectFromModel(estimator,threshold=<span class="hljs-number">0.03</span>)<br>data_transformed = selecor.fit_transform(data_0,target_0)<br><br><br>estimator = LinearSVC(C=<span class="hljs-number">0.01</span>,penalty=<span class="hljs-string">&#x27;l1&#x27;</span>,dual=<span class="hljs-literal">False</span>).fit(data_0,target_0)<br><span class="hljs-comment"># prefit: whether the model given to the selector is already fit</span><br>selecor = SelectFromModel(estimator,threshold=<span class="hljs-number">0.03</span>,prefit=<span class="hljs-literal">True</span>)<br>data_transformed = selecor.transform(data_0)<br><span class="hljs-built_in">print</span>(data_transformed)<br></code></pre></td></tr></table></figure>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/Machine-Learning/" class="category-chain-item">Machine Learning</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/Feature-Engineering/">#Feature Engineering</a>
      
        <a href="/tags/Feature-Selection/">#Feature Selection</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Feature Selection: Statistical Method</div>
      <div>http://example.com/2022/02/09/feature-selection-stats-method/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>Zhengyuan Yang</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>February 9, 2022</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/03/25/Hypothesis-Testing/" title="Hypothesis Testing">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Hypothesis Testing</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/02/09/MySQL-Basic/" title="MySQL 基础知识">
                        <span class="hidden-mobile">MySQL 基础知识</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <i class="iconfont icon-bug"></i> <a href="http://zhengyuanyang.com/report/" target="_blank" rel="nofollow noopener"><span>Report Bug</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
