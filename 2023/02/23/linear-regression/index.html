

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Zhengyuan Yang">
  <meta name="keywords" content="">
  
    <meta name="description" content="This article discuss about Linear Regression and Generalized Linear Model">
<meta property="og:type" content="article">
<meta property="og:title" content="Linear Regression and Generalized Linear Model">
<meta property="og:url" content="http://example.com/2023/02/23/linear-regression/index.html">
<meta property="og:site_name" content="Data Shore">
<meta property="og:description" content="This article discuss about Linear Regression and Generalized Linear Model">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2023/02/23/linear-regression/2.png">
<meta property="og:image" content="http://example.com/2023/02/23/linear-regression/3.png">
<meta property="article:published_time" content="2023-02-23T04:44:18.000Z">
<meta property="article:modified_time" content="2023-03-03T08:44:46.055Z">
<meta property="article:author" content="Zhengyuan Yang">
<meta property="article:tag" content="Linear Regression">
<meta property="article:tag" content="Generalized Linear Model">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/2023/02/23/linear-regression/2.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>Linear Regression and Generalized Linear Model - Data Shore</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.3","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"left","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.0.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Data Shore</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                Categories
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                Tags
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/Toolbox/">
                <i class="iconfont icon-briefcase"></i>
                Toolbox
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/banner.gif') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Linear Regression and Generalized Linear Model"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-02-23 12:44" pubdate>
          February 23, 2023 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          11k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          96 mins
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> views
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="padding-left: 2rem; margin-right: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;Table of Contents</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Linear Regression and Generalized Linear Model</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="linear-regression-and-generalized-linear-model">Linear Regression and Generalized Linear Model</h1>
<h2 id="linear-regression">1. Linear Regression</h2>
<h3 id="hypothesis-space-and-basic-assumption">1.1 Hypothesis Space and Basic Assumption</h3>
<p>The Linear Regression is a statistical model used to discover the correlation between an output variable Y and a set of input variable X. Basically, a linear regression model should follow such <strong>hypothesis space</strong>: <span class="math display">\[
Y = \beta _1X+\beta_0 +\epsilon
\]</span> where <span class="math inline">\(\beta_1\)</span> is a vector consists of parameters for each feature. <span class="math inline">\(\beta_0\)</span> is a constant, <span class="math inline">\(\epsilon\)</span> represents the random error of the observation.</p>
<p>To modeling the data with a linear regression model, five assumption should be fulfilled:</p>
<p><strong>1. Linearity</strong></p>
<p>Linearity Assumption requires there to has a linear mapping relationship between Y and X. That is, the real mapping relationship should be consistent with the hypothesis space. Otherwise, there would be bais in the model.</p>
<p><strong>2. <span class="math inline">\(\epsilon\)</span> Independency</strong></p>
<p>The linear model assume the <span class="math inline">\(\epsilon\)</span> is a completely randomized error. That is, a sample's <span class="math inline">\(\epsilon\)</span> shoud not be correlated with other samples. If this assumption cannot be satisfied, we say there exists autocorrelation in the data. Autocorrelation would make the model underestimate the randomized error and increase bias. It usually happened when there exists time-sequence influence among the samples.</p>
<p><strong>3. X Independency</strong></p>
<p>The features should be independent to each other, otherwise we said there exists multicollinearity. Multicollinearity would increase the variance of the model and cause overfitting</p>
<p><strong>4.<span class="math inline">\(\epsilon\)</span> Homoskedasticity</strong></p>
<p>The variance of <span class="math inline">\(\epsilon\)</span> should be same on different scale of Y. Otherwise, we said there is a Heteroskedasticity. Heteroskedasticity.increase the variance of the model and make the learned parameter unstable.</p>
<p><strong>5. <span class="math inline">\(\epsilon\)</span> Normality</strong></p>
<p><span class="math inline">\(\epsilon \sim N(0,\sigma^2)\)</span> . If the randomzied error are not normally distributed, the data points with high error would make the learned parameter unstable and increase the variances of the model. Notice that when <span class="math inline">\(\epsilon \sim N(0,\sigma^2)\)</span>, and <span class="math inline">\(Y = \beta _1X+\beta_0 +\epsilon\)</span>, we would have <span class="math inline">\(Y \sim N(\beta _1X+\beta_0,\sigma^2)\)</span>. This means (Y|X) should follows a normal distribution. Notice that this is not equivalent to <span class="math inline">\(Y \sim N(\mu, \sigma^2)\)</span>. We do not need to do normality test on Y before the learning.</p>
<p>The detection techniques and solutions for the violation of the above assumptions can be found in <a target="_blank" rel="noopener" href="http://zhengyuanyang.com/2022/09/22/evaluation-for-regression/">this article</a></p>
<p>Linear Regression is:</p>
<ul>
<li>A supervised learning model</li>
<li>A parameter learning model</li>
<li>A non-probability learning model</li>
<li>A discriminative model</li>
</ul>
<h3 id="training-process-of-linear-regression">1.2 Training Process of Linear Regression</h3>
<p>With the hypothesis space given:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs pseudocode">Initialize the weight<br>for each sample:<br>		calculate output<br>Calculate overall error based on loss function<br>while the error &lt; threshold:  #or current error &gt; previous error <br>		for each sample and error:<br>				update w_new = w_old + a*w&#x27; #with a optimization algorithm<br>return to step2<br>		<br></code></pre></td></tr></table></figure>
<p><strong>Optimizer</strong></p>
<p>In the training process, the weight is updated n times where n is the sample size. <span class="math inline">\(\alpha\)</span> is the a hyper-parameter called learning rate. It control the step size of optimal searching process.</p>
<p>For regression models, most optimizers are based on gradient descending. In the pseudocode above, <span class="math inline">\(\omega&#39;\)</span> represents the partial derivatives of the parameters: <span class="math display">\[
\omega&#39; = \frac{\partial L}{\partial \theta} = \frac{\partial L}{\partial Y}\cdot\frac{\partial Y}{\partial \theta}
\]</span> For more on optimizer for linear regression, refer to <a href>this article</a></p>
<p><strong>Loss function:</strong></p>
<p>Common loss functions for linear regression includes MSE, MAE and RMSE. For more on loss functions, refer to<a target="_blank" rel="noopener" href="http://zhengyuanyang.com/2022/09/22/loss-function/#numerical-output">this article</a></p>
<h2 id="regularization-lasso-regression-and-ridge-regression">2. Regularization: Lasso Regression and Ridge Regression</h2>
<p>A common problem in machine learning is the overfitting. For the details of overfitting, refer to <a target="_blank" rel="noopener" href="http://zhengyuanyang.com/2022/09/19/overfitting/">this article</a></p>
<p>To solve overfitting, we can apply the structural Risk Minimization. We would add a penalty term regarding to the complexity of the model to the loss function. For details, refer to <a target="_blank" rel="noopener" href="http://zhengyuanyang.com/2022/09/12/Principle/#structural-risk-minimization">this article</a></p>
<p>The application of SRM on linear regression create Lasso and Ridge Regression. The Lasso and Ridge Regression have same training process like linear regression, but it add a regularization term of <span class="math inline">\(\omega\)</span> in the loss function to penalize overfitting:</p>
<p><strong>Lasso Regression</strong> <span class="math display">\[
J = MSE + \lambda ||\omega||_1
\]</span> <strong>Ridge Regression</strong> <span class="math display">\[
J = MSE + \lambda ||\omega||_2^2
\]</span> where <span class="math inline">\(\lambda\)</span> is a penalty parameter decides the extent of penalty. The regularization term is a L-P norm of the parameter vector. It is a generalized distance concept. Refer to the <a target="_blank" rel="noopener" href="http://zhengyuanyang.com/2022/10/08/distance/#minkowski-distance">Minkowski Distance</a></p>
<p>The basic function of Lasso Regression and Ridge Regression are both minimizing the parameters(complexity), but they have the following differences:</p>
<ul>
<li>The Lasso regression can reduce <span class="math inline">\(\omega_i\)</span> to 0, thus can be used for feature selection.</li>
<li>The Ridge mostly only reduce the parameter close to 0, thus is not very suitable for feature selection. We can still try it when the features are scaled though.</li>
</ul>
<h2 id="logistic-regression">3. Logistic Regression</h2>
<h3 id="basic-assumption">3.1 Basic Assumption</h3>
<p>Logistics Regression is a model for classification. Unlike normal linear model, which assume the output is continuous and normally distributed, the logistic regression assume the output Y follows a Bernoulli Distribution.</p>
<p>The hypothesis space if logistic regression:</p>
<p>Let Z denote the linear transformation contributed by the a linear regression model: <span class="math display">\[
Z = \beta _1X+\beta_0 +\epsilon
\]</span> Use an activation function sigmoid to convert such a transformation into a probability <span class="math inline">\(P(Y|X)\)</span>. For activation functions, refer to <a href>this article</a>. The decision boundary is thus: <span class="math display">\[
P(Y=1|X=x) = sigmoid(Z)
\]</span> Decide the classification of Y by <span class="math display">\[
y_{pred}  = argmax \{P(Y=1|X=x) , P(Y=0|X=x)\}
\]</span> The Logistic Regression model is a discriminative probably model, as it directly modeling on <span class="math inline">\(P(X|Y)\)</span></p>
<h3 id="training">3.2 Training</h3>
<p><strong>Loss Function</strong></p>
<p>The common loss function for logistic regression is <strong>Log Loss</strong>. Refer to <a target="_blank" rel="noopener" href="http://zhengyuanyang.com/2022/09/22/loss-function/#log-losscross-entropy-loss">this article</a> for details.</p>
<p><strong>Optimizer</strong></p>
<p>The optimizer for logistic regression is the same as the linear regression. Notice that now: <span class="math display">\[
\omega&#39; = \frac{\partial L}{\partial \theta} = \frac{\partial L}{\partial A}\cdot\frac{\partial A}{\partial Z}\cdot \frac{\partial Z}{\partial \theta}
\]</span></p>
<h2 id="generalized-linear-model">4. Generalized Linear Model</h2>
<p>From the previous section we can find that the most important different between linear regression and logistic regression is that the output variable Y follows different distribution type. In fact, linear regression and logistic regression both belongs to Generalized Linear Model(GLM)</p>
<h3 id="exponential-family-distribution">4.1 Exponential Family Distribution</h3>
<p>Exponential Family Distribution refer to those distributions taht can be reformed as a exponential format: <span class="math display">\[
p(x|\lambda)  = \frac{1}{Z(\lambda)}h(x)exp\{ \phi(\lambda)^TT(X)\}
\]</span> where:</p>
<ul>
<li><span class="math inline">\(\lambda\)</span> is the original parameter of the distribution, it can be a constant or a vector(e.g. <span class="math inline">\(N(\lambda_1 = \mu, \lambda_2 = \sigma^2)\)</span>)</li>
<li>h(x) is a function called basic measure</li>
<li>T(X) is a function called sufficient statistic</li>
<li><span class="math inline">\(\phi(\lambda)\)</span> is a function of <span class="math inline">\(\lambda\)</span>, we can can let <span class="math inline">\(\theta = \phi(\lambda)\)</span>. In such form, we call <span class="math inline">\(\theta\)</span> the <strong>canonical parameter</strong>, it can be a constanr or a vector, with same size of <span class="math inline">\(\lambda\)</span></li>
<li><span class="math inline">\(Z(\lambda)\)</span> is the partition function of this probability <span class="math inline">\(Z(\lambda) = ln\int h(x)exp\{ \phi(\lambda)^TT(X)\}\)</span></li>
</ul>
<p>By moving <span class="math inline">\(h(x), Z(\lambda)\)</span> in to the exponential, let <span class="math inline">\(\theta = \phi(\lambda)\)</span>, we can obtain that all Exponential Family Distribution can be expressed in such format: <span class="math display">\[
p(x|\theta) = \{ \theta^T T(x) + S(x) - A(\theta)\}
\]</span> In this form, we <span class="math inline">\(A(\theta)\)</span> the cumulant function</p>
<p>For example, the PDF of a Bernoulli function: <span class="math display">\[
p(x|p) = \lambda^x(1-\lambda)^{1-x} = exp\{ln[\lambda^x(1-\lambda)^{1-x}]\} = exp\{xln(\frac{\lambda}{1-\lambda})+ln(1-\lambda)\}
\]</span> where:</p>
<ul>
<li>T(x) = x</li>
<li><span class="math inline">\(\theta\)</span> = <span class="math inline">\(ln(\frac{\lambda}{1-\lambda})\)</span></li>
<li><span class="math inline">\(A(\theta) = -ln(1-\lambda) = ln(1+e^\theta)\)</span></li>
<li><span class="math inline">\(S(x) = 0\)</span></li>
</ul>
<p>Common Exponential Family Distribution includes gaussian distribution, exponential distribution, gamma distribution, bernoulli distribution, binomial distribution, multinomial distribution, poisson distribution and so on.</p>
<p><strong>Natural EFD</strong></p>
<p>The Natural EFD is a subset of the EFD. If T(x) = x, we call this distribution a natural EFD. For example, Gaussian Distribution, Bernoulli Distribution, Exponential Distribution, Poisson Distribution, Gamma Distribution and Multinomial Distribution are all natural EFD.</p>
<p><strong>Statistics of EFD</strong></p>
<p>One properties of Exponential Family Distribution is that: <span class="math display">\[
\frac{dA}{d\theta} = \frac{d}{d\theta}\{ln \int h(x) exp\{\theta^TT(x)\}\} = E[T(x)]
\]</span> When T(x) is given, we can calculate E[x] according to the properties of Expectation. For natural EFD, which T(x) = x, <span class="math inline">\(E(T(x)) = E[x]\)</span>. Use the Bernoulli Distribution as an example: <span class="math display">\[
\frac{dA}{d\theta} = \frac{d }{d\theta}ln(1+e^\theta) = \frac{1}{1+e^{-\theta}} = p
\]</span> Samely, we can deduce that <span class="math inline">\(\frac{d^2A}{d\theta^2} = Var[T(x)]\)</span></p>
<p>This indicate a very important attribute of EFD: the canonical parameter <span class="math inline">\(\theta\)</span> has a mapping relationship with the moments(<span class="math inline">\(\mu, \sigma^2, skewness,...\)</span>) of the distribution. We know that the <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> of a EFD is decided by its original parameter <span class="math inline">\(\lambda\)</span>, and we know <span class="math inline">\(\theta = \phi (\lambda)\)</span>, so there exists are reversible function <span class="math inline">\(\theta = \psi(\mu)\)</span>(if the size of <span class="math inline">\(\theta\)</span> is 1)</p>
<p><strong>Canonical Form of EFD</strong></p>
<p>Some EFD has 2 original parameters and thus has two canonical parameters <span class="math inline">\(\theta = [\theta_1,\theta_2]\)</span>.</p>
<p>For example, the cumulant function of a gaussian distribution is: <span class="math display">\[
A(\theta) = -\frac{\theta_1^2}{4 \theta_2} - \frac{1}{2}ln(-2\theta_2)
\]</span> In such cases, some time we would find <span class="math inline">\(\mu,\sigma^2\)</span> are tangled with <span class="math inline">\(\theta_1, \theta_2\)</span> that <span class="math inline">\([\theta_1,\theta_2]= f(\mu,\sigma^2)\)</span>. This make it difficult to calculate <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span>. Thus, we would reconstruct the nature EFD as: <span class="math display">\[
p(y|\theta_\mu) = exp \{ \frac{y\theta_\mu - b(\theta_\mu)}{a(\theta_v)} + c(y,\theta_v)\}
\]</span> Both <span class="math inline">\(\theta_\mu\)</span> and <span class="math inline">\(\theta_v\)</span> are a function of <span class="math inline">\((\theta_1,\theta_2)\)</span>, and we would need to ensure: <span class="math display">\[
A(\theta) = \frac{b(\theta_{\mu})}{a(\theta_v)}
\]</span> Also, we would ensure <span class="math inline">\(\theta_{\mu}\)</span> would only be a function decided by <span class="math inline">\(\mu\)</span>. <span class="math inline">\(\theta_{mu} = \psi(\mu)\)</span> is <strong>stilled called canonical paraparameter</strong> and it control the location of the EFD. The <span class="math inline">\(\theta_v\)</span> is called a <strong>dispersion parameter</strong>, it is basically a scaler to control the shape of the EFD and is associated with the variance of the distribution. The <span class="math inline">\(a(\theta_v)\)</span> is called a dispersion function. For EFD that only has one original parameter, which means the distribution does not has a <span class="math inline">\(\theta_2\)</span>, the dispersion function is simply <span class="math inline">\(a(\theta_v) = 1\)</span>, as the distribution does not has a second parameters to control shape.</p>
<p>Now we can revise the calculation of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span>: <span class="math display">\[
\mu = \frac{\partial A}{\partial \theta_\mu} = b&#39;(\theta_\mu)
\]</span></p>
<p><span class="math display">\[
\sigma^2 = \frac{\partial^2 A}{\partial \theta_\mu^2} = a(\theta_v)b&#39;&#39;(\theta_\mu)
\]</span></p>
<h3 id="generalized-linear-model-1">4.2 Generalized Linear Model</h3>
<p>A Generalized Linear Model is a model used to predict output Y with input X. Thus, a good idea is to estimate <span class="math inline">\(E[Y|X]\)</span>. For example, the prediction of a linear regression is <span class="math inline">\(E[Y|X]\)</span>, the prediction of a logistic regression is <span class="math inline">\(E[Y|X] = 0*P(Y=0|X) + 1*P(Y=1|X) = P(Y=1|X)\)</span>, and the prediction muti-category regression(softmax regression) is <span class="math inline">\(E[\vec{Y}|X,\vec{\pi}=\vec{p}] = [P(Y=0|X),P(Y=1|X),P(Y=k|X)]\)</span>.</p>
<p>Now we nake the following assumption:</p>
<ol type="1">
<li>The variable (Y|X) follows a natural EFD. Usually this can be guarantee by knowing Y follows a EFD.</li>
<li>The canonical parameter of the EFD <span class="math inline">\(\theta_\mu\)</span>, in a Bayesian context, follows a normal distribution, and thus can be learned from a linear hypothesis space</li>
</ol>
<p>To achieve the expectation, a GLM consists of:</p>
<ul>
<li>A linear predictor <span class="math inline">\(\eta = \beta X+b\)</span></li>
<li>A function that can transfer the linear prediction <span class="math inline">\(\eta\)</span> to the expectation <span class="math inline">\(\mu\)</span> we want. <span class="math inline">\(\mu = g^{-1}(\eta)\)</span></li>
</ul>
<p>We know that Y does not necessary follows a normal distribution and can be difficult to learned from with a linear hypothesis space. Thus we add a non-linear function to enhance the non-linearity of the hypothesis space. This function is called <strong>Activation Function</strong>, and the inverse of it <span class="math inline">\(\eta = g( \mu)\)</span> is called a joing function.</p>
<p><img src="/2023/02/23/linear-regression/2.png" srcset="/img/loading.gif" lazyload></p>
<p>We know from the assumption that <span class="math inline">\(\theta\)</span> is normally distributed and can be learned directly from the linear predictor. Thus, a good idea is to let <span class="math inline">\(g = \psi^{-1}\)</span>, so we have: <span class="math display">\[
\eta = g(\mu) = \psi^{-1}(\mu) = \theta_\mu
\]</span> In this case, the <span class="math inline">\(\eta\)</span> we are learning is exactly <span class="math inline">\(\theta_\mu\)</span>, which can be learned with a linear hypothesis space.</p>
<p>Hence, we we want to build a GLM to predict a variable <span class="math inline">\(Y|X \sim natural \ EFD(\theta)\)</span></p>
<ol type="1">
<li>Figure out the distribution type of Y, and rewrite it into a canonical form of EFD</li>
<li>Read <span class="math inline">\(\theta_\mu = \phi(\mu), b(\theta_\mu)\)</span> out of the format and write down <span class="math inline">\(\mu = \psi(\theta_\mu)\)</span></li>
<li>Select the activation function as <span class="math inline">\(\psi^{-1}(\eta)\)</span></li>
<li>Train the model</li>
</ol>
<p>The GLM enable us to generalize linear regression to many other cases, as long as Y|X follows a EFD. Common application includes Logistic Regression(Bernoulli Distribution), Softmax Regression(multi-category distribution), Polynomial Regression and so on. When Y|X follows a gaussian distribution, the activation function is just <span class="math inline">\(\mu = \eta\)</span>, and the model is reduced to a simply linear regression, which Y can be directly learned from a linear hypothesis space.</p>
<p>Some common joint functions and and activation functions are listed as follows:</p>
<p><img src="/2023/02/23/linear-regression/3.png" srcset="/img/loading.gif" lazyload></p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/Machine-Learning/" class="category-chain-item">Machine Learning</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/Linear-Regression/">#Linear Regression</a>
      
        <a href="/tags/Generalized-Linear-Model/">#Generalized Linear Model</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Linear Regression and Generalized Linear Model</div>
      <div>http://example.com/2023/02/23/linear-regression/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>Zhengyuan Yang</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>February 23, 2023</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2023/02/27/decision-tree/" title="Decision Tree and Ensemble Models">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Decision Tree and Ensemble Models</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/02/18/sensitivity-improvement/" title="A/B Testing: Experiment Sensitivity Improvement">
                        <span class="hidden-mobile">A/B Testing: Experiment Sensitivity Improvement</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <i class="iconfont icon-bug"></i> <a href="http://zhengyuanyang.com/report/" target="_blank" rel="nofollow noopener"><span>Report Bug</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
